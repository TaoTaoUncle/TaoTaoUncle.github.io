<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[git学习]]></title>
    <url>%2F2019%2F10%2F04%2Fgit%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[git 安装跳过。。各平台google下即可 git 工作流程一般如下 clone git资源作为工作目录 在克隆的资源上添加/修改 如果有其他人修改，我可以更新资源 在提交前查看修改 提交修改 修改完成后，如果发现错误，可以撤回提交并在此修改并提交 一把我们如果我们克隆的资源是本地资源，如果本地提交到远程我们需要push 当然本地开发的话我们就只需要commit，本地的概念分为：工作目录区、暂存区、版本库 工作区：就是你在电脑里能看到的目录。 暂存区：英文叫stage, 或index。一般存放在 “.git目录下” 下的index文件（.git/index）中，所以我们把暂存区有时也叫作索引（index）。 可以认为就是一个cache中间缓存 版本库：工作区有一个隐藏目录.git，这个不算工作区，而是Git的版本库。 我的理解：暂存区我们可以日常提交删除修改/取消修改（有相应的命令支持），branch一般就是我们最后提交，如果要求干branch的话，我觉得可能需要checkout到branch然后修改后再提交。 可以看出 版本库的概念包含了index（暂存区）objects（对象库），branch 图中左侧为工作区，右侧为版本库。在版本库中标记为 “index” 的区域是暂存区（stage, index），标记为 “master” 的是 master 分支所代表的目录树。 图中我们可以看出此时 “HEAD” 实际是指向 master 分支的一个”游标”。所以图示的命令中出现 HEAD 的地方可以用 master 来替换。 图中的 objects 标识的区域为 Git 的对象库，实际位于 “.git/objects” 目录下，里面包含了创建的各种对象及内容。 当对工作区修改（或新增）的文件执行 “git add” 命令时，暂存区的目录树被更新，同时工作区修改（或新增）的文件内容被写入到对象库中的一个新的对象中，而该对象的ID被记录在暂存区的文件索引中。 当执行提交操作（git commit）时，暂存区的目录树写到版本库（对象库）中，master 分支会做相应的更新。即 master 指向的目录树就是提交时暂存区的目录树。 当执行 “git reset HEAD” 命令时，暂存区的目录树会被重写，被 master 分支指向的目录树所替换，但是工作区不受影响。 当执行 “git rm –cached “ 命令时，会直接从暂存区删除文件，工作区则不做出改变。 当执行 “git checkout .” 或者 “git checkout – “ 命令时，会用暂存区全部或指定的文件替换工作区的文件。这个操作很危险，会清除工作区中未添加到暂存区的改动。 当执行 “git checkout HEAD .” 或者 “git checkout HEAD “ 命令时，会用 HEAD 指向的 master 分支中的全部或者部分文件替换暂存区和以及工作区中的文件。这个命令也是极具危险性的，因为不但会清除工作区中未提交的改动，也会清除暂存区中未提交的改动。 git 创建仓库首先创建一个目录，打开目录 cd /path/to/directory 然后初始化git init 会产生一个.git目录 使用指定目录：git init /path/to/directory git clonegit clone &lt;repo&gt; 克隆到指定目录 git clone &lt;repo&gt; /path/to/directory repo：git仓库 git 基本操作git init git clone git add : 将文件添加到缓存（也就是暂存区） git status:查看当前项目的状态 git status -s:状态的简短信息 A:该状态代表添加到缓存中去 AM:该状态代表添加到缓存中去后又有改动 git diff: 显示已经写入缓存和尚未写入缓存的改动的区别 git diff --cached:查看已缓存的改动 git diff HEAD: 查看已缓存的和未缓存的所有改动 git diff —stat: 显示摘要而非整个diff git commit: git add是将要快照的内容写入缓存区，git commit 是将缓存区的内容添加到仓库中——这里是我们语境中所说的提交 Git 为你的每一个提交都记录你的名字与电子邮箱地址，所以第一步需要配置用户名和邮箱地址。 12git config --global user.name &apos;liutao&apos;git config --global user.email &apos;123@163.com&apos; 我们使用 -m 来在命令行中提交注释 git commit -m &#39;第一次版本提交&#39; 如果觉得git add 提交缓存太过繁琐，直接通过git commit -a可以跳过这一步 跳过并添加评论 git commit -am &#39;修改xxx文件&#39; git reset HEAD：用于取消已经缓存的内容，也就是把暂存区的内容用原分支的内容替代 git rm 如果只是从工作目录中手工的删除文件，运行git status时就会有Changes not staged for commit的提示 要从git中移除某个文件，就必须要在已跟踪文件清单中移除，然后提交，也就是在git中移除然后提交，用以下命令完成 git rm &lt;file&gt;——工作区 暂存区 都删除 如果删除之前修改过并且已经放到暂存区域的话，必须用强制删除选项-f git rm -f &lt;file&gt; 如果把文件从暂存区删除，但仍希望保留在当前git目录中，换句话说，仅是从跟踪清单中删除，使用--cached即可 git rm --cached &lt;file&gt;——仅删除暂存区，工作区保留 递归删除用-r git mv: 用于移动或重命名一个文件、目录、软链接 想要在git下操作，所有命令前都要加一个git ps：touch命令 简单用法：touch &lt;file&gt; 如果没有该文件 会在当前目录下创建一个文件，有的话，改变文件的建立时间属性 git 分支管理创建分支命令 git branch &lt;branchname&gt; 切换分支命令 git checkout &lt;branchname&gt; 当我们切换分支的时候，git会用该分支的最后提交的快照替换你的工作目录的内容，所以多个分支不需要多个目录 合并分支命令 git merge 列出分支命令: git branch or git branch --list 前面带*的是我们当前所处的分支 当我们执行git init的时候，默认情况下git就会为你创建master分支 使用分支将工作切分开来，从而让我们能够在不同开发环境中做事，并来回切换。 删除分支命令 git branch -d &lt;branchname&gt; 分支合并命令 git merge 一旦某分支有了独立内容，你终究希望将它合并会你的主分支。可以使用上面命令合并到当前分支去 合并冲突 合并并不仅仅是简单的文件添加、移除的操作，git也会合并修改 合并冲突会有提示，如下 12345678910111213$ git merge change_siteAuto-merging runoob.phpCONFLICT (content): Merge conflict in runoob.phpAutomatic merge failed; fix conflicts and then commit the result.$ cat runoob.php # 代开文件，看到冲突内容&lt;?php&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEADecho 1;=======echo 'runoob';&gt;&gt;&gt;&gt;&gt;&gt;&gt; change_site?&gt; 我们将冲突手动修改后，需要add 并 commit提交，如下： 1234567$ git status -sUU runoob.php$ git add runoob.php$ git status -sM runoob.php$ git commit[master 88afe0e] Merge branch 'change_site' git 查看提交历史查看提交历史： git log git log --oneline 查看历史记录的简洁版本 git log --graph开启了拓扑图选项 git log --reverse 逆向显示所有日志 git log --author=TaoTaoUncle --onelin -5 只想查找指定用户的部分，后面的5是现实该用户的记录的显示个数 1$ git log --oneline --before=&#123;3.weeks.ago&#125; --after=&#123;2010-04-18&#125; --no-merges 如果你要指定日期，可以执行几个选项：–since 和 –before，但是你也可以用 –until 和 –after。 例如，如果我要看 Git 项目中三周前且在四月十八日之后的所有提交，我可以执行这个（我还用了 –no-merges 选项以隐藏合并提交） git 标签如果你达到一个重要的阶段，并希望永远记住那个特别的提交快照，比如发布版本，你可以使用 git tag 给它打上标签。 git tag -a &lt;tag&gt; 例如git tag -a v1.0 -a 选项意为”创建一个带注解的标签”。 不用 -a 选项也可以执行的，但它不会记录这标签是啥时候打的，谁打的，也不会让你添加个标签的注解。 我推荐一直创建带注解的标签。 当你执行 git tag -a 命令时，Git 会打开你的编辑器，让你写一句标签注解，就像你给提交写注解一样。 当我们执行 git log --decorate 时，我们可以看到我们的标签了 如果我们忘了给某个提交打标签，又将它发布了，我们可以给它追加标签。 比如： 123456789101112131415161718* d5e9fc2 (HEAD -&gt; master) Merge branch 'change_site'|\ | * 7774248 (change_site) changed the runoob.php* | c68142b 修改代码|/ * c1501a2 removed test.txt、add runoob.php* 3e92c19 add test.txt* 3b58100 第一次版本提交$ git tag -a v0.9 85fc7e7$ git log --oneline --decorate --graph* d5e9fc2 (HEAD -&gt; master) Merge branch 'change_site'|\ | * 7774248 (change_site) changed the runoob.php* | c68142b 修改代码|/ * c1501a2 removed test.txt、add runoob.php* 3e92c19 add test.txt* 3b58100 (tag: v0.9) 第一次版本提交 查看所有标签命令 git tag 指定标签信息命令： 1git tag -a &lt;tagname&gt; -m &quot;runoob.com标签&quot; PGP签名标签命令： 1git tag -s &lt;tagname&gt; -m &quot;runoob.com标签&quot; git 远程仓库目前我们使用到的 Git 命令都是在本地执行，如果你想通过 Git 分享你的代码或者与其他开发人员合作。 你就需要将数据放到一台其他开发人员能够连接的服务器上。 添加远程库添加后还要生成一个SSH key 具体操作可以谷歌或者看这里：git 远程仓库 创建成功后，会有如下显示： 以上信息告诉我们可以从这个仓库克隆出新的仓库，也可以把本地仓库的内容推送到GitHub仓库。 先要remote add，才能够git push，remote add相当于本地和远程的repo建立了关系 123# 提交到 Github$ git remote add origin git@github.com:tianqixin/runoob-git-test.git$ git push -u origin master git push命令用于将本地分支的更新，推送到远程主机。它的格式与git pull命令相仿。 1`$ git push &lt;远程主机名&gt; &lt;本地分支名&gt;:&lt;远程分支名&gt;` 注意，分支推送顺序的写法是&lt;来源地&gt;:&lt;目的地&gt;，所以git pull是&lt;远程分支&gt;:&lt;本地分支&gt;，而git push是&lt;本地分支&gt;:&lt;远程分支&gt;。 如果省略远程分支名，则表示将本地分支推送与之存在”追踪关系”的远程分支(通常两者同名)，如果该远程分支不存在，则会被新建。 1`$ git push origin master` 上面命令表示，将本地的master分支推送到origin主机的master分支。如果后者不存在，则会被新建。 如果省略本地分支名，则表示删除指定的远程分支，因为这等同于推送一个空的本地分支到远程分支。 1`$ git push origin :master``# 等同于``$ git push origin --delete master` 更多详细的部分请看： git push参数 查看当前的远程库 git remote 执行时加上 -v 参数，你还可以看到每个别名的实际链接地址。 bug解决： ![rejected] master -&gt; master (fetch first) If you want to solve, fetch first (and then merge). If you want to hack, use the --force option. 详见stack overflow 提取远程仓库Git 有两个命令用来提取远程仓库的更新。 1、从远程仓库下载新分支与数据： 1git fetch 该命令执行完后需要执行git merge 远程分支到你所在的分支。 2、从远端仓库提取数据并尝试合并到当前分支： 1git merge 该命令就是在执行 git fetch 之后紧接着执行 git merge 远程分支到你所在的任意分支。 假设你配置好了一个远程仓库，并且你想要提取更新的数据，你可以首先执行 git fetch [alias] 告诉 Git 去获取它有你没有的数据，然后你可以执行 git merge [alias]/[branch] 以将服务器上的任何更新（假设有人这时候推送到服务器了）合并到你的当前分支。 推送到远程仓库推送你的新分支与数据到某个远端仓库命令: git push &lt;alias&gt; &lt;branch&gt; 上命令将你的 [branch] 分支推送成为 [alias] 远程仓库上的 [branch] 分支，实例如下。 12345678$ touch runoob-test.txt # 添加文件$ git add runoob-test.txt $ git commit -m &quot;添加到远程&quot;master 69e702d] 添加到远程 1 file changed, 0 insertions(+), 0 deletions(-) create mode 100644 runoob-test.txt$ git push origin master # 推送到 Github 删除远程仓库1git remote rm &lt;alias&gt;]]></content>
      <categories>
        <category>201910</category>
      </categories>
      <tags>
        <tag>Note</tag>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo+github创建博客]]></title>
    <url>%2F2019%2F10%2F02%2Fhexo-github%E5%88%9B%E5%BB%BA%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[hexo + github 创建博客首先hexo是一款博客框架，而github知识用来托管我们本地文件的 基本的逻辑就是，我们在本地用hexo搭建好博客，与github建立连接，然后托管到github上 具体的方法看知乎： GitHub+Hexo 搭建个人网站详细教程 简单说下自己的坑 yml语法非常严谨，配置时 冒号:后面一定要有一个空格 分清楚站点配置文件和主题配置文件，各自操作对应各自文件 在建立博客时，建议首先在本地预览，没有问题后然后再托管到github page上 因为托管到github page后看效果需要一段时间同步，本地则是实时的 主题的选取和配置我都是按着教程里来的，使用的next主题。具体的配置网上也有相关的文档可以查看。 简单的几个命令： 每次要托管前：下面的4个命令都是在blog文件夹下使用的，也就是和source同一级 sudo hexo clean：清除缓存 sudo hexo g：生成(generate) sudo hexo s:在本地(server)预览，具体是浏览器中输入localhost:4000 预览后没有问题，部署(deploy)到github page上： sudo hexo d 创建新的md文件：hexo new “blog_name” 创建新的页面：hexo new page “page 名称” 关于categories 和 tags page的个性化： 需要在配置文件中进行配置，选取FontAwesome 图标等，详看上面的知乎博客 然后在page的md文件中加上”type: categories” / “type: tags” 在对应的blog的md文件中开头的部分填写各自的 tags &amp; categories 详情看这里：hexo设置 关于 标签 分类 归档]]></content>
      <categories>
        <category>201910</category>
      </categories>
      <tags>
        <tag>Build</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Algorithm_Start_2019Fall]]></title>
    <url>%2F2019%2F09%2F29%2FAlgorithm_Start_2019Fall%2F</url>
    <content type="text"><![CDATA[数据结构和算法 Hash表 首先哈希表是散列表，和直接寻址表是两个定义范畴，相互独立 这里我们只讨论hash表相关知识 Hash表是根据关键码值key-value而直接进行访问的数据结构。 具有关键字k的元素被存储在槽k中 痛殴关键码值映射到表中一个位置来访问记录，加快查找速度。 主要是两个部分哈希函数和冲突解决 哈希函数——由关键字k计算出槽位置， 也就是！！！将关键字转换为自然数 对于哈希函数我们希望： 同一性：输出尽量均匀 雪崩效应：输入值微小变化，对应输出值巨大变化 冲突——两个/多个关键字映射到同一个槽上 冲突解决——链接法和直接寻址法 链接法 n个元素，m个槽位的散列表T，装载因子α定义为n/m，也就是平均一个槽装多少个元素 最坏情况：一个链表，查询时间复杂度O(n) 散列方法的平均性能依赖于所选取的散列函数h，将所有关键字结合分布在m个槽位上的均匀程度。 等可能地散列：简单均匀散列 越均匀，性能越好 链接法中使用的散列函数 除法散列法——需要一个超参数m 取k除以m的余数，即k mod m，只需做一次除法操作，还是非常快的 m不应为2的幂，如果m为2的幂，那么h(k)就是k的p个最低位数字（二进制移位运算），这样只依赖于低位字，理想情况是依赖于全部位 一个不太接近2的整数幂的素数，常常是m的一个较好的选择 乘法散列法——需要两个超参数m 和 A 第一步：用关键字k呈上常数A（0&lt;A&lt;1)，提取kA的小数部分 第二步：用m乘以这个值，再向下取整 h(k) = 向下取整(m(kAmod1)) 优点：m的选择不是那么关键，一般取2的某个幂次 一般取A为黄金比例0.618… （根号5-1）/2 全域散列法 设计一个精心的散列函数类， 执行开始时，先从一组函数中随机的选择一个作为散列函数，这样的随机化保证了平均性能 开放寻址法 注意，开放寻址法可以查找和插入，但是删除需要引入DELETED值，这样的话查找时间不再依赖于装载因子，所以在必须删除关键字的应用中，我们更倾向于使用链接法来解决冲突 简介： 所有的元素都在散列表中，每一个表项或包含动态集合的一个元素，或包含NIL。这种方法中散列表可能被填满，以致于不能插入任何新的元素 我们这里与链接法中的链表相类似的是，我们这里会采用探查序列，而这个序列不像链表，不依赖于指针，而是依赖于散列函数 所以，不需要存储指针 可以用更多的内存来充当槽 通过散列函数实现探查序列 散列函数作为一对一的关系实现探查序列，我们需要引入另一个序列量——探查号0-m-1 对每一个关键字k，我们的对应的探查序列是： $ &lt;h(k,0), h(k,1),…,h(k,m-1) &gt;$ 这样就如同链表 我们有了一个顺序的查找和插入序列 开放寻址法 的三种操作 插入时，先通过k获得k，根据0-m-1得排列取找寻一个h(k,.)的空位，然后插入 查找时，如果碰到空槽，就非成功地停止，因为如果有就是在这里（假定插入后不删除），或者到最后也没找到，说明序列已满，并且不存在 删除比较麻烦，而且使用特殊的值DELETED后，查找时间不再依赖于装载因子。 均匀散列：每个关键字的探查序列 等可能地为 &lt;0,1…m-1&gt;的m!排列的任何一种 注意！！！序列内容不变，只是顺序变了而已 一个超参——m 线性探查 linear probing 给定一个普通的散列函数h’，称之为辅助散列函数。 则线性探查方法采用的散列函数为： h(k,i) = (h’(k) + i) mod m i = 0,1.. m 先探查T[h’(k)] 然后+1 直 到 T[m-1] 然后绕到T[0] T[1] 最后探查T[h’(k)-1] 初始探查位置决定了整个序列，故有m种，而初始探查位置是由辅助散列函数h’(k)决定的 原因： 这里的i是用来 决定探查序列的起始位置，一共m个i，共有m个起始位置，针对每一个起始位置，都是同样的顺序查找，所以只有1种，mx1共m种 问题：一次群集， 连续被占用的槽的序列变的越来越长 这样会导致平均查找时间也不断增加 连续序列越长，冲突的可能型越大，这样我们后面新来的值的序列的前几号都冲突的话，就需要从比较大的号开始存储，这样意味着查找这个值的时候，前面的序列号都要走一遍，因为都是冲突的 可以这样理解，连续占用会导致不同数字前面的槽冲突，这样后续每个数字的探查序列的前几个都是无效，大大增加了查找时间 二次探查 散列函数：h(k,i) = $(h’(k)+c1i+c2i^2 ) mod$ m 后续的探查位置枷是一个二次的偏移量，如果两个关键字的位置相同，那么它们的探查位置也是相同的，这一性质会导致一种轻度的群集，成为二次群集，而且出事探查位置决定了整个序列，所以也仅有m个 二次群集是一种较为轻度的群集， 双重散列——用于开放寻址法的最好的方法之一 $h(k,i) = (h$1$(k)+ih$2$(k))$ mod m 这里的探查序列以两种不同方式依赖于关键字k，初始探查位置，偏移量或者二者都可能发生变化。 为了能查找到所有的位置，值h2必须与m互素 确保这个条件成立的简单方法： 取m为2的幂，并设计一个总产生奇数的h2， 另一种取m为素数，并设计一个总是返回较m小的正整数的h2 有$m^2$种，但只会用到m种 再散列（rehashing） 如果散列表满了，再往散列表中插入新的元素时候就会失败。这个时候可以通过创建另外一个散列表，使得新的散列表的长度是当前散列表的2倍多一些，重新计算各个元素的hash值，插入到新的散列表中。再散列的问题是在什么时候进行最好，有三种情况可以判断是否该进行再散列： （1）当散列表将快要满了，给定一个范围，例如散列表中已经被用到了80%，这个时候进行再散列。 （2）当插入一个新元素失败时候，进行再散列。 （3）根据装载因子（存放n个元素的、具有m个槽位的散列表T，装载因子α=n/m，即每个链子中的平均存储的元素数目）进行判断，当装载因子达到一定的阈值时候，进行在散列。 在采用链接法处理碰撞问题时，采用第三种方法进行在散列效率最好。 STL中hash_map扩容发生什么？ (1) 创建一个新桶，该桶是原来桶两倍大最接近的质数(判断n是不是质数的方法：用n除2到sqrt(n)范围内的数) ；(2) 将原来桶里的数通过指针的转换，插入到新桶中(注意STL这里做的很精细，没有直接将数据从旧桶遍历拷贝数据插入到新桶，而是通过指针转换)(3) 通过swap函数将新桶和旧桶交换，销毁新桶。 树 定义 123456struct Tree&#123; int value; Tree* pLeft; Tree* pRight;&#125;typedef Tree* binaryTree; 三种遍历递归 1234567891011121314151617181920212223void preOrder(binaryTree T)&#123; if(T==NULL) return; cout &lt;&lt; T-&gt;value &lt;&lt; endl; preOrder(T-&gt;pLeft); preOrder(T-&gt;pRight);&#125;void inOrder(binaryTree T)&#123; if(T=NULL) return; inOrder(T-&gt;pLeft); cout &lt;&lt; T-&gt;value &lt;&lt; endl; inOrder(T-&gt;pRight);&#125;void postOrder(binaryTree T)&#123; if(T==NULL) return; postOrder(T-&gt;pLeft); postOrder(T-&gt;pRight); cout &lt;&lt; T-&gt;value &lt;&lt; endl;&#125; 三种非递归遍历——用栈来实现 非递归实现前序遍历： （1）将根节点压入栈；（2）弹出栈顶元素，打印栈顶元素的值，如果该元素的右子树不为空，则先将右子数压 入栈，如果该元素的左子树也不为空，则将该元素的左子树也压入栈；（3）重复步骤2直到栈为空。 12345678910111213141516void preOrder(binaryTree T)&#123; if(T==NULL) return ; stack&lt;binaryTree&gt; S; S.push(T); while(!S.empty())&#123; binaryTree tmpNode = S.top(); S.pop(); cout &lt;&lt; tmpNode-&gt;value &lt;&lt; endl; //first push right subtree ,then push left subtree if(tmpNode-&gt;right!=NULL) S.push(tmpNode-&gt;right); if(tmpNode-&gt;left!=NULL) S.push(tmpNode-&gt;left) &#125;&#125; 非递归实现中序遍历： （1）定义一个当前节点，将根节点指针赋给当前节点；（2）如果当前节点不为空，就将当前节点压入栈，并将当前节点更新为其左子树；（3）如果当前节点为空，就弹出栈顶元素，并打印该元素值。然后将当前节点更新为该元素值的右子树；（4）一直重复（2）或（3）直到栈为空而且当前元素值也为空 123456789101112131415161718void Inorder(binaryTree T)&#123; if(T==NULL) return; stack&lt;binaryTree&gt; S; binaryTree tmpNode = T; S.push(T); while(!S.empty()&amp;&amp;!tmpNode)&#123; if(tmpNode==NULL)&#123; tmpNode = S.top()-&gt;right; cout &lt;&lt; S.top()-&gt;value; S.pop(); &#125; else&#123; tmpNode = tmpNode-&gt;left; S.push(tmpNode); &#125; &#125;&#125; 非递归实现后序遍历： （1）定义两个栈S1和S2，S1作为临时存储，S2作为最终输出数据存储，将根节点指针 压入S1； （2）从S1弹出栈顶元素，将该元素压入S2，将S1不为空的左右子树压入S1； （3）重复2过程直到S1为空为止； （4）最后依次弹出S2的数据，并打印就是后序遍历的结果。 1234567891011121314151617181920void postOrder(binaryTree T)&#123; if(T==Null) return; stack&lt;binaryTree&gt; S1; stack&lt;binaryTree&gt; S2; S1.push(T); while(!S1.empty())&#123; binaryTree tmpNode = S1.top(); S2.push(tmpNode); S1.pop(); if(tmpNode-&gt;left!=NULL) S1.push(tmpNode-&gt;left); if(tmpNOde-&gt;right!=NULL) S1.push(tmpNode-&gt;right); &#125; while(!S2.empty())&#123; cout &lt;&lt; S2.top()-&gt;value &lt;&lt; endl; S2.pop(); &#125;&#125; 层序遍历二叉树 BFS 队列：尾入头出 （1）将二叉树的根从头部压入队列（2）从队列尾部弹出一个元素，打印该元素值，然后将如果该元素左子树不为空，则将 该元素的左子树从头部压入队列，右子树相同的操作；（3）重复过程2直到队列为空。 123456789101112131415void floorOrder(binaryTree T)&#123; if(T==NULL) return; deque&lt;binaryTree&gt; Q; Q.push_back(T); while(!Q.empty())&#123; binaryTree tmpNode = Q.front(); cout &lt;&lt; tmpNode-&gt;value &lt;&lt; endl; Q.pop_front(); if(tmpNode-&gt;left!=NULL) Q.push_back(tmpNode-&gt;left)； if(tmpNode-&gt;right!=NULL) Q.push_back(tmpNode-&gt;right); &#125;&#125; 在树中一定要好好利用递归——解决二叉树相关问题的神级方法 树的各种算法题 什么是红黑树 红黑树是一棵二叉搜索树，每个结点增加了一个存储位来表示结点颜色，RED or BLACK，通过对任何一条从根到叶子的简单路径上的各个结点的颜色进行约束，确保没有一条路径会比其他路径长出两倍，近似于是平衡的。 性质 1.每个结点是红 or 黑 2.根结点是黑色 3.叶结点是黑色（NIL）——这里的叶结点是指最后的左右空指针 4.红色结点的两个子结点是黑色 5.对每个结点，从该结点到其他后代叶结点的简单路径上，均包含相同数目的黑色结点 使用一个哨兵T.nil来代替所有NIL 节省空间 一般我们把有关键字的非NIL结点成为内部结点，这是我们所关心的部分 从某个结点x出发（不含该结点）到达任意一个叶结点的简单路径上的黑色结点个数称为黑高。 红黑树的黑高为根结点的黑高 一棵n个内部结点的红黑树的高度至多为2lg(n+1) 旋转 INSERT DELETE操作可能违反红黑树的性质，这里需要旋转操作来维持这些性质 右旋 左旋——O(1)时间内完成，只有指针改变，其他所有属性不变 插入 可以证明在O(lgn)时间内完成 插入结点 颜色属性为红色 利用二叉搜索树的插入TREE-INSERT之后调用一个辅助程序INSERT-FIXUP来对结点重新着色并旋转 分析： TREE-INSERT插入红色结点后 哪些性质不能保持 只有两种情况： 1.z是根结点，破坏了性质2 2.z的父结点是红色，破坏了性质4 我们保证我们当前的指向的结点z颜色是红色，所以我们循环的条件就是z.p.color==RED，因为这样破坏了性质4 分情况操作： 父结点是右孩子和左孩子是对称的，所以我们这里只讨论父结点是左孩子的情况，右孩子的代码就是把右孩子中的left和right调换一下 情况一：叔结点是红色，爷肯定是黑色，那么叔 爸 变黑 爷变红，指针指到爷，在进行下一轮循环（符合z是红） 情况二：叔结点是黑色，如果z是右孩子，z上升为爸并左旋，否则不左旋，然后将爸变成黑色，爷变成红色，然后右旋。 红黑树和AVL树的区别 Trie树（字典树） 链表 链表的插入和删除，单向/双向链表 链表的问题考虑多个指针和递归 (1) 反向打印链表(递归) (2) 打印倒数第K个节点(前后指针) (3) 链表是否有环(快慢指针)等等。 栈和队列 队列和栈的区别？(从实现，应用，自身特点） 队列先进先出，栈后进先出 队列是一端 插入另一端删除，栈是单端插入删除 遍历数据速度不同 栈遍历时需要将元素取出，需要开辟临时空间，速度慢，而且只能从栈顶遍历 而队列不同，基于地址指针无需开辟临时空间，速度快，可以两端遍历但不能同时遍历 典型的应用场景 栈 符号匹配 在编译器的语法检查中，一个过程就是检查各种括号是否匹配，比如 ([]) ，这就是匹配的，而 {[}] 就不匹配了。可以用堆栈来实现括号匹配。 具体算法如下： 123456789101112建立一个空的堆栈。 while( 文件没有结束 ) &#123; 读取一个字符。 if 遇到一个左括号，把它入栈。 else if 遇到右括号 then 检查堆栈，&#123; if 堆栈为空 then 报告错误，终止程序（括号不匹配）。 else if 堆栈非空 then &#123; if 栈顶不是对应的左括号 then 报错，终止程序。 弹出栈顶。 &#125; &#125; if 栈非空 then 报错。 计算代数式 如果我们要计算 6 + 4 * 8 ，要考虑到优先级的问题，这时候就可以用到堆栈了。 先要把代数式构造成 6 4 8 * + （构造方法也是用堆栈，在下一条会讲到）。逐个读取数据，当读到数字时， 把数字入栈， 读到运算符时，弹出栈中的两个元素（因为这里的是二元运算符，所以弹出两个，如果是sin等一元运算符就弹出一个），根据读取 的运算符执行运算，把结果压入栈中，然后继续读取数据，读取结束后栈顶元素就是结果。 比如读取6，4，8，由于是数字，所以依次入栈， 读到 “*” 时，弹出 4 和 8，相乘得到 32，把32入栈。读到 “+” 时， 弹出 6 和 32 ，执行运算得到 38，压入栈中，接着读取结束，栈顶的 38 就是结果。 构造表达式 比如一个正常的代数式（叫他infix）, a + b * c + ( d * e + f ) * g , 转化成表达式 a b c * + d e * f + g * +, 这个表达式我们叫他 postfix。 123456789101112131415创建一个字符串output储存 postfix。创建一个空栈 operators。while ( ) 逐个读取 infix 中的元素，储存在 temp 中。 if temp 是数字（operand）then 把 temp 压入 output 字符串。 if temp 是除了右括号 &quot;)&quot; 之外的运算符（operator） if operators 栈空 then temp 入栈。 if operators 栈非空， while ( 栈顶元素优先级大于或等于 temp 并且 栈顶元素不等于左括号 ) 弹出栈顶元素到 output 。 if temp 是右括号 &quot;)&quot; while ( 栈顶元素不等于左括号 ) 弹出栈顶元素到 ouput. 弹出左括号, 但是不输出到 output 函数调用 队列： 先来先服务的应用 比如——多个用户要访问远程服务端的文件时，比如多个打印机任务 海量数据问题 十亿整数（随机生成，可重复）中前K最大的数 十亿整数（随机生成，可重复）中出现频率最高的一千个 位运算 技巧一： 对于正整数，左移一位，就是将数值乘2；右移一位就运算数值除2；但是位操作的效率要比运算符高。 技巧二： 一个数和另一个数异或两次得到的还是原来的数 题：不用临时变量交换两个整数。 123a = a ^ b;b = a ^ b;a = a ^ b; 技巧三： n &amp; (n - 1)将整数n的最后一位为1的位变成0 题：统计一个整数中二进制位上1的个数。 12345678910int fun(int num)&#123; int count = 0; while(num) &#123; num = num &amp; (num - 1); ++count; &#125; return count；&#125; 题：判断一个数是不是2的幂。 12345//返回0表示是2的幂，返回非0值表示不是2的幂int fun(int num)&#123; return n &amp; (n - 1);&#125; 解析：如果一个数是2的幂，则其有且只有一位为1。因此，消除这一位后就会变成0 题：判断一个32位整数是不是4的幂 123456789//返回0表示不是4的幂，返回非0表示是4的幂int fun(int num)&#123; if(!(n &amp; (n - 1))) &#123; return (n &amp; 0x55555555); &#125; return 0;&#125; 题：输入两个整数m和n，计算需要改变多少位能使m变成n 12345678910111213int fun(int m, int n)&#123; //将m和n按位异或，相同的位为0，不同的位为1 m = m ^ n; int count = 0; //统计不同的位有多少个就ok while(m) &#123; m = m &amp; (m - 1); ++count; &#125; return count；&#125; 技巧四 n &amp; (~n + 1)提取出整数n最后一位为1的数 举例：n = 01101，n是将n按位取反就是10010，n + 1 = 10011，最后，n &amp; (~n + 1) = 00001 题：统计一个整数中二进制位上1的个数。 12345678910int fun(int num)&#123; int count = 0; while(num) &#123; n -= n &amp; (~n + 1); ++count; &#125; return count；&#125; 技巧五： 不使用+，-，*，/完成整数相加 123456789101112131415int Add(int num1, int num2) &#123; int sum, carry; do&#123; //将两个数异或，模拟加法中相加不进位的结果 sum = num1 ^ num2; //只考虑进位的情况 carry = (num1 &amp; num2) &lt;&lt; 1; num1 = sum; num2 = carry; &#125; while(num2 != 0); //将结果相加的过程就重复上述过程，直到进位为0 return sum; &#125; #]]></content>
      <categories>
        <category>201909</category>
      </categories>
      <tags>
        <tag>Note</tag>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[剑指offer_201904]]></title>
    <url>%2F2019%2F09%2F29%2F%E5%89%91%E6%8C%87offer_201904%2F</url>
    <content type="text"><![CDATA[剑指 offer总结： 需要补充的知识点 几种经典的排序算法，先重点掌握二分查找，归并排序，快速排序，然后桶排序/堆排序/插入排序/冒泡排序。 堆 哈希表(散列表) 进一步：红黑树 B+树 C++内存管理的部分 经验总结： 先思考 再动手 一定要思考清楚全面周到后再开始动笔/手 好的代码命名 规范的缩进习惯 测试在前 ——1.测试用例 2.对所有输入考虑全面 代码更鲁棒 调试能力——有时间学习一下gdb lldb 审题很重要，题意理解一定要到位 好好想清楚，是否用 指针 引用 是否要加const 注意 new一定要和delete 配对，除非在不需要delete的情况下 核心功能可以单独写个函数，更加模块化，比如functionCore()这样 在创建一个功能函数时，我们一定要想好入口参数，是指针还是变量，是拷贝还是引用，选择最优的最可读性的方案。 第一章 面试的流程 扎实的基础知识 c++相关的书籍再看 高质量代码——边界条件 特殊输入 鲁棒性的代码着很重要 思路一定要清晰 要求我们一定要想好再动笔 不要考虑的混混沌沌 这样写起代码来磕磕绊绊 而且往往是错的 优化的能力——追求极致的性能 空间和时间效率的权衡，空间换时间（一般是），空间/时间复杂度的分析能力，可以提出更加优化的算法 良好的沟通合作能力，精神面貌，着很重要 个人提问环节，该问的问，不该问的千万别问 第二章 面试需要的基础知识面试题一：赋值运算符函数 看看书上添加赋值运算符的操作 再回来看这道题目 面试题二：实现singleton模式 这个书上没有c++的部分 去网上查找学习 数据结构：数组 字符串 链表 树 栈 队列 ​ 数组/字符串 连续内存存储 ​ 链表和树 会涉及大量的指针操作 好好考虑边界条件 ​ 栈和递归紧密联系 队列和BFS紧密联系 数组/字符串 连续内存顺序存储 需要实现指定数组大小/分配内存 所以空间效率不是很好 可以用来构建简单的哈希表 下标和数组内容对应键-值对 哈希表查找只需要O(1)的时间复杂度 动态数组vector：每次开辟空间都是原来的两倍，分配更大的空间，然后将原空间的内容拷贝过去，所以vector扩容会有大量的额外操作 使用指针或者下标访问数组，确保没有超过数组的边界用指针超过边界会有不确定的结果，用下标则会直接报错 数组作为函数的参数进行传递时，数组就自动退化为同类型的指针 面试题三：数组中重复的数字 长度为n的数组里所有数字都在0～n-1的范围内。数组中某些数字是重复的，但不知道几个数字重复，也不知道重复几次，找出数组中任意一个重复的数字 法一：使用哈希表 时间复杂度O(n)，空间复杂度O(n) 法二：扫描交换 思路：如果0-n-1没有重复，重新排序后，数组值和对应下标值一样。有重复，那么有的位置会有多个数字 有的位置没有数字 思路： 从头到尾扫描数组 如果数组值m和下标值n相同，扫描下一个 如果数组值m和下标值n不同 则交换下标m和下标n的值，还是从该下标开始并重复上述操作，如果下标m和下标n的值相同返回 注意：每个数字最多交换两次就能找到属于它自己的位置 题目二：不修改数组找出重复的数字 长度为n+1的数组里的所有数字在1-n的范围内 注意和面试官沟通需求，能不能修改原数组，这涉及到是否要重新开辟O(n)的空间，能不能使用辅助内存，最终要求的细化，是要得到所有的重复数字以及重复次数还是说只要得到任意一个重复的数字即可。 法一：使用哈希表，空间复杂度O(n)时间复杂度O(n) 法二：使用二分查找，空间复杂度O(1),时间复杂度O(nlogn) 数字在1-7之间 统计1-4的数字出现次数 (统计一次需要O(n)的时间复杂度） 然后如果大于4那么再一分为二统计其一，否则在5-7之间一分为二继续统计 统计logn次 每次O(n)，总共O(nlogn) 面试题4:二维数组中的查找 在一个二维数组中，每一行都是按照从左到右递增的顺序排序，每一列都按照从上到下递增顺序排列，请完成一个函数，输入这样的一个二维数组和整数，判断数组中是否含有该整数 可以使用强制类型转换把(int**)转换成 指向整数的指针，这样就可以把二维整数数组转换成了一维整数数组 规律的找寻： 从右上角或者左下角开始进行比较，大于小于对应删除一行或者一列，当然这里不是指删除而是查找范围的确定 字符串 常用：c风格的字符串 和 string对象 c风格的字符串结尾会有一个’\0’，所以在声明数组大小时计算进入该字符，否则会造成越界 常量字符串会放到一个单独的内存区域，当几个指针赋值给相同的常量字符串时，它们实际上指向相同的内存地址 但用常量内存初始化数组，有所不同 面试题五：替换空格 请实现一个函数，把字符串中的每个空格替换成”%20” 首先确定需求，是否可以在原来的字符串上进行替换，并保证输入的字符串后面有足够多的空余内存，否则我们需要开辟O(n)的空间。以及是否有字符串最长的长度限制。因为替换后的字符串可能会很长 超越限制 关于遍历的终止条件，一般字符串是 ‘\0’,string貌似也可以是’\0’，也可通过size()方法获得其长度 方法：首先遍历一遍，得到空格个数然后计算替换后的长度，将p2定义为替换后的长度，p1定义原先的长度，遇到空格就向前替换 否则替换对应字符，并做相应的剑法操作 直至两个index相同 对内存覆盖要有高度的警惕 相关的题目：有两个排序的数组A1和A2，内存在A1的末尾有足够多的空余空间容纳A2。请实现一个函数，把A2中的所有数字插入A1中，并且所有的数字是排序的。 方法：从尾到头比较A1和A2的数字，并把较大的数字复制到A1中合适的位置 举一反三：在合并两个数组（包括字符串）时，如果从前往后复制每个数字（或字符）则需要重复移动数字（或字符）多次，那么我们可以考虑从后往前复制，这样就能减少移动的次数，从而提高效率 链表 我们说链表是一种动态数据结构，是因为在创建列表时，无需知道长度，插入结点时，只需要为新结点分配内存，然后调整指针指向 内存分配不是一次性完成的，而是每添加一个结点分配一次内存。由于没有闲置的内存，所以空间效率高。但是时间效率较低 注意 在链表的结点插入过程中，函数额第一个参数pHead时一个指向指针的指针。当我们往一个空链表中插入一个结点时，新插入的结点就是链表的头指针。由于此时会改动头指针，因此必须把pHead参数设为指向指针的指针，否则除了这个函数pHead仍然是一个空指针 遍历链表的时间复杂度为O(n) 链表的变体： 末尾结点指针指向头结点，形成环形链表 双向链表 复杂链表：除了指向下一个结点的指针，还有指向任一结点的指针 面试题六：从尾到头打印链表 输入一个链表的头结点，从尾到头反过来打印出每个结点的值 法一：将列表反转再将其从头到尾打印，但是这样的话改变了原有列表 法二：类似于后进先出的行为，我们考虑使用栈stack来存储，然后在pop()打印 由于栈和递归联系紧密，所以这时我们也可以使用递归的方式来完成该题目，但是递归可能会导致溢出，基于循环的代码鲁棒性更高 树 大部分都是二叉树，操作会涉及大量指针 关于三种遍历：（前中后指的是’根’的位置，左都是在右前面） 前序遍历：根 左 右 中序遍历：左 根 右 后序遍历：左 右 根 我们可以根据与题目的契合度 相应的改变 比如 右根左 虽然上述三种遍历访问次序不同，但是访问路径相同 用递归实现遍历比用循环实现遍历简洁的多 还有一种BFS遍历：使用队列 二叉树有很多特例 二叉搜索树：左子结点总是小于或等于跟结点，右子结点总是大于或等于根结点。可以平均以O(logn) 的时间内找到一个结点 堆：最大堆 最小堆，最大堆中根结点最大 最小堆根结点最小 许多快速寻找最大最小值的问题可以用堆来解决 红黑树，把结点定义为红黑两色，通过规则确保从根结点到叶结点的最长路径的长度不超过最短路径的两倍 set multiset map multimap 都是基于红黑树实现的 面试题七：重建二叉树 输入某二叉树的前序遍历和中序遍历的结果，重建该二叉树，假设输入的前序遍历和中序遍历的结果中都不含重复的数字。 思路： 前序遍历的第一个肯定是根结点 可以据此从中序遍历中得到根结点位置，那么就可以分别得到左子树的前序遍历 中序遍历 和右子树的的前序遍历 中序遍历 这样就可以不断递归 递归的起始处 创建根结点 终止处创建叶子节点 完成二叉树的构建 递归：先创建根结点 再左右递归 边界条件和输入非法情况的考虑 初始化指针如果不确定值的话，可以初始化为nullptr 面试题八：二叉树的下一个结点 给定一棵二叉树和其中的一个结点，如何找出中序遍历序列的下一个结点。树中的结点除了有两个分别指向左右子节点的指针，还有一个指向父结点的指针 思路：首先中序遍历是左根右，其次我们需要确定当前给定节点的性质/状态来进行下一步的操作 以是否有右子树作为区分 如果有右子树，右子树的最左结点，如果没有右子树，是左子结点返回父结点，如果没有，向上找父结点直至为左子结点，返回该左子结点的父结点，如果到顶也没有，则没有下一个结点。 栈和队列 栈：先进后出 队列：后进后出 注意：数据结构的特性都是有对应的应用场景，在合适的场景下应用对应的数据结构是高效的，这是在其源代码的实现中确定了的，所以一定要根据应用场景选取对应的数据结构，这很重要 栈：操作系统会给每个线程创建一个栈用来存储函数调用时各个函数的参数、返回地址及临时变量等。 栈不考虑排序，min/max需要遍历一次O(n)。除非做特殊设计，牺牲某一方面来换取 面试题九：用两个栈实现队列 实现队列的两个函数appendTail和deleteHead，分别完成在队列尾部插入结点和在队列头部删除结点的功能，队列是尾进头出 辅助栈的使用，有的时候一个不行，用两个或者多个，一般两个/一个辅助足矣 思路：使用两个栈A和B，插入时，直接插入A栈，删除时，如果B栈不为空，直接弹出，如果为空，将A栈所有元素入B栈在弹出。可以通过画图来证明该方法的可行性。 相关题目：用两个队列实现一个栈 思路：使用两个队列A和B，插入时，插入A队，删除时，将A队里的n-1一个元素插入B队，然后删除A队最后一个，这样A队空，再插入时，插入非空的队。 递归和循环的选择，递归往往更简洁，循环往往效率更高。复杂度相同的情况下，在允许递归层数的情况下，可以选用递归。但是如果递归的复杂度更高，即会出现重复计算的情况，我们还是要使用循环，降低复杂度。 同时，栈可以模拟递归 二维数组的路径搜索可以考虑回溯法，而回溯法很适合用递归来实现，如果明确不能用递归，可以用栈模拟递归 求某个问题的最优解，并且问题可以分为多个子问题，可以尝试动态规划，如果自上而下子问题会有重叠，我们可以使用自下而上的循环代码来实现 如果在分解子问题时，每一步的子问题都有特殊选择，并且每一步的特殊选择能保证最终的最优解，那么该面试题适用贪心算法。 位运算：可以看作一类特殊的算法，基本上有 与 或 异或 左移 右移 5种位运算，可以从这五种中去寻找解题办法 面试题十：斐波那契数列 主要是找到斐波那契数列的规律： $ f(0) = 0$ $ f(1) = 1$ $ f(n) = f(n-1)+f(n-2) ​$ 如果自上而下计算$f(n)$，会有重复计算，效率很低 所以我们用自下而上的循环，从$f(2)$开始计算直至我们需要的结果 斐波那契数列很容易扩展，我们要意识到这是个斐波那契 比如青蛙跳台阶的问题，矩形覆盖问题 从斐波那契数列我们也可以联想到使用递推公式的解决方案。 但是初始值可能会有不同，需要思虑周全 青蛙跳台阶问题扩展：每次可以跳1-n级，共有多少种跳法？ ——用数学归纳法证得$f(n) = 2^{n-1}$ 查找和排序 查找不外乎 顺序查找、二分查找、哈希表查找和二叉排序树查找 哈希表可以O(1)时间查找但是需要辅助内存。 员工年龄排序，用一个辅助数组保存0-100年龄段中的出现次数（哈希表的办法），相当于是排序了。。 面试题11 旋转数组的最小数字 题目：把一个数组的最开始的若干个元素搬到数组的末尾，我们称之为数组的旋转。输入一个递增排序数组的一个旋转，输出旋转数组的最小元素。 思路：排序数组一般对应二分查找，时间复杂度为O(logn) new两个指针分别指向数组头和尾，判断中间指针是位于前面的递增子数组还是后面的递增子数组，然后将头指针/尾指针更新为中间指针，知道最后两个指针相邻，第二个指针即为我们最后的答案。 两种特例：一种是旋转了0个数字，也就是仍是排序的数组，这时候我们初始化最终的index为首地址，如果发现首地址的值小于尾地址的值，可以认为是一个排过序的数组，直接返回首地址的字符 另一个是中间指针 头指针 尾指针 值相同的情况，这时候我们需要顺序遍历 回溯法 可以看作蛮力法的升级版，将所有的可能的路径试一遍，不行的话，回到上一步在进行其他选项的可行性测试 ，如果都尝试过还不行，则无解 回溯法适合递归 面试题12:矩阵中的路径 设计一个函数，用来判断在一个矩阵中是否存在一条包含某字符串所有字符的路径。路径可以从矩阵的任意一格开始，每一步可以在矩阵的左右上下移动一格，如果一条路径经过了矩阵的某一格，那么该路径不能再次进入该格子。 思路，首先遍历一次矩阵，得到所有可能的起始点，再将这些起始点一一进行验证（这里可以抽象一个验证的函数模块）注意边界上能移动和非边界上能移动是不一样的，所以我们需要保证row 和col大于0，否则返回false。 而且我们需要定义一个和二位矩阵相同的布尔型矩阵，来表示各个格子是否已经进入/访问过。 面试题13 机器人的运动范围 题目：地上有一个m行n列的方格。一个机器人从坐标(0,0)的格子开始移动，它每次可以向左、右、上、下移动一格，但不能进入行坐标和列坐标的数位之和大于k的格子。例如，当k为18时，机器人能够进入方格(35,37)但不能进入(35,38)，请问该机器人能够到达多少格子 动态规划和贪婪算法 特点一：求一个问题的最优解 特点二：整体问题的最优解是依赖各个子问题的最优解 特点三：被分解的小问题之间还有相互重叠的更小的子问题 特点四：从上往下分析问题，从下往上求解问题 ​ 因为从上往下会有重复，从下往上计算不会重复 一般的思路：从解决最小问题开始，然后把子问题一般是存储在一维数组或二维数组中，然后通过子问题最优解的组合来解决大的问题 贪婪算法：基于子问题的最优解，我们去定能够得到整个问题的最优解 ——一般需要数学证明 面试题14:剪绳子 题目：给你一根长度为n的绳子，请把绳子剪成m段，每段绳子的长度记为k[0],k[1]…k[m]请问k[0]xk[1]…k[m]的可能的最大乘积是多少？例如，当绳子的长度为8，剪成2，3，3三段，此时最大乘积是18 注意这里一般需要导出一个递推公式 f(n) = max(f(i) * f(n-i)) 然后针对每一个i我们都要遍历0&lt;i&lt;n 所以我们需要计算出f(1)…f(n-1) 显然会有重复计算，我们需要从f(1)一直计算到f(n) 还有初始值需要严格确定 在这个题目中，还需要注意，一段长度作为整体长度和非整体长度所能提供的最大值是不一样的，整体长度的最大值是必须要分成两段的，而非整体长度的最大值是整体长度的最大值和本身长度数值两者之间的最大值，这个一定要区分 以及第二层循环中，j&lt;=i/2是因为f(i)xf(n-i)==f(n-i)xf(i)，避免无谓的计算 本题的贪婪算法解法： 当n&gt;=5时，我们尽可能多减长度为3的绳子；剩下的绳子长度为4时，爸绳子剪成两段长度为2的绳子。 证明： 最后的因子肯定是2或3，因为大于这两个数分成这两个数肯定更大 2xP(n-2) &lt;= 3xP(n-3) (n&gt;=5时） 上式可以用数学归纳法证明 所以尽可能分为多的3，最后剩下0，1或2 个2 位运算 共有*五种位运算——与 或 异或 左移 右移 * 有符号数 移位的时候肯定是不考虑符号位，也就是保留符号位 左移低位补0，右移高位补0（如果是带符号数，则负数高位补1，正数高位补0） 面试题15:二进制中1的个数 常规解法：通过与 0..1..0相与，就知道对应1的给定数的位置是不是1，如果与的结果是1，则是1，结果是0，则是0。时间复杂度是给定数字的长度 进阶解法 把一个整数减去1，该数最右边的1变0，如果它的右边还有0，则所有的0都变成1，而之前的位数保持不变 我们可以利用这个特性，可以得到n&amp;(n-1)的结果就是消去最右边1后的数，能进行多少次这样的操作，就代表一个整数二进制表示中有多少个1 时间复杂度是给定整数中1的个数 宝贵思路：把一个整数减去1之后再和原来的整数做位与运算，得到的结果相当于把整数二进制表示中最右边的1变成0 第三章 高质量的代码非法输入 边界情况 适合的数据结构 命名方式 鲁棒性 首先把可能的输入都想清楚 测试用例 设计单元测试——功能测试 边界测试 负面测试 功能测试 尽量突破常规思维的限制，比如 是不是大数问题 边界测试 结束循环的边界条件是否正确 递归终止的边界值是否正确 最大值 最小值 是否能够适用 负面测试 可能的错误输入 永远不变的就是需求会一直改变，将需求可能的变化考虑进去，尽量减少代码改动的风险，——可扩展性和可维护性 面试题16：数值的整数次方 题目：实现函数double Power(double base, int exponent) 求base的eponent次方。不得使用库函数，同时不需要考虑大数问题。 边界问题：0的0次方 非法输入：0的负数次方 判断两个double是否相等，使用equal，a-b的误差在一个范围内即可（计算机数值精度的问题） 当然可以用普通循环来完成计算，我们可以用分解的办法 使用O(lgn)的复杂度来完成 1.使用右移运算符代替除以2 2.用 与1位与 判断是否为奇数 面试题17 打印从1到最大的n位数 题目：输入数字n，按顺序打印出从1到最大的n位十进制数。比如输入3，则打印出1，2，3一直到最大的3位数999 首先，这是一个大数问题，考虑用字符串/数组表达大数求解 对于n位的数字，我们可以用n+1位的数组来表示，最后一个元素为’\0’坐标志。 其次，我们需要定义如何增加increment以及如何打印printStr这两个函数，同时在increment中还要有判断是否上溢 第二种思路 这其实是将n位0-9所有数字的一个全排列打印出来。 全排列使用递归表达，数字的每一位都可能是0-9中的某一个数，然后设置下一位。递归结束的条件是我们已经设置到了数字的最后一位 面试题18:删除列表的结点 题目一：在O(1)时间内删除链表结点，给定单向链表的头指针和结点指针，定一一个在O(1)时间内删除该结点。 狸猫换太子，该结点复制后面结点的内容，然后将后面结点删掉 注意，对尾结点而言，仍需要从头结点顺序查找，所以我们要判断是否为尾结点。 题目二：删除链表中重复的结点 在一个排序的链表中，如何删除重复的结点 边界问题：头结点可能被删除，所以我们输入的参数，应该是指向头结点指针的指针，也就是ListNode** pHead 因为是排序，所以重复必然连续。我们需要使用两个指针来标识，一个指针指向重复段的pre，另一个指向重复段的next，然后把中间部分也就是重复段删除掉并把pre和next连接起来 通过while循环来找寻连续重复段 ps：关于链表的问题，头结点和尾结点一定要做位边界/终止条件考虑进来 面试题19:正则表达式匹配 题目：请实现一个函数用来匹配’.’和’*‘的正则表达式 ‘.’表示任意一个字符 ， ‘*‘表示它前面的字符可以出现任意次（含0次，就是这两个字符ignore） 我们这里要考虑第二个字符是 * 的情况 第二个字符不是 * 简单很多，直接比较判断 第二个字符是 * 稍微麻烦 所以我们这里判断当前字符时，要考虑下一个字符是否为 * 当第二个字符是* 时，一种选择是向后移动两个字符， 相当于* 和 其前面的字符被忽略了。 如果模式中的第一个字符和字符串的第一个字符相匹配，则在字符串上向后移动一个字符，在模式上有两个选择，可以在模式上向后移动两个字符，也可以保持模式不变。 使用递归的思路求解 面试题20:表示数值的字符串 题目：请实现一个字符串用来判断字符串是否表示数值 这个问题的关键——找到正确的匹配模式 P127 面试题21:调整数组顺序使奇数位于偶数前面 题目：输入一个整数数组，实现一个函数来调整该数组中数字的顺序，使得所有奇数位于数组的前半部分，所有偶数位于数组的后半部分。 基本的解法：维护两个指针，一个指向数组头部，一个指向数组尾部。前面的指针向前移动，如果遇到偶数，与后面指针指向的元素交换，后面指针向前移动，并重复进行判断，如果是奇数 前面指针向后移动 可扩展的解法 将函数解耦成两部分，一是判断数字是前半部分还是后半部分的标准； 二是拆分数组的操作。 防御性编程：对不符合要求的输入予以处理 面试题22:链表中倒数第k个结点 常规解法：遍历两次，记录长度 只遍历一次的解法：维护两个指针，一个指针先向前走k-1步，第二个指针保持不动，然后同时遍历，当第一个指针到达链表的尾结点时，第二个指针正好指向倒数第k个结点 不合法的输入： 输入的是空指针 输入的k小于0或者是0 输入的链表结点总数小于k 所以这里要注意鲁棒性 相关题目：求链表的中间结点，如果链表中的结点总数为奇数，则返回中间结点，如果结点总数是偶数，则返回中间两个结点的任意一个。 定义两个指针，同时从链表的头结点出发，一个指针走一步，另一个指针一次走两步。当一个指针到达末尾时，另一个正好在链表的中间 用两个不同速度的指针遍历链表 面试题23:链表中环的入口结点 首先是有没有环的问题，其次是环的入口结点 有没有环： 两个快慢指针，如果一个到了尾结点 说明没有环。如果相遇则有环，并且相遇的结点在环内 环的入口结点：从上面得到的结点出发，临时变量存储当前结点，循环一圈可以得到环的长度（结点个数） 两个指针 一个先移动环的长度步，然后同时出发，相遇的那个结点便是环的入口结点 面试题24:反转链表 题目：定义一个函数，输入一个链表的头结点，反转该链表并输出反转后链表的头结点。 设计的时间一般长于编码的时间 定义三个指针：当前结点，前一个结点，后一个结点 对输入的考虑： 链表头指针式nullptr 输入的链表只有一个结点 输入的链表有多个结点 面试题25:合并两个排序的链表 题目：输入两个递增排序的链表，合并这两个链表并使新链表中的结点仍然是递增排序的。 可以用递归也可以用循环 面试题26:树的子结构 输入两个二叉树A和B，判断B是不是A的子结构。 不要对一些引用相同变量的代码段做耦合操作，不然可能会有很大的问题，尽量解耦 首先是遍历结点，然后判断以该结点为起始是否有子结构，同时子结构的判断也是一个递归的形式。 判断两个浮点数是否相等，看差距是否在0.0000001之内，这是计算机的精度问题。 第四章 解决面试题的思路画图 举例子 适应白板 面试题27 二叉树的镜像 其实就是在遍历树的同时交换非叶结点的左、右子结点 面试题28 对称的二叉树 请实现一个二叉树，]]></content>
      <categories>
        <category>201909</category>
      </categories>
      <tags>
        <tag>Note</tag>
        <tag>Interview</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++_Start_2019Fall]]></title>
    <url>%2F2019%2F09%2F29%2FC%2B%2B_Start_2019Fall%2F</url>
    <content type="text"><![CDATA[final 面经 C++ extern关键字的作用 第一，置于变量/函数前，表示在别的文件中定义了该变量/函数，本文件中找不到去其他文件中寻找 注意，在定义的部分不加extern，以及那些想要共享/使用的文件中也要有加上extern的声明。 你没include该文件还想使用某变量/函数的时候，用extern，到时候编译器会在你编译链接的其他文件中寻找 注意：在同一文件中，变量不可重复声明，但是函数可以。 我们一般include头文件.h，头文件里所有我们都是可以访问的，但是cpp的话我们一般不include，如果我们想要使用其他cpp里的变量，就要在本文件中extern该变量声明，因为这样编译器在本文件中找不到的时候就会去其他文件（指一起编译链接的文件）里找。 第二，extern &quot;C&quot; void fun(int a,int b) 告诉编译器在编译fun这个函数时，按照C的规则而不是C++， C++语言在编译的时候为了解决函数的多态问题，会将函数名和参数联合起来生成一个中间的函数名称，而C语言则不会，因此会造成链接时找不到对应函数的情况，此时C函数就需要用extern “C”进行链接指定，这告诉编译器，请保持我的名称，不要给我生成用于链接的中间函数名。 extern 和 static (1) extern 表明该变量在别的地方已经定义过了,在这里要使用那个变量. (2) static 表示静态的变量，分配内存的时候, 存储在静态区,不存储在栈上面. extern和const可以连用 static关键字作用 static修饰局部变量 被修饰的变量成为静态变量，存储在静态区，数据生命周期与程序相同，main函数之前初始化，程序退出时销毁 生命周期不代表可以一直被访问，因为变量的访问还受到其作用域的限制 局部静态变量在退出函数后不会被销毁，所以该变量的值与退出函数与否无关 static修饰全局变量 全局变量本来就存在于静态区域，所以不改变存储位置，但是，static限制了其链接属性。 被statci修饰的全局变量只能被包含该定义的文件访问。 static修饰函数 使得该函数只能在包含该函数定义的文件中被调用 static在C++中的作用 在类中创建的静态成员变量和静态成员函数。所有对象只维持一个实例，——因此，采用static可以实现不同数据之间的数据共享 volatile限定符 直接处理硬件的程序常常包含这样的数据元素，他们的值由程序直接控制之外的过程控制， 当对象的值可能在程序的控制或检测之外被改变时，应将对象声明成volatile。——告诉编译器不应对这样的对象进行优化 const 定义常量 const修饰的变量value是不可变的 指针使用const 顶层const：指针本身不可变 const ptr;```1234底层const：指针指向的内容不可变```const int* ptr; 既有底层又有顶层：两者都不可变 int* const ptr;```123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354- 注意const的相互转换/传递，顶层const没啥问题 但是底层const：const对象可以接受非const，但是不能将const对象赋给非const对象- 接上一条，函数中使用const 形参可以是：常量，顶层const，底层const，const引用，注意存在常量引用，但是不存在引用常量 这样可以保证常量..在函数内部不被改变- const也可以修饰返回值——但很少见 多用于操作符的重载- 拷贝赋值运算符必须返回const引用，因为返回const会造成无限循环- 类相关const - const修饰成员变量 表示成员常量不能被修改，**且只能在初始化列表中赋值** - const修饰成员函数 类中的this指针默认是顶层const不是底层const，所以**无法绑定常量对象——实例中的常量部分以及常量对象实例** 这里与const修饰符与const修饰形参和返回类型不冲突，这里const修饰的是函数调用 常量成员函数：不改变对象的成员变量，也不能调用类中任何非const成员函数 const成员函数不被允许改它所在对象的任何一个数据成员 const成员函数可以访问对象的const成员（对象的常量部分），而其他函数不可以 - const修饰类对象/对象指针/对象引用 const修饰的类对象表示该对象为常量对象，其中的任何成员都不能修改。对于对象指针和对象引用也是一样 const修饰的对象，该对象的任何非const成员函数都不能调用，因为任何非const成员函数都会有修改成员变量的企图- 将const类型转换为非const的方法 使用**const_cast**转换只能改变运算对象的**底层const** 常量指针变非常量指针，并且仍然指向原来对象 常量引用变非常量引用，并且仍然绑定原来对象 ```C++ const int constant = 21; const int* const_p = &amp;constant; int* modifier = const_cast&lt;int*&gt;(const_p); *modifier = 7; 如果指针指向的是非常量对象，可以通过const_cast后的指针进行值的修改，如果指向的是常量对象，则是未定义的行为 建议 大胆使用const，但要搞清楚原委 避免一般的赋值/指向/绑定错误 在函数参数中要使用引用/指针，而不是对象实例 不要轻易的将函数的返回值类型定为const 除了重载操作符和拷贝赋值运算符（也属于重载操作符）之外一般不要将返回值类型定为某个对象的const引用 任何不会修改数据成员的函数都应该声明为const类型 其他 非const成员函数：this指针是一个类类型的 const成员函数中：this指针是一个const类型的 volatile成员函数中：this指针是一个volatile类型的 new和malloc的区别 动态分配内存是指程序运行时/即时对内存的分配，不是预先分配。 new 和 malloc 内存分配在堆上 malloc和free是库函数，new和delete是c++操作符 new自己计算需要空间大小，a 12malloc需要**指定大小**，```int* a = malloc(sizeof(int)); new在动态分配内存时可以初始化对象，调用其构造函数，delete释放内存时调用对象的析构函数 而malloc只分配一段内存，返回该内存首地址指针，失败则返回NULL C++ operator关键字——用于重载操作符 operator new和operator delete可以重载，而malloc不行 new可以调用malloc实现，但malloc不能调用new来实现 对于数据C++定义new[]专门进行动态数组分配，用delete[]进行销毁。new[]会一次分配内存，然后多次调用构造函数；delete[]会先多次调用析构函数，然后一次性释放 即分配和释放都是一次性的 C++多态性和虚函数表 多态——一个接口，多种方法，程序在运行时才决定调用的函数，polymorphism C++多态性是通过虚函数来实现的 这里注意重载overload 隐藏hide 覆盖override 重载：同一类中，相同函数名，不同形参列表 隐藏：针对非虚成员函数，派生类中（基类/派生类），和基类相同函数名，此时在派生类作用域中该函数名隐藏了基类中的函数名，但不代表没有了，因为派生类继承了，所以可以在Derived类中，通过作用域运算符来访问——Base::func()，即该函数仍然存在 覆盖：也叫做重写，针对虚函数，实现C++多态，下面看详解 ！！！多态与非多态的实质区别就是函数地址是早绑定还是晚绑定 函数的调用在编译期间就可以确定函数的调用地址，并生产代码，是静态的，此时我们说地址是早绑定的 而函数的调用的地址不能在编译期间确定，运行时才能确定，这就属于晚绑定 ps： 封装可以使代码模块化 继承可以扩展已经存在的代码 都是为了代码重用 多态的目的是为了接口重用，不论传递过来的是哪个类的对象，通过同一个接口调用到适应各自对象的实现方法 声明基类的指针，可以指向任意一个子类对象，调用相应的虚函数，根据指向子类的不同实现不同的方法。 如果没有使用虚函数，基类指针调用相应的函数时，总被限制在基类本身，也就是子类的基类函数部分，而虚函数是重写/覆盖了基类的虚函数，所以也就不存在基类的同名函数部分 （1）如果派生类的函数与基类的函数同名，但是参数不同。此时，不论有无virtual关键字，基类的函数将被隐藏（注意别与重载混淆）。（2）如果派生类的函数与基类的函数同名，并且参数也相同，但是基类函数没有virtual关键字。此时，基类的函数被隐藏（注意别与覆盖混淆）。 纯虚函数，虚函数后面 = 0，w含有纯虚函数的类称为抽象基类，不能创建对象实例 纯虚函数要求派生类必须重写。 纯虚函数提供接口 虚函数表 编译器为每一个类维护一个虚函数表，注意，这里的VTable是和类绑定的，不是对象实例，所以！！！同一个类的不同对象实际指向同一张虚函数表！！！ 虚函数是通过一张虚函数表V-Table来实现的。 主要是一个类的虚函数的地址表， 在有虚函数的类的实例中这个表被分配在了这个实例的内存中 就像一个地图map一样，指明了实际所应该调用的函数 C++的编译器应该是保证虚函数表的指针存在于对象实例中最前面的位置（这是为了保证取到虚函数表的有最高的性能——如果有多层继承或是多重继承的情况下） :我们可以通过对象实例的地址得到这张虚函数表，并调用相应函数 最后一个结点是虚函数表的结束结点，类似于字符串的’\0’ ok，接下来我们将继承时的虚函数表 继承分两种：有覆盖继承和无覆盖继承，无覆盖没有意义，重点讨论有覆盖 无覆盖继承 注意 这里的函数都是虚函数 可以看到在派生类实例 Derive d中，虚函数按照声明顺序放于表中。基类的虚函数放在子类的虚函数前面 有函数覆盖 覆盖的虚函数放到了虚表中原来父类虚函数的位置 未被覆盖的函数依旧 所以根据实际调用的实例不同，调用的虚函数不同，因为基类和派生类的虚表的同样位置对应的虚函数不同 多重继承 无虚函数覆盖 派生类实例中的VTable： 1.每个基类都有自己的虚表 2.派生类的虚函数被放到了第一个基类的表中，基类的顺序是按照派生列表的顺序来说明的 有虚函数覆盖 ​ 多重继承会有多个虚函数表，几重继承，就会有几个虚函数表。这些表按照派生的顺序依次排列，如果子类改写了父类的虚函数，那么就会用子类自己的虚函数覆盖虚函数表的相应的位置，如果子类有新的虚函数，那么就添加到第一个虚函数表的末尾 动态绑定实现原理 当编译器发现类中有虚函数的时候，编译器会创建一张虚函数表，把虚函数的函数入口地址放到虚函数表中，并且在类中增加一个指针：vpointer，这个指针是指向对象的虚函数表。在多态调用的时候，根据vpointer指针，找到虚函数表来实现动态绑定。 也就是在运行时根据vpointer指向的虚表来调用具体的函数——运行时绑定 静态多态和动态多态 静态多态是指通过模板技术或者函数重载技术实现的多态，其在编译器确定行为。动态多态是指通过虚函数技术实现在运行期动态绑定的技术。 纯虚函数如何定义，为什么对于存在虚函数的类中析构函数要定义成虚函数 构造函数 不可以是虚函数 显然，如果构造函数是虚函数，我们需要一个虚函数表来调用，但是类还没有实例化对象，就没有内存空间，就没有虚函数表，这是个死循环 析构函数 要定义成虚函数 如果不是虚函数的话： p 12```delete p; 这样的话我们效用的是Base基类的析构函数，只会释放掉基类部分的内存，派生类部分没有释放，造成内存泄漏 而如果将析构函数定义成虚函数 虚析构函数的地址存在于虚函数表中，和普通虚函数别无二致，同时也会像普通的虚函数一样进行覆盖 虽然父子的析构函数名字不一样，但是他们占同一个坑（即父子析构函数在虚函数表中的位置是一样的，否则就不存在多态了） 析构时，到特定的坑中调用该类型的析构函数，其析构函数中又嵌套了很多对父类的析构函数的调用 派生类析构函数中嵌套了基类析构函数的调用 析构函数能抛出异常吗 对象在运行期间出现了异常，异常处理模型应该调用这些对象的析构函数来完成释放资源的任务，所以析构函数已经变成了异常处理的一部分——所以我们假定析构函数是不会抛出异常的，因为如果这个过程出现异常，，会无限递归下去 1）C++中析构函数的执行不应该抛出异常； 2）假如析构函数中抛出了异常，那么你的系统将变得非常危险，也许很长时间什么错误也不会发生；但也许你的系统有时就会莫名奇妙地崩溃而退出了，而且什么迹象也没有，崩得你满地找牙也很难发现问题究竟出现在什么地方； 3）当在某一个析构函数中会有一些可能（哪怕是一点点可能）发生异常时，那么就必须要把这种可能发生的异常完全封装在析构函数内部，决不能让它抛出函数之外（这招简直是绝杀！呵呵！）； 比如： 1234567~ClassName()&#123; try&#123; do_something(); &#125; catch()&#123; //这里可以什么都不做，只是保证catch块的程序抛出的异常不会被扔出析构函数之外。&#125; 构造函数和析构函数调用虚函数吗 不要再类的构造或者析构函数中调用虚函数 不要在类的构造或者析构过程中调用虚函数，因为这样的调用永远不会沿类继承树往下传递到子类中去。 指针和引用区别 引用是一个变量别名 指针是一个对象 引用必须初始化 指针不是必须 引用一定不为空 相对于指针不需要检查所指对象为空，这增加了效率 指针和数组 函数返回类型不可以是数组或者函数类型 但可以是指向数组或者函数的指针 数组不允许拷贝，所以函数形参不能值传递 使用数组时，通常会转化为指针 数组会被转换为指针，所以我们为函数传递一个数组时，实际上传递的是指向数组首元素的指针 我们对应的形参可以是： const int* const int[] const int[10] 注意！不存在引用的数组，但存在数组的引用 1234int* ptrs[10] = /*...*/ //包含十个整数指针的数组int (*ptr)[10] = &amp;arr //ptr指向一个包含十个整数的数组int&amp; Parray[10] = /*...*/ //错误：不存在引用的数组int (&amp;arrRef)[10] = arr //一个包含十个整数数组的引用 智能指针是怎么实现的，什么时候改变引用计数 自己管理内存，可能不小心忘了delete，导致内存泄露 这里引入一个知识点，我们把ptr;```后，ptr指向的对象释放了，但是**ptr指针仍旧在并指向那块内存**，这里我们需要**附加操作**```ptr 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758 除了上边考虑到的两个问题，上边程序还存在另一问题：如果内存申请不成功，new会抛出异常，而我们却什么都没有做！所以对这程序我们还得继续改进（也可用try...catch…()当我们**使用智能指针**：- 智能指针能够**帮助我们处理资源泄漏**的问题- 帮我们处理**空悬指针** 的问题- 处理比较隐晦的**由异常造成的资源泄漏**1. **class shared_ptr**实现**共享式拥有**（shared ownership）概念。多个智能指针可以指向相同对象，该对象和其相关资源会在“最后一个引用（reference）被销毁”时候释放。为了在结构复杂的情境中执行上述工作，标准库提供了weak_ptr、bad_weak_ptr和enable_shared_from_this等辅助类。2. **class unique_ptr**实现**独占式拥有**（exclusive ownership）或严格拥有（strict ownership）概念，保证同一时间内只有一个智能指针可以指向该对象。它对于避免资源泄露（resourece leak）——例如“以new创建对象后因为发生异常而忘记调用delete”——特别有用。**shared_ptr**在多个地点指向同一对象的需求场景多个shared_ptr可以共享（或说拥有）同一对象。对象的最末一个拥有者有责任销毁对象，并清理与该对象相关的所有资源shared_ptr的目标就是，在其所指向的对象不再被使用之后（而非之前），自动释放与对象相关的资源。**unique_ptr**这个智能指针实现了独占式拥有概念，意味着它可确保**一个对象和其相应资源同一时间只被一个指针拥有**。一旦拥有者**被销毁或变成空，或开始拥有另一个对象**，**先前**拥有的那个对象就会**被销毁**，其任何相应资源也会被释放**什么时候改变引用计数**- 当创建类的**新对象时，初始化指针**，并将引用计数设置**为1**- 当对象作为另一个对象的副本时，**拷贝构造函数**复制副本指针，并增加与指针相应的引用计数（加1）- 使用赋值操作符对一个对象进行赋值时，处理复杂一点：**先使左操作数的指针的引用计数减1（为何减1：因为指针已经指向别的地方），如果减1后引用计数为0，则释放指针所指对象内存。然后增加右操作数所指对象的引用计数（为何增加：因为此时做操作数指向对象即右操作数指向对象）。**- 析构函数：调用析构函数时，析构函数先使引用**计数减1，如果减至0则delete对象**。 ps：减1肯定要接上check是否为0**weak_ptr**我们要用一个share_ptr来初始化一个weak_ptr不影响动态对象的生命周期，不影响对象的**引用计数器**由于底层对象上的引用计数不会随weak_ptr引用而增加，因此**循环引用不会导致底层对象未被删除**- 关于循环引用 两个对象互相使用一个shared_ptr成员变量指向对方的会造成循环引用。导致引用计数失效。 ```cpp class A &#123; shared_ptr&lt;B&gt; b; ... &#125;; class B &#123; shared_ptr&lt;A&gt; a; ... &#125;; shared_ptr&lt;A&gt; x(new A); // +1 x-&gt;b = new B; // +1 x-&gt;b-&gt;a = x; // +1 // Ref count of &apos;x&apos; is 2. // Ref count of &apos;x-&gt;b&apos; is 1. // When &apos;x&apos; leaves the scope, there will be a memory leak: // 2 is decremented to 1, and so both ref counts will be 1. // (Memory is deallocated only when ref count drops to 0) C++四种类型转换，static_cast, dynamic_cast, const_cast, reinterpret_cast 一个命名的强制类型转换有如下形式： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136 - **static_cast** 任何具有明确定义的类型转换，只要**不包含底层const**，都可以使用static_cast 和**C风格强制转换**效果**基本一样** C++的**任何隐式转换**都是使用**static_cast**来实现 - 用于**基本数据类型**的转换，和C风格的强制转换都**有安全隐患** - 基类和派生类之间的**指针或者引用的转换** 派生类转基类 安全。但是基类转派生类时没有动态类型检查是不安全的。 所以最好只用派生类转基类 - static_cast不能转换掉原有类型的const、volatile、或者 __unaligned属性。(前两种可以使用const_cast 来去除) - **const_cast** const_cast**只能改变**运算对象的**底层const**，也就是**去掉const性质** **上述是它唯一的功能** - 常量指针被转化成非常量的指针，并且仍然指向原来的对象； - 常量引用被转换成非常量的引用，并且仍然指向原来的对象； - const_cast一般用于修改指针。如const char *p形式。 如果原来对象是**常量对象**，那么使用const_cast执行**写操作**会产生**未定义**的后果 如果指向对象不是**常量对象**，那么是**合法行为** - **dynamic_cast** dynamic_cast运算符可以在**执行期决定真正的类型**。如果downcast是安全的（也就说，如果基类指针或者引用确实指向一个派生类对象）这个运算符会传回适当转型过的指针，也就是此时**可以转型为派生类指针**。如果downcast不安全，这个运算符会传回空指针（也就是说，基类指针或者引用没有指向一个派生类对象）。 - 在类层次间进行上行转换时，dynamic_cast和static_cast的效果是一样的； - 在进行下行转换时，dynamic_cast具有类型检查的功能，比static_cast更安全。 也就是**根据其执行期间指向的对象**，**如果是基类指针确实指向了派生类**，那么基类指针可以转换为派生类，否则会返回null。 - 对指针进行dynamic_cast，失败返回null，成功返回正常cast后的对象指针； - 对引用进行dynamic_cast，失败抛出一个异常，成功返回正常cast后的对象引用 - **reinterpret_cast** reinterpret_cast是强制类型转换符用来处理无关类型转换的，**通常为操作数的位模式提供较低层次的重新解释**！但是他仅仅是重新解释了给出的对象的比特模型，并没有进行二进制的转换！ - 从指针类型到一个足够大的整数类型 - 从整数类型或者枚举类型到指针类型 - 从一个指向函数的指针到另一个不同类型的指向函数的指针 - 从一个指向对象的指针到另一个不同类型的指向对象的指针 - 从一个指向类函数成员的指针到另一个指向不同类型的函数成员的指针 - 从一个指向类数据成员的指针到另一个指向不同类型的数据成员的指针 **尽量避免使用**- 内存对其的原则 - 为什么要内存对齐 - **平台原因**：各个硬件平台对存储空间的处理上有很大的不同。一些平台对某些特定类型的数据只能从某些特定地址开始存取。————- 比如，有些架构的CPU在访问 一个没有进行对齐的变量的时候会发生错误，那么在这种架构下编程必须保证字节对齐。 - **性能原因**：内存对齐可以提高存取效率。————- 比如，有些平台每次读都是从偶地址开始，如果一个int型（假设为32位系统）如果存放在偶地址开始的地方，那么一个读周期就可以读出这32bit，而如果存放在奇地址开始的地方，就需要2个读周期，并对两次读出的结果的高低字节进行拼凑才能得到该32bit数据。 每个特定平台上的编译器都有自己的默认“对齐系数”（也叫对齐模数）。你可以通过预编译命令`#pragma pack(n)`，n=1,2,4,8,16 来改变这一系数，其中 n 就是你要指定的“对齐系数”。 **1）概念：** **有效对齐值**：是 `#pragma pack`指定值 和 结构体中最长数据类型长度 中**较小**的那个。有效对齐值也叫**对齐单位**。 注意：VS、VC 默认是#pragma pack(8)，而 gcc 默认是#pragma pack(4)，并且gcc只支持1，2，4对齐。 **2）规则：** 1. 结构体变量的**首地址**是有效对齐值（对齐单位）的**整数倍**。 2. 结构体第一个成员的**偏移量（offset）**为0，——**结构体地址就是第一个成员地址** 以后每个成员相对于结构体首地址的 offset 都是**该成员大小与有效对齐值中较小那个**的整数倍，如有需要编译器会在成员之间加上填充字节。 3. **结构体的总大小**为 有效对齐值 的**整数倍**，如有需要编译器会在最末一个成员之后加上填充字节。 4. 结构体内类型相同的连续元素将在**连续的空间**内，和数组一样。 5. sizeof(union)，以**结构里面size最大元素**为union的size,因为在某一时刻，union只有一个成员真正存储于该地址。- **内联函数的优点 内联函数和宏定义的区别** 内联函数优点： - 编译的时候直接在该节点展开，不需要寻址调用，**效率高** - 内联函数是一个函数，编译器会像对待函数一样**检查参数**，**更安全**，——***宏有安全隐患*** - inline可以作为类的成员函数操作私有成员 ，——***宏不可以*** 内联函数缺点： 内联函数以复制为代价，活动产函数开销 - 如果函数的**代码较长**，使用内联将**消耗过多内存** - 内联函数不能有循环，一个是代码量太大 ，另一个是编译器一般会把他变为非内联函数，编译器的优化？ 综上,C++ 语言的函数内联机制既具备宏代码的效率，又增加了安全性，而且可以自由操作类的数据成员。所以在C++ 程序中，应该用内联函数取代所有宏代码. BUT , “断言assert”恐怕是唯一的例外。assert是仅在Debug版本起作用的宏，它用于检查“不应该”发生 的情况。为了不在程序的Debug版本和Release版本引起差别，**assert不应该产生任何副作用**。如果assert是函数，由于函数调用会引起内 存、代码的变动，那么将导致Debug版本与Release版本存在差异。所以assert不是函数，而是宏。- **C++**内存管理 简介，分为五个区，**栈**，**堆**，**自由存储区**，**全局/静态存储区**，**常量存储区** **栈** 在**执行函数**时，函数内**局部变量的存储单元**都可以在**栈上创建**，函数执行**结束时**这些存储单元自动**被释放**。**栈内存分配运算**内置于处理器的**指令集**中，**效率很高**，但是分配的**内存容量有限** **堆** 就是那些由 `new`分配的内存块，他们的**释放编译器不去管**，由我们的**应用程序去控制**，一般一个`new`就要对应一个 `delete`。如果程序员没有释放掉，那么在程序结束后，操作系统会自动回收 **自由存储区** 就是那些由`malloc`等分配的内存块，**和堆十分相似**的，不过它是用`free`来结束自己的生命的 **全局/静态存储区** **全局变量和静态变量**被**分配到同一块内存中**，在以前的C语言中，全局变量又分为**初始化的和未初始化**的，在C++里面没有这个区分了，他们**共同占用同一块内存**区。 **常量存储区** 里面**存放的是常量**，**不允许修改** - 明确区分 堆与栈 ```cpp void f() &#123; int* p=new int[5]; &#125; p位于栈中，指向了一块堆中的内存 堆和栈的区别 (1). 管理方式不同 ​ 栈：编译器自动管理 ​ 堆：程序员管理，容易产生memory leak (2). 空间大小不同 ​ 堆：32位系统，堆内存可以达到4G的空间 ​ 栈：在VC6下，默认的栈空间是1M大小 ​ 可以认为堆几乎无限制，栈有限制 (3). 能否产生碎片不同 ​ 堆：频繁的new和delete势必会造成空间的不连续，从而造成大量碎片，程 序效率降低 ​ 栈：先进后出，是连续的，不存在内存碎片的问题 (4). 生长方向不同 ​ 堆：向上生长，沿着内存地址增加的方向 ​ 栈：向下生长，沿着内存地址减小的方向 (5). 分配方式不同 ​ 动态分配：函数运行时分配 ​ 静态分配：函数编译时分配 ​ 堆：只有动态分配，没有静态 ​ 栈：有静态分配，比如局部变量的分配，也有动态分配，有alloca函数进行 分配。但是栈的动态分配与堆不同，栈的动态分配是有编译器进行释放，无须 我们手工实现。 (6). 分配效率不同 ​ 栈：机器系统提供的数据结构，计算机对栈有底层支持，分配专门的寄存器存 放栈的地址，入栈出栈都有专门的指令执行，所以栈的效率高 ​ 堆：C++函数库提供的。抽象层次高，当然效率就低了 ​ 栈的效率高，且不会有内存碎片的问题，但是堆更自由，且使用的内存更大 那么如何避免产生野指针呢？这里列出了5条规则，平常写程序时多注意一下，养成良好的习惯。 规则1：用malloc或new申请内存之后，应该立即检查指针值是否为NULL。防止使用指针值为NULL的内存。规则2：不要忘记为数组和动态内存赋初值。防止将未被初始化的内存作为右值使用。规则3：避免数组或指针的下标越界，特别要当心发生“多1”或者“少1”操作。规则4：动态内存的申请与释放必须配对，防止内存泄漏。规则5：用free或delete释放了内存之后，立即将指针设置为NULL，防止产生“野指针”。 学会使用智能指针 越是怕指针，就越要使用指针。不会正确使用指针，肯定算不上是合格的程序员。 必须养成使用“调试器逐步跟踪程序”的习惯，只有这样才能发现问题的本质 STL里的内存池实现 为什么要使用内存池 如果应用程序频繁地在堆上分配和释放内存，会导致性能的损失。并且会使系统中出现大量的内存碎片，降低内存的利用率。默认的分配和释放内存算法自然也考虑了性能，然而这些内存管理算法的通用版本为了应付更复杂、更广泛的情况，需要做更多的额外工作。而对于某一个具体的应用程序来说，适合自身特定的内存分配释放模式的自定义内存池可以获得更好的性能。 内存池则是在真正使用内存之前，预先申请分配一定数量、大小相等（一般情况下）的内存块留作备用。当有新的内存需求时，就从内存池中分出一部分内存块，若内存块不够再继续申请新的内存。这样做的一个显著优点是，使得内存分配效率得到提升。 单线程内存池整个生命周期只被一个线程使用，因而不需要考虑互斥访问的问题；多线程内存池有可能被多个线程共享，因此需要在每次分配和释放内存时加锁。相对而言，单线程内存池性能更高，而多线程内存池适用范围更加广泛 从内存池可分配内存单元大小来分，可以分为固定内存池和可变内存池。所谓固定内存池是指应用程序每次从内存池中分配出来的内存单元大小事先已经确定，是固定不变的；而可变内存池则每次分配的内存单元大小可以按需变化，应用范围更广，而性能比固定内存池要低。 经典的内存池实现过程 （1）先申请一块连续的内存空间，该段内存空间能够容纳一定数量的对象；（2）每个对象连同一个指向下一个对象的指针一起构成一个内存节点（Memory Node）。各个空闲的内存节点通过指针形成一个链表，链表的每一个内存节点都是一块可供分配的内存空间；（3）某个内存节点一旦分配出去，从空闲内存节点链表中去除；（4）一旦释放了某个内存节点的空间，又将该节点重新加入空闲内存节点链表；（5）如果一个内存块的所有内存节点分配完毕，若程序继续申请新的对象空间，则会再次申请一个内存块来容纳新的对象。新申请的内存块会加入内存块链表中。 STL里的set和map是基于什么实现的。红黑树的特点 STL里的其他数据结构和算法实现 必须在构造函数初始化式里进行初始化的数据成员有哪些 常量成员——只能初始化不能赋值 引用类型——必须在定义时初始化 且 不能重新赋值 数据成员是一个没有默认构造函数的对象 子类初始化父类的私有成员，需要在且只能在参数初始化列表中显式调用父类的构造函数 1234567891011121314151617181920class Test&#123;public: Test()&#123;&#125;; Test (int x)&#123; int_x = x;&#125;; void show()&#123;cout&lt;&lt; int_x &lt;&lt; endl;&#125;private: int int_x;&#125;;class Mytest:public Test&#123;public: Mytest() ：Test(110)&#123; //Test(110); // 构造函数只能在初始化列表中被显示调用，不能在构造函数内部被显示调用 &#125;;&#125;;int _tmain(int argc, _TCHAR* argv[])&#123; Test *p = new Mytest(); p-&gt;show(); return 0;&#125; 模板特化 定位内存泄漏(1)在windows平台下通过CRT中的库函数进行检测； (2)在可能泄漏的调用前后生成块的快照，比较前后的状态，定位泄漏的位置 (3)Linux下通过工具valgrind检测 手写strcpy，memcpy，strcat，strcmp等函数 assert：断言， 先计算表达式expression，如果其值为假（0），那么它先向stderr打印一条出错信息，然后通过调用abort来终止程序运行 strcpy：拷贝字符串，以’\0’为标志结束，并返回dst地址 123456char* strcpy(char* dst,const char* src)&#123; assert(dst!=nullptr &amp;&amp; src!=nullptr); char* cp = dst; while(*cp++ = *src++) return dst;&#125; strcat：把src所指字符串添加到dst结尾处（覆盖dst结尾处的’\0’)并添加’\0’ 123456789char* strcat(char* dst,const char* src)&#123; assert(dst!=nullptr &amp;&amp; src!=nullptr); char* cp = dst; while(*cp) cp++; while(*cp++ = *src++) ; return dst;&#125; strcmp：比较两个字符串 比较规则：从左到右进行比较（ASCII值），直到出现不同的字符或者遇到’\0’为止。如果全部字符相同，则认为两个字符串相等，返回0。 如果出现不同字符，则对第一次出现的不同字符进行比较。比较方法是以S1的第一个不同字符减去S2的第一个不同字符，以所得差值作为返回值（大于0，则返回1，小于0则返回-1） 12345678910111213int strcmp(const char* src, const char* dst)&#123; assert(src!=nullptr &amp;&amp; dst!=nullptr); int ret = 0; while(!(ret=*(unsigned char*)src-*(unsigned char*)dst) &amp;&amp; *dst)&#123; ++dst; ++src; &#125; if(ret&lt;0) return -1; else if(ret&gt;0) return 1; return 0;&#125; memcpy： strlen：计算字符串s的长度，不包括’\0’ 123456size_t strlen(const char* str)&#123; assert(str!=nullptr); const char* cp = str; while(*cp++); return (cp-str-1);&#125; #]]></content>
      <categories>
        <category>201909</category>
      </categories>
      <tags>
        <tag>Note</tag>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Network_Start_2019Fall]]></title>
    <url>%2F2019%2F09%2F29%2FNetwork_Start_2019Fall%2F</url>
    <content type="text"><![CDATA[计算机网络 TCP和UDP的区别 IP首部 TCP首部 UDP首部 TCP和UDP的区别 TCP和UDP的应用场景 如何实现可靠的UDP 其中网络接口对应：物理层和数据链路层（数据链路层又包括逻辑链路子层和介质链路子层） 链路层（或者说物理层） 包括操作系统中的驱动程序和计算机网卡还有传输的物理介质，链路层上面的主要协议有以太网协议。 其中，MAC地址集成在网卡 网络层 保证数据从一台主机将数据准确的发送到另一台指定的主机，主要通过指定IP地址（点分十进制）和端口号（表明应用程序）来实现，主要的协议有IP协议，ICMP和IGMP作为辅助协议。路由器属于网络层。 主机 —&gt; 主机 点分十进制是一个表达数字数据的形式。 其形式为用句点（.） 分隔的多个十进制数。 将其每8位分为一组，转换为十进制，分别得到127、0、0和1，再将这四个十进制数之间以句点连接，即为127.0.0.1。 传输层 网络层提供了一种不可靠的服务，它只是尽可能快把分组从源端口发送到目的窗口，但是并不能保证能毫发无损地准时送到 而传输层则利用TCP，UDP协议来保证传输。TCP采用超时重传，发送和接收端分组等机制来实现可靠传输。主要协议有TCP，UDP，TCP数据和UDP数据基本一致，唯一的区别是UDP传给IP的协议的信息单元称为UDP数据报。 应用层 负责应用程序的具体需求，主要协议有FTP，TELNET，HTTP，HTML，STMP，POP，IMAP，DNS等 MAC地址——物理层 IP地址——网络层 TCP——传输层 HTTP——应用层 IP 地址 网络上每一个节点都必须有一个独立的 IP 地址，通常使用的 IP 地址是一个 32bit 的数字，被 . 分成 4 组，例如，255.255.255.255 就是一个 IP 地址。有了 IP 地址，用户的计算机就可以发现并连接互联网中的另外一台计算机。 域名（主机名） 用 12 位数字组成的 IP 地址很难记忆，在实际应用时，用户一般不需要记住 IP 地址，互联网给每个 IP 地址起了一个别名，习惯上称作域名。 域名与计算机的 IP 地址相对应，并把这种对应关系存储在域名服务系统 DNS(Domain Name System)中，这样用户只需记住域名就可以与指定的计算机进行通信了 数据链路层 实现计算机的二进制数据与物理介质中的光或电信号的转化； 将数据分装为帧，帧是数据在链路层传送的单位； 控制帧的传输，校验数据是否完整； 将数据从一个硬件实体传输到另一个硬件实体； 数据链路层最重要的两个概念——mac地址和分组交换 mac地址mac地址是网卡的物理地址，mac地址在出厂时都是唯一的。mac地址是数据在链路层传输时使用的地址。对于mac地址获取是通过发送arp包实现。 分组交换 分组交换是指将较大的数据分割为若干个较小的数据，然后依次发送。 原因：不同的数据链路有各自的最大传输单元(MTU: Maximum Transmission Unit)。针对不同的MTU，我们分割的方法也不一样 以以太网(一种数据链路)为例，它的MTU是 1500 字节，也就是通过以太网传输的数据，必须分割为若干帧，每个帧的数据长度不超过 1500 字节。如果上层传来的数据超过这个长度，数据链路层需要分割后再发送。 以太网帧 以太网帧的开头是“前导码(Preamble)”，长度为 8 字节，这一段没什么用，重点在于以太网帧的本体。本体由首部，数据和，FCS 三部分组成： 首部以太网首部包括目标mac地址，源mac地址和类型。 类型类型部分存储了上层协议的编号，比如上层是 IP 协议，则编号为 0800，ARP协议为0806。 FCSFCS 表示帧校验序列(Frame Check Sequence)，用于判断帧是否在传输过程中有损坏(比如电子噪声干扰)。FCS 保存着发送帧除以某个多项式的余数，接收到的帧也做相同计算，如果得到的值与 FCS 相同则表示没有出错。 交换机交换机是一种在数据链路层工作的网络设备，它有多个端口，可以连接不同的设备。交换机根据每个帧中的目标 MAC 地址决定向哪个端口发送数据，此时它需要参考“转发表” 转发表并非手动设置，而是交换机自动学习得到的。当某个设备向交换机发送帧时，交换机将帧的源 MAC 地址和接口对应起来，作为一条记录添加到转发表中 全双工与半双工通信 全双工通信是指可以同时接受数据和发送数据，而半双工是指可以发送数据也可以接受数据，但是两者不能同时进行，实际是采用了单工的通信方式进行分时通信。 网络层简单的理解为一个寄快递的过程，从源ip地址到目标ip地址 网络层可以简单的理解为一个寄快递过程：源IP地址就是寄件人的地址，目标IP地址就是收件人的地址。IP地址被分成几类，好比快递地址被分成多个省，但是省这个范围太大了，不好找到收件人的具体位置，于是就将省划分为很多市县，这就好比IP划分子网的过程。IP选路过程和快递的发送过程是一样的。假设快递要从A省M市，发往C省N市。快递从A省M市出发，到了A省中转站，发往了B省中转站，然后和目的地址比较，发现不是目的省份，继续往前走。发送到C省中转站，发现是目标省份，继续发送到具体市县的中转站，知道找到N市。每一个中转站就好比一个路由器，每一站的转发就是一跳。在发送的过程中发现，包裹太大，每辆车载重有限额的。为了避免超载，于是将包裹分成几车来运输。但是每个司机都按照自己的想法去运送货物，因此他们走的路线可能不一样，有的走了国道被堵死，有的走了高速爽的不行，但是最终都会到达目的地，只是先出发的车不定能先到。所以，在发车前给每辆车按照发车顺序贴了一个序号标签。最后到达目的地后就按车的标签顺序卸货。这其中，车的载重量就好比MTU，分车装载的过程就好比分片过程，车的序号标签好比片偏移。 几个重要的概念：路由器 跳 分片 片偏移 MTU mac地址：没有规律可循 ip地址：有规律可循 有网络 子网 主机的一级一级的概念 类似于国家/省/市 所以我们在前面跳的时候使用ip寻址，最后一跳使用MAC寻址 ip地址的表示方法：32位 点分十进制 ip地址由两部分组成——网络标识 和 主机标识 网络标识：不同网段 主机标识：同一网段下的不同主机，同一网段中不能重复出现 根据网络段所占位数和主机位数的不同，氛围ABCD四类，具体如下 这种固定数目的分类方法，会造成IP地址的极大浪费 这时我们引入子网掩码 子网掩码：一段连续的1和一段连续的0组成，用来和ip地址按位与 通过子网掩码，从主机位借位给网络位，这样就扩大了网络标识 也可以把借的部分称为子网位 相当于子网掩码重新分配了网络位和主机位 更加灵活 但是由于通用的还是ABCD，所以我们需要加个后缀来表示子网掩码 直观上来看，子网掩码的借位效果，就如同产生了几个子网，可以看作是：网络+子网+主机 IP路由控制 对于目前庞大的网络结构，不可能直接相连，而是采用路由器组建起来的网络拓扑结构 这样 如何将数据发往指定的ip地址呢 ps：MAC寻址是由交换机来完成的，ip寻址是由路由器来完成的 主机和路由器内部都有一张路由表 路由表的搜索过程 搜索路由表，如果能找到和目的 IP 地址完全一致的主机，则将 IP 数据报发向该主机； 搜索路由表，如果匹配主机失败，则匹配同子网的路由器(这需要子网掩码的协助)。如果找到路由器，则将 IP 该数据报发向该路由器； 搜索路由表，如果匹配同子网路由器失败，则匹配同网络号路由器，如果找到路由器，则将该 IP 数据报发向该路由器； 如果以上都失败了，就搜索默认路由，如果默认路由存在，则发送给默认路由； 如果都失败了，就丢弃这个包，然后发送一份主机不可达的ICMP报文给源IP地址； 接收到数据报的路由器再按照它自己的路由表继续转发，直到数据报被转发到目的主机； 如果在转发过程中，IP 数据报的 TTL（生命周期）已经被减为 0，则该 IP 数据报就被抛弃，然后发送超时的ICMP报文给源IP地址主机。 路由表：ip地址到路由器地址的映射，意即如果路由表有这个ip地址，我们就跳到该ip地址对应的路由器 简单总结上述的搜索过程 先匹配主机ip地址 ，如果有，发送对应路由器 ，没有接下 再匹配子网ip地址，即同子网的路由器 ，如果有，发送，没有接下 再 匹配网络ip地址，即同网络路由器，如果有，发送，没有接下 以上都失败，搜索默认路由，存储，发送，没有接下 都失败了——丢弃这个包，发送一份主机不可达的ICMP报文给源IP地址 接上，这时候收到数据报的路由器按照他自己的路由表继续转发，直到数据报转发到目的主机 接上，如果在转发过程中，IP 数据报的 TTL（生命周期）已经被减为 0，则该 IP 数据报就被抛弃，然后发送超时的ICMP报文给源IP地址主机。 分片与重组 发送数据太大，超过以太网的MTU，需要分片，独立寻径。 但是只有第一个分片，包含了传输层的首部 如何重组：重组只在最终目的主机进行。依靠IP首部中的16位标识和片偏移，实现重组。只有同属于一个包的片才具有相同的16位标识。 如果一个分片丢失 整个数据报作废，因为网络层没有重传机制，只能由上层协议实现 路径MTU 分片会加重路由器的负担，因此只要条件允许，我们都不希望路由器对IP数据包进行分片处理。另外，如果一个分片丢失，整个IP数据报都会作废，因为网络层没有重传机制，只能由上层协议实现。 解决以上问题的技术是“路径MTU发现”。主机会首先获取整个路径中所有数据链路的最小MTU，并按照整个大小将数据分片。因此传输过程中的任何一个路由器都不用进行分片工作。 为了找到路径MTU，主机首先发送整个数据包，并将IP首部的禁止分片标志设为1.这样路由器在遇到需要分片才能处理的包时不会分片，而是直接丢弃数据并通过ICMP协议将整个不可达的消息发回给主机。 主机将ICMP通知中的MTU设置为当前MTU，根据整个MTU对数据进行分片处理。如此反复下去，直到不再收到ICMP通知，此时的MTU就是路径MTU。 路径MTU简介： 为了不让路由器分片，我们主机提前吧数据分片好，这时分片对应的大小就是路径MTU。 不断尝试的过程，直至找到整个路径MTU 将IP首部的禁止分片设置为1，这样路由器在需要分片才能处理的包时候不会分片，而是通过ICMP协议发送给主机数据不可达的消息。这样主机会按照这个消息里的MTU来对数据分片，并在此发送，直至没有数据不可达的消息传回。此时对应的MTU就是路径MTU 关于IP报文的组成 版本（Version）：由四位bit构成，表示IP的版本信息，如IPv4的版本号为4 首部长度：表示IP首部的字节长度，如果没有可选字段，则首部长度为20字节 区分服务：表示服务质量，如延时，吞吐量等 总长度(Total Length)：表示IP首部与数据部分总的字节数，该段长16比特，所以IP包的最大长度为65535字节(2^16)。虽然不同数据链路的MTU不同，但是IP协议屏蔽了这些区别，通过自己实现的数据分片功能，从上层的角度来看，IP协议总是能够以65535为最大包长进行传输。 标识（ID：Identification）：用于分片重组。属于同一个分片的帧的ID相同。但即使ID相同，如果目标地址、源地址、上层协议中有任何一个不同，都被认为不属于同一个分片。 标志（Flags）：由于分片重组，由三个比特构成。 第一个比特未使用，目前必须是0。 第二个比特表示是否进行分片，0表示可以分片，1表示不能分片。在路径MTU发现技术中就用到了这个位。 第三个比特表示在分片时，是否表示最后一个包。1表示不是最后一个包，0表示分配中最后一个包。 片偏移（FO: Fragment Offset）：由13比特组成，表示被分片的段相对于原始数据的位置。它可以表示8192(2^13)个位置，单位为8字节，所以最大可以表示8 x 8192 = 65536字节的偏移量。 生存时间（TTL: Time To Live）：表示包可以经过多少个路由器的中转。每经过一个路由器，TTL减1。这样可以避免前文提到的无限传递包的问题。 协议： 表示IP协议的上层协议使用了哪个协议。比如TCP协议的编号为6，UDP编号为17. 首部校验和：用于检查IP首部是否损坏 可选项：仅在试验或诊断时用，可以没有。如果有，需要配合填充（Padding）占满32比特。 传输层 首先，需要传输层的原因/或者说实现了什么 IP协议不可靠的传输，数据丢包 数据损害，IP协议并不能提供解决办法 应该由哪个应用程序来接受这个数据包呢？IP协议没有办法告诉我们 传输层协议有TCP和UDP TCP是面向有连接的协议，也就是传输数据之前要在发方和收方之间先建立连接 一般建立连接需要三步，关闭连接需要四步 TCP概述： TCP 协议是面向有连接的协议，还有数据重传、流量控制等功能，TCP 协议能够正确处理丢包问题，保证接收方能够收到数据，与此同时还能够有效利用网络带宽。然而 TCP 协议中定义了很多复杂的规范，因此效率不如 UDP 协议，不适合实时的视频和音频传输。 UDP概述： UDP 协议是面向无连接的协议，它只会把数据传递给接收端，但是不会关注接收端是否真的收到了数据。但是这种特性反而适合多播，实时的视频和音频传输。因为个别数据包的丢失并不会影响视频和音频的整体效果。 在IP中，两大关键要素就是源IP地址和目标IP地址 而传输层主要实现应用程序之间的通信 ，增加了两个要素，源端口号和目标端口号 再加上IP首部中的协议号， 这五个元素，可以唯一识别一个通信——源IP地址 目标IP地址 源端口号 IP端口号 协议号 这五个信息只要有一个不同，都认为是不同的通信 端口号：作用是用于区分同一台主机中正在通信的不同应用程序，因此也被称为程序地址。 分为两种： 知名端口号：这种端口号是固定的，用于服务器程序，使用对应协议的程序就将端口号设为对应的数字。比如DNS的端口号就是53. 动态端口号：这种端口号是不固定的，用于客户端程序，客户端程序对端口号要求不高，只要该端口号在本机中唯一就行。 端口号 协议 53 DNS 80 HTTP 20 FTP数据 21 FTP控制 23 SSH 25 SMTP TCP和UDP的区别： TCP基于有连接，UDP基于无连接（就是UDP在发送数据之前，并不考虑对方能否接收到，甚至目的地址可能是无效） TCP可以保证可靠传输，UDP不能保证可靠传输。 TCP结构复杂，消耗资源多，建立过程慢 复杂。 UDP结构简单，消耗资源少，建立过程快 TCP基于流模式，UDP基于数据报模式。 TCP可以通过发送缓冲区和接受缓冲区来存储数据流，没有边界，一段传输 UDP每一个数据报都是一个独立对象，有着指定大小。 TCP连接只能是点到点，而UDP可以一对一，一对多或者多对多。TCP只能是点到点原因很简单，因为TCP的传输前要先建立连接。因此，广播和多播只能采用UDP数据报的方式。 TCP有确认，重传，拥赛控制机制，UDP在没有建立连接或者对方已经退出的情况下任然会继续发送数据，导致通信流量的浪费。 TCP和UDP的用途： TCP：用于实现可靠传输的情况，文件非常重要，对网络拥堵有较高要求的情况。 UDP： 用于高速传输和实时性较高的场合（即时通信）。对于采用UDP的实事视频通信，如果出现丢包也只会出现短暂卡顿，但是如果采用TCP丢包后需要重发，会导致很长时间的卡顿。 包总量较少的通信（DNS），客户端较多 广播通信 UDP首部 源端口号：表示发送端端口号，不需要时设为0 目标端口号：表示接收端端口号 包长度：表示整个UDP包的长度 校验和：为了提供可靠的UDP首部和数据而设计，只要源IP地址，目标IP地址，源端口号，目标端口号，协议号有一个发生了篡改校验和都会不正确。 TCP首部 源端口号：发送端端口号 目标端口号：接受端端口号 序列号：发送数据时，表示发送数据的位置，发送完一次数据后，序列号的值都等于原来的序列号加上数据的长度 应答号：用于接受端告诉发送端下次应该从哪个位置开始发送，表示前面的数据已经都收到了 数据偏移：实际就是TCP首部长度 保留：一般设置为0，用于后续扩展 控制位：长度为8，从左到右分别是CWR，ECE，URG，ACK，PSH，RST，SYN，FIN 窗口大小：能够发送数据的最大值，为0时可以发送探测窗口 校验和：与UDP校验和作用相同 紧急指针：用于处理紧急情况 选项：其他控制设置 如何实现可靠的UDP solution：在应用层模仿TCP 添加seq/ack机制，确保数据发送到端 添加发送和接受缓冲区，主要是用户超时重传 添加超时重传机制 详细说明：送端发送数据时，生成一个随机seq=x，然后每一片按照数据大小分配seq。数据到达接收端后接收端放入缓存，并发送一个ack=x的包，表示对方已经收到了数据。发送端收到了ack包后，删除缓冲区对应的数据。时间到后，定时任务检查是否需要重传数据。 TCP三次握手和四次握手 TCP保证可靠传输的控制协议和算法： 连接管理——三次和四次握手 数据破坏——通过校验和 丢包——应答和超时重发机制 分片乱序——序列号 窗口滑动——提高发送效率，对发送端和接受端流量进行控制 加快通信速度——快速重发，三次收到重发消息进行重发 流控制——避免网络流量浪费 拥塞控制——慢启动算法，拥塞窗口 TCP中的确认应答机制 在TCP中当发送端的数据达到接受主机时，接受主机端都会返回一个消息，告诉对方我已经收到了。这个消息叫确认应答。发送确认应答时，TCP首部中的ACK标志位设1。 通过 序列号 和 确认应答号来实现 主机A发送第一个包时序列号为1，数据长度为1000，那么主机B收到包后发送一个数据包给主机A，在该包中将TCP首部中的32位确认号设为1001.相当于告诉对方1001之前的我都收到了，下次从1001开始发 经受时延的确认应答 为了降低确认应答包的数量，TCP提出了经受时延的确认应答。接受端在收到数据后并不立即发送一个应答数据包，而是等待一段时间，如果有新的数据被接受就更新应答号，如果有其他数据要发送就坐上该数据包的顺风车。在系统的内核中维持了一个定时器，一般是200ms如果定时器溢出，即使没有其他数据到达，也发送该应答数据包。 经受时延的目的，主要是为了在时延期间内能够搭上一个发送数据的顺风车，当然，这期间如果接受数据也要更新应答号 Nagle算法 TCP是基于流的传输协议，在Rlogin和Telnet传输中会出现只有一个字节数据的TCP数据包。而一个TCP数据包的首部加上IP首部就有40个字节，很显然发这样的数据包划不来。为了减少这样的数据包，有人提出了Nagle算法。 Nagle算法简单讲就是，等待服务器应答包到达后，再发送下一个数据包。数据在发送端被缓存，如果缓存到达指定大小就将其发送，或者上一个数据的应答包到达，将缓存区一次性全部发送。 Nagle算法是从发送端角度考虑减少了数据包的个数，时延应答从接收端角度考虑减少了数据包的个数。 TCP的连接与断开（三次握手和四次握手） 建立连接——三次握手 建立连接 客户端发送请求包，告诉服务器：“我想和你通信？”数据包中SYN位置为1，假设其序列号为x，客户端状态变成SYN_SENT； 服务器端接受到请求包后也发送一个请求包，告诉客户端：“现在可以建立连接”。数据包中SYN位置位1，假设其序列号为y，注意客户端序列号和服务器端序列号并没有关系，他们是由各自的内核按照一定的规则生成的。但是这个应答包的32位应答号，必须是x+1，之所以加1是因为客户端发过来的包SYN位被认为占一个数据。因此，告诉下一包从x+1开始发。发送后，服务器从监听状态变成SYN_RCVD状态。 客户端发送应答数据包，告诉服务器：“那我们开始发送数据吧”。数据包应答号为y+1。客户端变成ESTABLISHED状态，即可以传输状态。 服务器端接受到应答数据包后，变成ESTABLISHED状态。 发送数据 客户端发送一个一个字节的数据，因此序列号为x+1； 服务端发送一个应答包，应答号为x+2，告诉客户端下次从x+2开始发； 断开连接——四次握手 断开连接 客户端发送请求断开的数据包，告诉服务器：“数据传完了，我要断开了”。发送一个FIN包，序列号x+2。客户端转移到FIN_WAIT_1状态。 服务器端发送应答包，告诉客户端：“行，我知道了，你断开吧！”。应答号为x+3，服务器进入CLOSE_WAIT状态。客户端收到应答后，转移到FIN_WAIT_2状态。 服务器发送一个断开数据包，告诉客户端：“既然传完了，那我这边的开关也准备关了”。序列号为y+1，发送完后服务器进入LAST_ACK状态。 客户端发送一个应答包，告诉服务器：“好的，我知道你要断开了。”应答号为y+2。客户端进入TIME_WAIT状态。 TIME_WAIT又称为2MSL等待状态，MSL是系统中定义的最大报文生存时间，任何TCP报文在网络中生存时间超过这个值就必须被丢弃。 等待MSL的原因是防止最后一个ACK丢失后可以进行重发，如果ACK丢失后，服务器会重发FIN。 总结 涉及到的首部部分：控制位SYN FIN 、序列号seq 、确认应答号ACK TCP建立连接三次握手 客户端向服务端 发送 请求数据包，数据包中SYN置1， 发送后 客户端状态变为SYN_SENT，假设序列号为x 服务端接收到请求包后，也向客户端发送一个请求包，数据包中SYN置1，假设序列号为y，应答号为x+1，发送后服务器从监听状态变为SYN_RCVD状态 ps：服务端和客户端的序列没有关联，由各自内核按照一定规则生成。但是应答号是根据对方的序列号和数据来的。 客户端向服务端发送 应答数据包，数据包应答号为y+1，由SYN_SENT变为ESTABLISHED状态 建立连接后发送数据 客户端发送一个一个字节的数据，序列号为x+1 服务端发送一个应答包，应答号为x+2，告诉客户端下次从x+2开始 TCP断开连接四次握手 客户端发送请求数据包，FIN置1，序列号为x+2，发送后客户端变为FIN_WAIT_1状态 服务端发送应答包，序列号为y，应答号为x+3，发送后服务器进入CLOSE_WAIT状态 客户端收到应答后，转移到FIN_WAIT_2状态 服务器发送一个断开数据包，序列号为y+1，发完后服务器进入LAST_ACK状态 客户端收到后发送一个应答包，应答号为y+2，客户端进入TIME_WAIT状态 TIME_WAIT又称为2MSL等待状态，MSL是系统中定义的最大报文生存时间，任何TCP报文在网络中生存时间超过这个值就必须被丢弃。等待MSL的原因是防止最后一个ACK丢失后可以进行重发，如果ACK丢失后，服务器会重发FIN。 注意我们连接的时候SYN都是1，应答包时ACK=1，FIN包时FIN=1 这里需要补充一些知识 TCP层有个FLAGS字段，包括这几个标识： SYN FIN ACK ** PSH RST URG** SYN：表示建立连接 FIN：表示关闭连接 ACK：表示响应 PSH：表示有DATA数据传输 RST：表示连接重置 ACK可以与SYN/FIN同时使用，比如SYN和ACK同时为1，表示的就是建立连接之后的响应 单一的一个SYN 表示的只是建立连接 TCP的几次握手，就是通过这样的ACK表现出来（和SYN同时为1的ACK） SYN和FIN时不会同时为1，一个表示建立连接，一个表示断开连接 RST一般是在FIN之后才会出现为1的情况，表示的是连接重置。 一般地，当出现FIN包或RST包时，我们便认为客户端与服务器端断开了连接；而当出现SYN和SYN＋ACK包时，我们认为客户端与服务器建立了一个连接。 PSH为1的情况，一般只出现在 DATA内容不为0的包中，也就是说PSH为1表示的是有真正的TCP数据包内容被传递。 自己来一遍： 三次握手建立连接： 首先客户从CLOSED开始，服务器从LISTEN开始（CLOSED打开后到LISTEN） 客户端发送SYN包，SYN=1，发送完后，客户端为SYN_SENT状态 序列号为x 服务端收到客户端发送的SYN包，发送SYN+ACK包给客户端，序列号为y，应答号为x+1，发送完后，服务端处于SYN_RCVD状态 客户端收到服务端发送的SYN+ACK包，发送ACK包给服务端，序列号为x+1，应答号为y+1，发送完后客户端处于ESTABLISHED状态。 服务端收到客户端发送的ACK包之后，也处于ESTABLISHED状态 **前两次都有SYN**，最后一次没有，只是一个**ACK包** 之后客户端开始穿数据，序列号是x+1 注意**SYN/SYN+ACK包不能携带数据，但要消耗一个序号** **ACK包可以携带数据，但是不携带数据就不消耗序号** 四次握手断开连接 一开始两者都处于ESTABLISHED状态 首先客户端想要断开，发送FIN包给服务端，发送完之后，客户端处于FIN_WAIT_1状态 seq = x 服务端收得到客户端发过来的FIN包后，发送ACK包给客户端，发送完后，进入CLOSE_WAIT状态。seq = y，ack = x+1 客户端收到服务端发来的ACK包之后，进入FIN_WAIT_2状态，这个时候，客户端不再向服务端发数据，但是客户端仍要接受服务端的数据，相当于客户端到服务端的连接断开，服务端到客户端的连接还在 同时，这时候TCP服务器进程应该告诉高层应用进程，马上要断开连接，这时候如果还有数据要发送，可以发送。 服务端这边如果已经没有发送给客户端的数据，发送一个FIN包给客户端，发送完后，服务端进入LAST_ACK状态。seq = u，ack = x+1 客户端收到后，发送一个ACK包，发送完后进入TIME_WAITED状态，经过2MSL后没有收到来自服务端的消息后进入CLOSED状态 服务端收到客户端的ACK包后进入CLOSED seq = x+1，ack = u+1 FIN报文不携带数据 也要消耗掉一个序列号 2-3服务器可能会发一些数据，这中间ack会变，所以服务端必须重复上次的ack = x+1 为什么要2MSL，保证客户端发送的最后一个ack到达服务端 因为如果没有到达，服务端会在2MSL时间内重发FIN+ACK包，这时候继续在此节点上重复前面操作。保证握手的正常进行 为什么是三次 如果客户端的发送的第一个请求延时，这个时候会发送第二个，（因为客户端会认为是丢包，故重新发送），假设第二个没有延时，建立连接并断开，之后服务端又接收到第一个请求，这时候会发送确认包给客户端，但客户端并不会接受该数据包并回发。这样服务端会一直等待客户端发送数据，浪费资源 为什么是四次 因为TCP是全双工的通信，需要客户端和服务器端分别关闭。所以需要四次 TCP窗口 是为了解决应答机制等待时间过长 如果没有窗口，TCP每发送一次数据就必须等待应答，收到后继续发送，如果没有收到则等待一段时间后重发，如果很长时间都没有收到应答则判断为网络断开。 使用窗口后，无需等待应答可以连续发送多个数据包 TCP在每个传输方向都有两个窗口——发送端窗口和接受端窗口，TCP是全双工，购有四个窗口 发送端窗口 接受端窗口 发送端的发送窗口和接受端的接受窗口是配对的 超时重传RTO 当一个包被发送后，就开启一个定时器，如果定时时间到了，还未收到能确认该发送包的应答包，就重传一份数据。注意收到的应答包可能是该包也可能是后面包的，但是只要能确认该包被收到就行。另外如果，是因为网络延时造成重传，则接受端收到重复数据包后丢弃该包。 快速重传 当如果发送端收到一个包的三次应答包后，立即重传，比超时重传更高效。 拥塞控制算法： 拥塞控制算法先采用慢启动算法，到达慢启动阀值后采用拥塞避免算法。 通信开始时，发送方的拥塞窗口大小为 1。每收到一个 ACK 确认后，拥塞窗口大小加1。 由于指数级增长非常快，很快地，就会出现确认包超时，认为发生了拥塞。 此时设置一个“慢启动阈值”，它的值是当前拥塞窗口大小的一半。 拥堵发生后将拥塞窗口大小设置为 1，重新进入慢启动过程。 由于现在“慢启动阈值”已经存在，当拥塞窗口大小达到阈值后，停止使用慢启动算法，开始采用拥塞避免算法。窗口大小开始线性增加。 随着窗口大小不断增加，如果收到三次重复确认应答，则进入“快速重发”阶段。对于这用拥塞情况，TCP 将“慢启动阈值”设置为当前拥塞窗口大小的一半，再将拥塞窗口大小设置成阈值大小（也有说加 3）。然后采用拥塞避免算法增加窗口大小。 随着窗口大小不断增加，如果发生超时。对于这种拥塞情况，TCP将满启动阀值设置为当前拥塞窗口的一半，然后将拥塞窗口设置为1。 知识点学习总结 若确认号为N，说明到序号N-1为止的所有数据都已正确收到 数据偏移，TCP报文的数据起始处 立 TCP报文的起始处有多远 确认ACK：ACK=1该字段有效。在连接建立后所有传送的报文段都必须把ACK置1 同步SYN：连接建立是用来同步序号。 SYN=1:连接请求报文 SYN= 1 ACK=1:连接接受报文 窗口：发送端发送窗口 接受端接受窗口 最大报文段长度MSS指的是每一个TCP报文段中的数据字段的最大长度 所以MSS不是整个的最大长度，因为还有首部 单工状态下，窗口就是发送端的发送窗口对应接受端的接受窗口，但是TCP是全双工所以有四个窗口。这里我们讨论单工，原理上与双工一致 客户端A 服务端B A收到B的确认报文段来确定发送窗口 B的报文段：确认号31 窗口是20 则A的发送窗口是31-50 31之前的是后沿，已发送并收到确认的部分 50之后的是前沿，不允许发送的部分 窗口包含：已发送但未收到确认 ，尚未发送两部分 前沿 = 后沿 + 窗口 后沿的变化：不动（未收到新的确认） 前移（收到了新的确认） 在发送窗口中，尚未发送的部分称为可用窗口 B的接收窗口：和 A对应，或者说发送给A的最近的确认段中给的信息所构成的A的滑动窗口对应 B中的滑动窗口中会未按序收到，只能对按序收到的最高序号给出确认 B收到的数据会给到B的应用进程 发送缓存用来暂时存放： 发送应用程序 传送给 发送方TCP 准备发送的数据 TCP已发出但尚未收到确认的数据 接受缓存用来暂时存放： 按序到达的 但是暂未被接受应用程序/进程 读取的数据 未按序到达的数据 超时重传的概念 主要是隔多久重传， 报文段的往返时间RTT：一个报文段发出时间到收到相应确认时间的差 RTTs：RTT的滑动平均 新的RTTs = (1-a) x (旧的RTTs) + a x (新的RTT样本) 超时重传时间RTO 建议 RTO = RTTS + 4 x RTTD 流量控制就是用我们上述所说的滑动窗口来解决的 流量控制和拥塞控制 首先区别这两个概念 流量控制是点到点、端到端，考虑的是发送端和接受端的速度匹配，网络不构成瓶颈，主机端的读写是瓶颈 计算机网络中的链路容量（即带宽），交换节点中的缓存和处理机等，都是网络资源 当我们对资源的需求超过了网络能够提供的资源，就会出现拥塞 对网络资源需求的总和 &gt; 可用资源——拥塞发生 所谓拥塞控制就是防止过多的数据注入到网络中，这样可以使的网络中的路由器或者链路不致过载。这是一个全局性的问题 我们介绍拥塞控制的四种算法 慢开始 拥塞避免 快重传 快恢复 讨论之前 做两个假定 数据单方向传送，另一个方向只传送确认 接收方总是有足够大的缓存空间，发送窗口的大小由网络的拥塞程度来决定 发送方维持一个拥塞窗口，我们让发送方自己的发送窗口 = 拥塞窗口 慢开始 配合 拥塞避免 慢开始： 一开始使用一个MSS，没经过一个传输轮次，double 拥塞避免：每次➕一个MSS 两者配合慢开始门限ssthresh 一开始使用慢开始算法，到达ssthresh后，使用拥塞避免算法， 直到遇到网络拥塞——将ssthresh变为当前拥塞窗口的一半，初始值变为1MSS，然后慢开始，遇到门限变拥塞避免，周而复始 注意上面判断拥塞的依据——没有按时收到确认 快重传 配合 快恢复 基于如下考虑：发送方设置的超时计时器时限已到但是还没有收到确认，不使用快重传的话，会将ssthresh减半然后拥塞窗口cwnd减小到1 快重传算法： 首先要求接收端每收到一个失序的报文段就立刻发出重复确认——而不是等待接收端自己发送数据时进行捎带确认，——为的是使发送方及早知道有报文段没有到达对方 快重传算法约定，发送方一连收到（对同一数据）三个重复确认，就立即重传对该确认数据的下一数据，比如使确认M2，重传M3（因为确认M2的ack就是M3的数据序号） 快恢复——配合快重传使用 过程： 快重传后： 将sshthresh变为现在cwnd的一半，然后执行拥塞避免算法 原因：当我们一连接收到三个重复确认，我们会认为这时候网络很可能没有发生拥塞 TCP Server 和 TCP Client（Linux 套接字） 数据传输过程中，一定有一个标准化的过程，从主机a到主机b通信： a的固有数据——标准化——转化成b的固有格式 a或者b的固有数据存储格式就是自己的主机字节序，上面的标准化就是网络字节序 a的主机字节序——网络字节序——b的主机字节序 主机字节序：就是自己的主机内部，内存中数据的处理方式，可以分为两种： 大端字节序：按照内存的增长方向，高位数据存储在高位内存中 小端字节序：按照内存的增长方向，高位数据存储在低位内存中 在linux系统中，内核已经将这些协议实现，看看linux下套接字编程的API 套接字的API分为服务器端的部分和客户端的部分 服务器端 分为五个部分：创建套接字 绑定套接字 监听套接字 数据传输 关闭套接字 1. 创建套接字socket函数 123#include &lt;sys/socket.h&gt; int socket(int family,int type,int protocol); 返回：非负描述字－－－成功 -1－－－失败 返回的就是**套接字描述符（如果成功）——一个非负描述字** 现在返回的描述符**仅是部分打开的**，还**不能用于读写**，如何**完成打开的工作**，取决于我们时**客户端还是服务端** 2. 绑定套接字bind函数 一个**套接字地址（本机IP和端口号）**绑定到**创建的套接字描述符**上，客户端一般不需要，但是对**服务器而言，一般要使用知名端口号**，如果不进行绑定，客户端不知道目的端口号，连接不能完成 123 #include &lt;sys/socket.h&gt; int bind(int sockfd, const struct sockaddr * server, socklen_t addrlen); 返回：0－－－成功 -1－－－失败 3. 监听listen函数 socket函数创建的套接字是主动套接字，**调用listen变成监听套接字** **主动套接字描述符**——&gt;**监听套接字描述符** 此时TCP状态由**CLOSE跃迁到LISTEN** backlog是已完成队列和未完成队列大小之和，对于监听套接字有两个队列，一个是未完成队列，一个是已完成队列。 这里的已完成和未完成指的是**是否建立了连接** 未完成队列：客户端发送一个SYN包，服务器收到后变成SYN_RCVD状态，这样的套接字被加入到未完成队列中。 已完成队列：TCP已经完成了3次握手后，将这个套接字加入到已完成队列，套接字处于ESTABLISHED状态。 12#include&lt;sys/socket.h&gt;int listen(int sockfd, int backlog); ![img](https://img-blog.csdn.net/20170409102055702?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvc2hhbmdoYWlydW94aWFv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast) 上图中可以看出，TCP的三次握手是在调用connect函数时完成的，服务器端没有调用函数，但是必须有套接字在某个端口监听，不然会返回客户端RST，终止连接。 **4.accept函数** accept函数从**已完成连接的队列**中**取走一个套接字**，如果该**队列为空，则accept函数阻塞**。accept**函数的返回值称为已连接套接字**，已连接的套接字就**建立一个完整的TCP连接**，源IP地址，源端口号，目的IP地址，目的端口号都是唯一确定了。 ***总结：accept函数从已完成的队列中去走一个套接字（监听套接字），返回一个已连接套接字，这个已连接的套接字建立了一个完整的TCP连接——五元素全部确定（+协议号）*** **5.数据传输** write read / send recv write和read函数：当服务器和客户端的**连接建立起来后**，就可以**进行数据传输（读和写操作）**了，服务器和客户端用各自的套接字描述符进行读/写操作。因为**套接字描述符也是一种文件描述符，所以可以用文件读/写函数write()和read()进行接收和发送操作**。 **write()函数用于数据的发送** 123#include &lt;unistd.h&gt; int write(int sockfd, char *buf, int len); 回：非负－－－成功 -1－－－失败 sockfd是套接字描述符，对于服务器是accept()函数返回的已连接套接字描述符，对于客户端是调用socket()函数返回的套接字描述符 buf是指向一个用于发送信息的数据缓冲区；len指明传送数据缓冲区的大小 **read()函数用于数据的接收** 123#include &lt;unistd.h&gt; int read(int sockfd, char *buf, intlen); 回：非负－－－成功 -1－－－失败 参数sockfd是套接字描述符，对于服务器是accept()函数返回的已连接套接字描述符，对于客户端是调用socket()函数返回的套接字描述符；参数buf是指向一个用于接收信息的数据缓冲区；len指明接收数据缓冲区的大小。 send和recv函数：TCP套接字提供了send()和recv()函数，用来发送和接收操作。这两个函数与write()和read()函数很相似，只是多了一个附加的参数。 （1）send()函数用于数据的发送 1234#include &lt;sys/types.h&gt;#include &lt; sys/socket.h &gt; ssize_t send(int sockfd, const void *buf, size_t len, int flags); 回：返回写出的字节数－－－成功 -1－－－失败 前3个参数与write()相同，参数flags是传输控制标志。 （2）recv()函数用于数据的发送。 1234#include &lt;sys/types.h&gt;#include &lt; sys/socket.h &gt; ssize_t recv(int sockfd, void *buf, size_t len, int flags); 回：返回读入的字节数－－－成功 -1－－－失败 前3个参数与read()相同，参数flags是传输控制标志。 **6.关闭套接字** close函数 close函数关闭套接字 12#include &lt;unistd.h&gt;int close(int sockfd); 参数是：套接字描述符 TCP客户端 创建套接字socket函数 连接服务器connect函数 用connect函数来建立与TCP服务器的连接 123#include &lt;sys/socket.h&gt; int connect(int sockfd, const struct sockaddr * addr, socklen_t addrlen); 返回：0－－－成功 -1－－－失败 客户端发送的SYN包可能会遇到失败，可能有以下几种情况： 如果客户端没有收到SYN的响应包，根据TCP的超时重发机制进行重发。75秒后还没收到，就返回错误。 如果目的主机没有监听目的端口号，就会返回一个RST的分节，客户端收到RST后立刻返回错误。 如果SYN在中间路由遇到目的不可达，客户端收到ICMP报文，客户端保存这个报文信息，并采用第一种情况方案解决，也就是重发。 收发数据 关闭套接字 由上图可以看出： connect 建立三次握手 close两边分别关闭四次握手 clientfd：套接字描述符——socket函数返回，默认主动套接字 listenfd：监听描述符——listen函数返回，将主动套接字转换为监听套接字 connfd：已连接描述符——accept函数返回 connect：函数成功返回0，出错则返回 -1 UDP Server 和 UDP Client（linux套接字） UDP比TCP简洁很多，不需要listen accept 和 connect过程 服务端程序 socket函数创建套接字描述符 123#include &lt;sys/types.h&gt;#include &lt;sys/socket.h&gt;sockfd = socket(AF_INET, SOCK_DGRAM, 0)； UDP是数据报的形式，因此在创建套接字时，是SOCK_DGRAM，这是与TCP不同的地方 bind函数，绑定服务器地址到套接字上 123#include &lt;sys/types.h&gt; /* See NOTES */#include &lt;sys/socket.h&gt;int bind(int sockfd, const struct sockaddr *addr, socklen_t addrlen); bind函数与TCP的使用相同，将服务器的知名端口号和IP地址绑定到服务器套接字地址上，IP地址可能有多个。 sendto函数，发送数据给指定地址 123#include &lt;sys/types.h&gt;#include &lt;sys/socket.h&gt;ssize_t sendto(int sockfd, const void *buf, size_t len, int flags, const struct sockaddr *dest_addr, socklen_t addrlen); sendto函数比send函数多出两个参数，一个是目的地址，一个是地址长度。告诉发送给哪个IP地址和哪个端口号。 recvfrom函数，接受数据 123#include &lt;sys/types.h&gt;#include &lt;sys/socket.h&gt;ssize_t recvfrom(int sockfd, void *buf, size_t len, int flags, struct sockaddr *src_addr, socklen_t *addrlen); recvfrom函数比recv函数多出两个参数，相当于TCP的accept函数，告诉我们是谁发送了数据过来。 UDP的connect函数UDP的套接字分为已连接的套接字和未连接的套接字，默认的是未连接的套接字，上面的例程采用的是未连接的套接字。 UDP的connect函数形式与TCP的相同，但是作用的实现也是不同的。TCP的connect会完成三次握手，而UDP的connect不会，UDP的connect只是告诉内核保存了对端的IP和端口号，内核以后就将该套接字的数据发给这个对端地址，从这个对端地址收到的数据也会发送给客户程序。 在服务器未启动的情况下，启动客户端并发送消息。对于未连接的套接字而言，客户端不能收到服务器主机传回的ICMP差错报文。而已连接的套接字可以收到。 UDP已连接的套接字只能实现一对一的传输，如果要从多个地方接受数据和发送数据，则只能使用未连接的套接字。因此，UDP客户端多用已连接的套接字，服务端用未连接的套接字。 UDP缺乏流量控制UDP没有TCP那样的窗口通知过程，因此，如果UDP的服务器收到的数据过快，主机来不及处理，就可能导致套接字缓冲区被占满。套接字的缓冲区被填满后，新到达的数据报就会被丢弃，导致大量丢包。]]></content>
      <categories>
        <category>201909</category>
      </categories>
      <tags>
        <tag>Note</tag>
        <tag>Network</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OS_Start_2019Fall]]></title>
    <url>%2F2019%2F09%2F29%2FOS_Start_2019Fall%2F</url>
    <content type="text"><![CDATA[操作系统Linux 进程与线程 进程和线程的区别 进程：资源分配的基本单位 线程：cpu调度/程序执行的最小单位 同一个进程中可以并行运行着多个线程 进程分别有独立的地址空间， 同一进程的线程共享该进程的空间。 linux下面启动一个新的进程，系统必须分配给它独立的地址空间，建立众多的数据表来维护它的代码段、堆栈段和数据段，这是一种非常昂贵的多任务工作方式。而运行一个进程中的线程，它们之间共享大部分数据，使用相同的地址空间，因此启动一个线程，切换一个线程远比进程操作要快，花费也要小得多。当然，线程是拥有自己的寄存器和堆栈（线程栈） 线程切换比进程更快更高效，开销更小 用户级线程和内核级线程的比较 ps：阻塞：暂停并等待某个条件的触发 用户级线程不需要陷入内核，因此切换速度更快 用户级线程允许每个进程有自己定制的调度算法，因为不是内核的系统调用 用户级线程跨平台更方便 用户级线程会面临问题：一是如何实现阻塞 二是没有时钟如何实现调度 多进程程序和多线程程序区别，优缺点，使用场合.. 多进程，一个进程崩溃不影响其他进程，但是进程之间切换和通信代价大 多线程，一个线程崩溃会导致整个进程死掉，其他线程也不能正常工作，但是数据共享 通信方便 进程需要开辟独立地址空间，对资源消耗很大。线程对资源消耗更小。对于高并发，只有线程加上IO复用技术才能适应 有了进程为什么还要线程 一个任务可以分成多个子任务并行执行，他们是对一个对象在操作。 线程不需要像进程一样维护那么多信息，因此创建和销毁速度更快，拥有同一个地址空间，访问很容易 ——多线程更快，占用资源少 任务有CPU密集和IO等待，的过程，最大化利用CPU 进程间的通信方式 需要解决的问题有三个：数据传递 关键部位不会交叉 顺序 进程通信适用于线程 但有一个地方不同，进程间交换数据在不同的地址空间，但是线程在同一个地址空间进行，只要知道数据的地址，都可以很方便的访问 七种进程间通信方式 信号量：信号量用于实现进程间的互斥与同步，而不是用于存储进程间通信数据。 信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它通常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段 管道( pipe )：管道是一种半双工的通信方式，数据只能单向流动，而且只能在具有亲缘关系的进程间使用。进程的亲缘关系通常是指父子进程关系。 命/有名管道 (named pipe) ： 有名管道也是半双工的通信方式，但是它允许无亲缘关系进程间的通信。 消息队列( message queue ) ： 消息队列是由消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。 信号 ( signal ) ： 信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。 共享内存( shared memory ) ：共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的 IPC 方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号两，配合使用，来实现进程间的同步和通信。 套接字( socket ) ： 套解口也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同及其间的进程通信。 锁机制： 互斥锁 提供了以排他方式阻止数据结构被并发修改的办法 读写锁 允许多个进程同时读，但是写操作互斥 条件变量 可以以原子变量的方式阻塞进程，直到某个特定条件为真为止对条件测试是在互斥锁的保护下进行的。条件变量始终与互斥锁一起使用。 线程与进程相同，都有三个基本状态，——运行、阻塞 和 就绪 有四种转换关系： 运行—&gt;阻塞 阻塞—&gt;就绪 就绪—&gt;运行 运行—&gt;就绪 只有运行到就绪可以相互转换 阻塞肯定是从运行来的，到就绪去 多线程有几种实现方法，都是什么 调用操作系统API，Linux用POSIX线程，内核级线程 使用第三方库的库函数，比如Boost库，实现用户级线程 C/C++库里的函数，$$头文件，用户级线程 多线程同步和互斥有几种方法 首先搞清楚什么是线程的同步和互斥——对进程也适用 互斥 对于线程A和线程B来讲，同一时刻，只允许一个线程对临界资源进行操作，A操作则B等待，A退出B才能操作 同步 在互斥的基础上，实现线程之间的有序访问，A和B都可以对缓冲区读写数据，A写的时候B不能拿，B拿的时候A不能写，这是一种制约关系，我们称为线程的同步关系 那什么是临界资源和临界区——适用于线程/进程 临界资源 能被多个线程共享的数据/资源 临界区 对临界资源进行操作的那一段代码 显然，如果能保证诸进程互斥地进入自己的临界区，便可以实现诸进程/线程对临界资源的互斥访问 信号量：对应一个down和up操作（都是原子操作），down使信号量减一，up使信号量加1.如果你信号量大于0，则down后继续执行。down=0，down后睡眠，但是并不会讲信号量减到负数。 互斥量：互斥量是信号量的一种特例，只有0和1两种状态（解锁和枷锁） 关键区域：与互斥量类似，但是最大的区别在于，关键区域会进行忙等待，而互斥量如果不能解锁会自动让出cpu Linux平台下：加锁实现同步和互斥 互斥锁mutex 访问共享资源之前加锁，访问完成之后解锁 加锁后，任何其他试图在此加锁的线程会被阻塞，直到当前进程解锁 如果解锁时有一个以上的线程阻塞，那么所有该锁上的线程都被编程就绪状态， 第一个变为就绪状态的线程又执行加锁操作，那么其他的线程又会进入等待。在这种方式下，只有一个线程能够访问被互斥锁保护的资源。 读写锁rwlock 读写锁有三种状态：读加锁状态、写加锁状态和不加锁状态 写加锁模式下，任何试图加锁的进程都会被阻塞，直到写进程对其解锁 读加锁模式下，任何线程都可以对其进行读加锁操作，但是所以试图进行写加锁操作的线程都会被阻塞，直到所有的读进程都解锁 所以读写锁非常适合对数据结构读的次数远远大于写的情况 如果严格按照上述读写锁的操作进行的话，那么当读者源源不断到来的时候，写者总是得不到读写锁，就会造成不公平的状态。一种避免这种不公平状态的方法是：当处于读模式的读写锁接收到一个试图对其进行写模式加锁操作时，便会阻塞后面对其进行读模式加锁操作的线程。这样等到已经加读模式的锁解锁后，写进程能够访问此锁保护的资源。 自旋锁spinlock 使用模式和互斥锁很类似 只是在加锁后，有线程试图再次执行加锁操作的时候，该线程不会阻塞，而处于循环等待的忙等状态（CPU不能够做其他事情）。所以自旋锁适用的情况是：锁被持有的时间较短，而且进程并不希望在重新调度上花费太多的成本。 屏障 进程和线程（POSIX）的系统调用 进程原语 线程原语 描述 fork pthread_create 创建线程或进程 waitpid pthread_join 获取线程进程或线程退出状态 getpid pthread_self 获取进程ID或线程ID exit pthread_exit 退出进程/线程 wait()和waitpid() 函数说明 wait()函数用于使父进程（也就是调用wait()的进程）阻塞，直到一个子进程结束或者该进程接收到了一个指定的信号为止。如果该父进程没有子进程或者它的子进程已经结束，则wait()函数就会立即返回。 waitpid()的作用和wait()一样，但它并不一定要等待第一个终止的子进程（它可以指定需要等待终止的子进程），它还有若干选项，如可提供一个非阻塞版本的 wait()功能，也能支持作业控制。实际上，wait()函数只是 waitpid()函数的一个特例，在Linux 内部实现 wait()函数时直接调用的就是waitpid()函数。 pthread_join用于等待一个线程的结束，也就是主线程中要是加了这段代码，就会在加代码的位置卡主，直到这个线程执行完毕才往下走。 pthread_exit用于强制退出一个线程（非执行完毕退出），一般用于线程内部。 线程池是什么 预先创建一些线程，并处于阻塞状态，新来了一个连接时就从线程池中挑一个为其服务，服务完毕后线程也不关闭，重新放回池子，线程池就是这样采用一个队列或其他容器，维持一定数量线程 多线程同步和互斥有何异同，什么情况下分别使用他们，举例说明 互斥：只某一资源同一时刻只允许一个访问者对其访问，具有唯一性和排他性，但是无法限制访问者对资源的访问顺序，即访问是无序的 同步：在互斥的基础上，通过其他机制实现对资源的有序访问。 少数情况可以允许多个访问者同时访问资源，如第一类读写者模型。 **火车票售票**是互斥还是同步——**互斥** 生产者消费者**主要是同步问题**，**也有互斥**的问题 - 生产者消费者问题？？ - 读者写者问题？ 进程间通信（IPC）介绍 IPC(InterProcess Communication) 在不同进程之间传播或交换信息 常用方式：管道（无名管道和有名管道）、信号量、消息队列、共享存储、socket、Streams **管道** 通常指无名管道，UNIX系统IPC最古老的姓氏 1. 特点 - 半双工 - 用于亲缘关系的进程间通信。**父子进程，兄弟进程**之间 - 可以看成是**特殊的文件**，对于**管道pipe的读写**可以使用普通的read、write等函数，不属于任何其他文件系统，并且**只存在于内存中** 2. 原型 123#include &lt;unistd.h&gt;int pipe(int fd[2]); // 返回值：若成功返回0，//失败返回-1 一个管道pipe**建立**时，会创建**两个文件描述符**：fd[0]为读而打开，fd[1]为写而打开 ![Screen Shot 2019-08-06 at 3.56.32 PM](/Users/liutao/Desktop/screenshot/Screen%20Shot%202019-08-06%20at%203.56.32%20PM.png) **关闭管道只需要关闭这两个文件描述符即可** **调用pipe的进程接着调用fork**，这样就创建了父子进程之间的IPC通道 ![Screen Shot 2019-08-06 at 4.01.40 PM](/Users/liutao/Desktop/screenshot/Screen%20Shot%202019-08-06%20at%204.01.40%20PM.png) 若要数据流从父进程流向子进程，则关闭父进程的读端（`fd[0]`）与子进程的写端（`fd[1]`）；反之，则可以使数据流从子进程流向父进程 123456789101112131415161718192021222324#include&lt;stdio.h&gt;#include&lt;unistd.h&gt;int main()&#123; int fd[2]; // 两个文件描述符 pid_t pid; char buff[20]; if(pipe(fd) &lt; 0) // 创建管道 printf("Create Pipe Error!\n"); if((pid = fork()) &lt; 0) // 创建子进程 printf("Fork Error!\n"); else if(pid &gt; 0) // 父进程 &#123; close(fd[0]); // 关闭读端 write(fd[1], "hello world\n", 12); &#125; else &#123; close(fd[1]); // 关闭写端 read(fd[0], buff, 20); printf("%s", buff); &#125; return 0;&#125; ***ps:在12345678910111213141516171819202122232425262728293031323334 两个进程的pid不同，与**fork函数特性**有关 fork函数的一个奇妙之处就是**仅仅被调用一次，却能够返回两次，可能有三种不同的返回值**： 1. **父进程**中，fork返回新创建**子进程的PID**（非负） 2. **子进程**中，fork返回0 3. 出现**错误**，返回一个**负值** 所以在接下来的代码中**用fork的返回值判断当前进程是父进程还是子进程** &lt;font color=red&gt;其实就相当于链表，进程形成了链表，父进程的pid(p 意味point)指向子进程的进程id, 因为子进程没有子进程，所以其pid为0.&lt;/font&gt; 每个进程都有一个独特（互不相同）的进程标识（process ID），可以通过getpid（）函数获得，还有一个记录父进程pid的变量，可以通过getppid（）函数获得变量的值 ***注意，fork完之后，父子进程是独立的，子进程会把父进程拷贝一份，变量独立，在不同的地址中，不是共用的。*** **FIFO**FIFO也称为**命名管道**，是一种**文件类型**1. **特点** - FIFO可以在**无关的进程**之间交换数据，与无名管道不同 - FIFO有路径名与之相关联，以一种特殊设备文件形式存在于**文件系统**中2. **原型** ```c++ #include &lt;sys/stat.h&gt; // 返回值：成功返回0，出错返回-1 int mkfifo(const char *pathname, mode_t mode); 其中的 mode 参数与`open`函数中的 mode 相同。一旦创建了一个 FIFO，就可以**用一般的文件I/O函数操作**它。 当 open 一个FIFO时，是否设置非阻塞标志（`O_NONBLOCK`）的区别： - 若没有指定`O_NONBLOCK`（默认），只读 open 要阻塞到某个其他进程为写而打开此 FIFO。类似的，只写 open 要阻塞到某个其他进程为读而打开它。 - 若指定了`O_NONBLOCK`，则只读 open 立即返回。而只写 open 将出错返回 -1 如果没有进程已经为读而打开该 FIFO，其errno置ENXIO。 3. **例子** FIFO的通信方式类似于在进程中**使用文件来传输数据**，只不过FIFO类型文件同时具有管道的特性。在数据读出时，FIFO管道中同时清除数据，并且**“先进先出”**。下面的例子演示了使用 FIFO 进行 IPC 的过程： ![Screen Shot 2019-08-06 at 4.52.48 PM](/Users/liutao/Desktop/screenshot/Screen%20Shot%202019-08-06%20at%204.52.48%20PM.png) **消息队列** 是**消息的链表**，存放在**内核中**，一个**消息队列**由一个**标识符即队列ID）**来标识 1. 特点 - 消息队列面向记录，其中的**消息具有特定的格式和特定的优先级** - 消息队列**独立于发送与接收进程**。进程终止时，消息队列及其内容并不会被删除 - 消息队列**可以实现消息的随机查询**，**不一定要先进先出的次序读取**，可以按消息的类型读取 2. 原型 1234567891 #include &lt;sys/msg.h&gt;2 // 创建或打开消息队列：成功返回队列ID，失败返回-13 int msgget(key_t key, int flag);4 // 添加消息：成功返回0，失败返回-15 int msgsnd(int msqid, const void *ptr, size_t size, int flag);6 // 读取消息：成功返回消息数据的长度，失败返回-17 int msgrcv(int msqid, void *ptr, size_t size, long type,int flag);8 // 控制消息队列：成功返回0，失败返回-19 int msgctl(int msqid, int cmd, struct msqid_ds *buf); 在以下两种情况下，`msgget`将创建一个新的消息队列： - 如果没有与键值key相对应的消息队列，并且flag中包含了`IPC_CREAT`标志位。 - key参数为`IPC_PRIVATE`。 函数`msgrcv`在读取消息队列时，type参数有下面几种情况： - `type == 0`，返回队列中的第一个消息； - `type &gt; 0`，返回队列中消息类型为 type 的第一个消息； - `type &lt; 0`，返回队列中消息类型值小于或等于 type 绝对值的消息，如果有多个，则取类型值最小的消息。 可以看出，type值非 0 时用于以非先进先出次序读消息。也可以把 type 看做优先级的权值。（其他的参数解释，请自行Google之） **信号量** 信号量（semaphore）与已经介绍过的IPC结构不同，它是一个**计数器**，用于**实现进程间的互斥与同步**，**而不是用于存储进程间通信数据** 1. **特点** - 信号量用于进程间同步，若要在进程间**传递数据需要结合共享内存** - 信号量**基于操作系统的PV操作**，程序**对信号量的操作都是原子操作** 每次对信号量的PV操作不仅限于对信号量值+1或-1，而且可以任意加减正整数 支持信号量组 首先应弄清PV操作的含义：PV操作由P操作原语和V操作原语组成（原语是不可中断的过程），对信号量进行操作，具体定义如下： P（S）：**表示pass**①将信号量S的值减1，即S=S-1；②如果S&gt;0，则该进程继续执行；否则该进程置为等待状态，排入等待队列。 V（S）：**表示释放**①将信号量S的值加1，即S=S+1；②如果S&gt;0，则该进程继续执行；否则释放队列中第一个等待信号量的进程。PV操作的意义：我们用信号量及PV操作来实现进程的同步和互斥。PV操作属于进程的低级通信 原型 最简单的信号量是只能取 0 和 1 的变量，这也是信号量最常见的一种形式，叫做二值信号量（Binary Semaphore）。而可以取多个正整数的信号量被称为通用信号量。 Linux下的信号量函数都是在通用的信号量数组上进行操作 1234567#include &lt;sys/sem.h&gt;// 创建或获取一个信号量组：若成功返回信号量集ID，失败返回-1int semget(key_t key, int num_sems, int sem_flags);// 对信号量组进行操作，改变信号量的值：成功返回0，失败返回-1int semop(int semid, struct sembuf semoparray[], size_t numops); // 控制信号量的相关信息int semctl(int semid, int sem_num, int cmd, ...); 当semget创建新的信号量集合时，必须指定集合中信号量的个数（即num_sems），通常为1； 如果是引用一个现有的集合，则将num_sems指定为 0 在semop函数中，sembuf结构的定义如下： 123456struct sembuf &#123; short sem_num; // 信号量组中对应的序号，0～sem_nums-1 short sem_op; // 信号量值在一次操作中的改变量 short sem_flg; // IPC_NOWAIT, SEM_UNDO&#125; 其中 sem_op 是一次操作中的信号量的改变量： 若sem_op &gt; 0，表示进程释放相应的资源数，将 sem_op 的值加到信号量的值上。如果有进程正在休眠等待此信号量，则换行它们。 若sem_op &lt; 0，请求 sem_op 的绝对值的资源。 如果相应的资源数可以满足请求，则将该信号量的值减去sem_op的绝对值，函数成功返回。 当相应的资源数不能满足请求时，这个操作与 12345678有关。- sem_flg 指定`IPC_NOWAIT`，则semop函数出错返回`EAGAIN`。- sem_flg 没有指定 ```IPC_NOWAIT ，则将该信号量的semncnt值加1，然后进程挂起直到下述情况发生： 当相应的资源数可以满足请求，此信号量的semncnt值减1，该信号量的值减去sem_op的绝对值。成功返回； 此信号量被删除，函数smeop出错返回EIDRM； 进程捕捉到信号，并从信号处理函数返回，此情况下将此信号量的semncnt值减1，函数semop出错返回EINTR 若sem_op == 0，进程阻塞直到信号量的相应值为0： 当信号量已经为0，函数立即返回。 如果信号量的值不为0，则依据 12345678决定函数动作：- sem_flg指定`IPC_NOWAIT`，则出错返回`EAGAIN`。- sem_flg没有指定 ```IPC_NOWAIT ，则将该信号量的semncnt值加1，然后进程挂起直到下述情况发生： 信号量值为0，将信号量的semzcnt的值减1，函数semop成功返回； 此信号量被删除，函数smeop出错返回EIDRM； 进程捕捉到信号，并从信号处理函数返回，在此情况将此信号量的semncnt值减1，函数semop出错返回EINTR 在semctl函数中的命令有多种，这里就说两个常用的： SETVAL：用于初始化信号量为一个已知的值。所需要的值作为联合semun的val成员来传递。在信号量第一次使用之前需要设置信号量。 IPC_RMID：删除一个信号量集合。如果不删除信号量，它将继续在系统中存在，即使程序已经退出，它可能在你下次运行此程序时引发问题，而且信号量是一种有限的资源。 **共享内存** 共享内存（Shared Memory），指**两个或者多个进程共享一个给定的存储区** 1. **特点** - 共享内存时**最快的一种IPC**，因为进程是**直接对内存进行存取** - 因为**多个进程可以同时操作**，所以**需要进行同步** - **信号量+共享内存**通常**结合在一起**使用，**信号量用来同步**对共享内存的**访问** 2. 原型 123456789#include &lt;sys/shm.h&gt;// 创建或获取一个共享内存：成功返回共享内存ID，失败返回-1int shmget(key_t key, size_t size, int flag);// 连接共享内存到当前进程的地址空间：成功返回指向共享内存的指针，失败返回-1void *shmat(int shm_id, const void *addr, int flag);// 断开与共享内存的连接：成功返回0，失败返回-1int shmdt(void *addr); // 控制共享内存的相关信息：成功返回0，失败返回-1int shmctl(int shm_id, int cmd, struct shmid_ds *buf); 当用`shmget`函数创建一段共享内存时，必须指定其 size；而如果引用一个已存在的共享内存，则将 size 指定为0 。 当一段共享内存被创建以后，它并不能被任何进程访问。必须使用`shmat`函数连接该共享内存到当前进程的地址空间，连接成功后把共享内存区对象映射到调用进程的地址空间，随后可像本地空间一样访问。 `shmdt`函数是用来断开`shmat`建立的连接的。注意，这并不是从系统中删除该共享内存，只是当前进程不能再访问该共享内存而已。 `shmctl`函数可以对共享内存执行多种操作，根据参数 cmd 执行相应的操作。常用的是`IPC_RMID`（从系统中删除该共享内存）。 使用**【共享内存+信号量+消息队列】**的组合来实现服务器进程与客户进程间的通信。 - 共享内存用来传递数据； - 信号量用来同步； - 消息队列用来 在客户端修改了共享内存后 通知服务器读取。 **匿名管道与命名管道的区别**：匿名管道只能在具有公共祖先的两个进程间使用。 **共享文件映射mmap** mmap建立进程空间到文件的映射，在建立的时候并不直接将文件拷贝到物理内存，同样采用缺页终端。mmap映射一个具体的文件可以实现任意进程间共享内存，映射一个匿名文件，可以实现父子进程间共享内存。 **常见的信号有哪些？**：SIGINT，SIGKILL(不能被捕获)，SIGTERM(可以被捕获)，SIGSEGV，SIGCHLD，SIGALRM 内存管理 为什么叫内存的抽象：用户使用的4GB地址空间并不是一一对应着物理内存的4GB，具体的实现被封装了，所以叫做内存抽象 如果同时运行的程序太多，物理内存装不下怎么办？ 因此出现了两种技术：交换技术和虚拟内存 交换技术 就是当内存满了之后，就将一个程序从内存中换出，将另一个程序放入内存，换出的内存数据保存在硬盘上，当该程序再次被换入时，再将硬盘上的数据拷贝到内存 虚拟内存 每次交换一整个进程，速度非常慢，不能够容忍 操作系统为了管理内存，给每个进程分配独立的地址空间，对32位系统而言，这个空间的大小时4GB。但这4GB不是实际的物理内存，实际上并不存在，因此称为虚拟内存 实际物理内存——物理地址 虚拟内存——逻辑地址 虚拟地址空间/物理地址空间都被分成大小相同的页， 虚拟地址的页通过一个页表映射物理内存的页 CPU使用逻辑地址，当进程要访问该进程地址空间里的某个地址的时候，将该地址传递给CPU，CPU访问该地址，经过MMU将逻辑地址换为物理地址，之前说的页表就保存在MMU中，操作系统为每个进程维护一个页表 为什么会快？？ 如果所有数据在页表中都有对应项，那么虚拟地址没有任何意义了。实际上内存中只有部分数据，在内存中只有部分页面和页框有对应值。其余的页表的数据保存在硬盘一块固定的地方，Linux中叫swap分区/windows在C盘中。当访问到某个页面在物理内存中没有对应的页时就会发生缺页中断，这时候操作系统就将该页面保存在硬盘中的数据拷贝到物理内存中，并更新页表建立该页面和对应页框之间的映射关系 这样做就实现了每次交换的代价很小，但是物理地址空间还是可能不够用，因此操作系统交换一些数据进物理内存的时候，也会从物理内存中移除部分页框数据到硬盘上，那到底该移出谁呢？这就涉及到页面交换算法了。 Linux内存管理简介 进程具有独立的地址空间，对于32位的系统而言，该地址空间的大小是4GB。Linux将这4GB的地址空间分为两部分，一个是用户地址空间，一个是内核地址空间。内核地址空间的地址范围范围为3G到4G，用户地址空间的地址范围为0G到3G。这里所讲的0G到4G都是虚拟地址，也称为逻辑地址 Linux对内核空间和用户空间是分别管理的——因为进程要么运行在用户态，要么运行在内核态，进程通过系统调用进入内核态 内核空间 内核空间的逻辑地址范围在3GB到4GB，并且内核空间是线性映射到物理空间的。何为线性映射，举例说明，内核空间逻辑地址0xc0000000对应的物理地址是0x00000000，逻辑地址0xc0000001对应的物理地址是0x00000001，也就是说逻辑地址到物理都减了一个0xc0000000的偏移量。如果1GB都是这样映射的话，那么内核空间能使用物理地址范围在0x00000000到0x40000000之间，不能访问所有的物理地址了。线性映射意味着偏移量相同 为了解决这个问题，内核空间就将物理内存分为三个区：ZONE_DMA，ZONE_NORMAL，ZONE_HIHGEM。DMA区是用于一些特殊设备的，我们不过多追究。主要讨论高端内存(ZONE_HIHGEM)，对于内核空间而言高于896M的空间称为高端内存，低于896M的自然就可以称为低端内存了，低端内存的范围上，逻辑地址与物理地址是线性映射的。对于内核空间896M以上剩余的128M是用来访问高端内存的。这128M里的页面到物理页框随机映射的，和用户空间的映射是一样的。低端内存是自动永久映射的，高端内存可以永久映射也可以零时映射。 前面两端主要将的是对页表页框的管理，后面再将如何分配内存，也就是如果内核需要一定大小的内存的时，在3GB到4GB的范围里取出拿一块给它。内核空间分配内存可以按页分配，采用alloc_pages()和free_pages()函数分配多个连续页大小的内存，也可以通过kmalloc()分配指定大小的内存。 内核分配内存时很多时候都是分配固定大小的内存块，比如为每一个进程维护的task_struct结构体等。频繁分配这样的小块，很容易造成内存碎片，自然想到用内存池的方法来解决内存碎片的问题，只不过在Linux中给其取了一个更高大上的名字，叫高速缓存cache与slab层。一个高速缓存中有多个slab，分为三类：满的，部分满，和空的。每个slab就是一个链表，链表的每个节点就是一块固定大小的内存。和内存池是一样的 用户空间 这张图解释了，一个进程将数据分为代码段，数据段，BSS段，堆和栈。 PS：BSS段通常是指用来存放程序中未初始化的或者初始化为0的全局变量全局变量和静态变量的一块内存区域。特点是可读写的，在程序执行之前BSS段会自动清0。 在采用段式内存管理的架构中，数据段（data segment）通常是指用来存放程序中已初始化且不为0的全局变量的一块内存区域、数据段属于静态内存分配 实际上这些数据分享了0GB到3GB的地址范围。Linux管理这些段采用分区的结构，为每一个段维护一个vm_area_struct的结构体。这些结构体中保存了指向下一个指针因此形成了链表，还有另外一个指针使其构成红黑树，用户快速查找。 对于用户空间不得不谈到malloc函数，malloc函数是动态分配内存，内存来自用户空间的堆区。操作系统通过链表的形式将堆区的空间贯穿起来，当需要动态分配内存时就去查询该链表，找到空闲块，如果堆区满了，就调用sbrk函数扩大堆的范围。 当分配内存时，操作系统去查询该链表，找到一块能容纳下的地方放进去，将剩余的返还给空闲表。如何找到这个容纳的地方有出现了多种算法：首次适配算法，第二次首次适配，最佳适配算法，最差适配算法。这四个算法你可以去细讲差别，首次适配第一次找到第一个大于需要的地址空间的块，每次都从表头开始找，第二次着从上次找到的位置开始找，最佳适配找一个和需要大小最接近比需要的大的，最差每次早最大的。实际上对于进程内部堆的分配，页可以采取同样类似的办法。具体可以去看malloc的源码。 另外还有一点很重要的是内存映射文件，内存映射文件通过mmap函数实现，将文件映射到内存中，读写文件通过操作指针就能实现。实际上，内存映射文件并不是调用mmap的时候就将该文件拷贝到内存中，而是建立逻辑地址到文件地址之间的映射关系，但访问这段内存的数据时还是引发缺页中断，然后将该页的数据换到物理地址上。可以直接使用mmap实现进程间内存共享，XSI的内存共享实现的原理也是基于mmap，只是映射一种特殊文件系统的文件到内存中，该文件不能通过read和write调用来访问 进程调度 Linux进程分为两种，实时进程和非实时进程（普通进程）； 实时进程的优先级（099）都比普通进程的优先级（100139）高 优先级越小——越高 调度策略task_struct-&gt;unsigned long policy;指定调度策略#define SCHED_NORMAL 0 //非实时进程，CFS#define SCHED_FIFO 1 //实时进程，先进先出，它就一直运行直到退出，除非它阻塞才会释放CPU, 或被更高优先级的实时进程抢占。#define SCHED_RR 2 //实时进程，基于优先级的轮回法（Round Robin），只有当它的时间片用完，内核会把它放到进程队列的末尾。 优先级分为静态优先级和动态优先级，优先级的范围； 内核代码中有四种优先级，dynamic priority 、normal priority、static priority、以及实时进程的rt_priority static priority 范围是100-139 实时进程的rt_priority 每个实时进程都有一与其相关的实时优先级，范围0-99 其大小可以通过sched_setscheduler()和__setscheduler_params()来改变。实时进程被一个进程替换，可能的情况有：a)进程被拥有更高优先级的进程抢占。b)进程发生阻塞进入睡眠状态。c)进程被终止（状态为TASK_STOPPED OR TASK_TRACED）或者被杀死（EXIT_DEAD OR EXIT_ZOMBIE）。d)进程通过调用sched_yield()自愿放弃处理器。e)进程是轮回实时（SCHED_RR）且其时间片执行完毕。f)当在SCHED_RR时调用nice()和set_priority()函数并不影响实时优先级，只会影响静态优先级（从而影响基时间片） normal priority 和 dynamic priority task_has_rt_policy()用来区分进程是否是实时进程（）如果进程是普通进程，那么normal_prio被设置为static_prio，（prio也等于static_prio？），dynamic priority = normal priority = static priority如果进程是实时进程，那么normal_prio被设置成（MAX_RT_PRIO-1 - p-&gt;rt_priority），prio被设置成（MAX_RT_PRIO-1 - p-&gt;rt_priority）。rt_priority的值越大，实时优先级越高。 调度策略 先来先服务调度算法FCFS：进程/作业调度 进程调度中采用FCFS算法时，则每次调度是从就绪队列中选择一个最先进入该队列的进程，为之分配处理机，使之投入运行。该进程一直运行到完成或发生某事件而阻塞后才放弃处理机。 每次调度都是从后备作业队列中选择一个或多个最先进入该队列的作业，将它们调入内存，为它们分配资源、创建进程，然后放入就绪队列 短进程（作业）优先调度算法 SPF - Short Process First 指对短作业或短进程优先调度的算法 短进程优先(SPF)调度算法则是从就绪队列中选出一个估计运行时间最短的进程，将处理机分配给它，使它立即执行并一直执行到完成，或发生某事件而被阻塞放弃处理机时再重新调度。 高优先权优先调度算法（FPF） 算法常被用于批处理系统中，作为作业调度算法，也作为多种操作系统中的进程调度算法，还可用于实时系统中。当把该算法用于作业调度时，系统将从后备队列中选择若干个优先权最高的作业装入内存。当用于进程调度时，该算法是把处理机分配给就绪队列中优先权最高的进程， 该算法又可进一步分为以下两种： 非抢占式优先权算法 系统一旦把处理机分配给就绪队列中优先权最高的进程后，该进程便一直执行下去，直至完成；或因发生某事件使该进程放弃处理机时，系统方可再将处理机重新分配给另一优先权最高的进程 这种调度算法主要用于批处理系统中；也可用于某些对实时性要求不严的实时系统中。 抢占式优先权算法 抢占式优先权调度算法：在这种方式下，系统同样是把处理机分配给优先权最高的进程，使之执行。但在其执行期间，只要又出现了另一个其优先权更高的进程，进程调度程序就立即停止当前进程(原优先权最高的进程)的执行，重新将处理机分配给新到的优先权最高的进程。因此，在采用这种调度算法时，是每当系统中出现一个新的就绪进程i 时，就将其优先权Pi与正在执行的进程j 的优先权Pj进行比较。如果Pi≤Pj，原进程Pj便继续执行；但如果是Pi&gt;Pj，则立即停止Pj的执行，做进程切换，使i 进程投入执行。显然，这种抢占式的优先权调度算法能更好地满足紧迫作业的要求，故而常用于要求比较严格的实时系统中，以及对性能要求较高的批处理和分时系统中。 高响应比优先调度算法 在批处理系统中，短作业优先算法是一种比较好的算法，其主要的不足之处是长作业的运行得不到保证。如果我们能为每个作业引入前面所述的动态优先权，并使作业的优先级随着等待时间的增加而以速率a 提高，则长作业在等待一定的时间后，必然有机会分配到处理机。该优先权的变化规律可描述为： 在利用该算法时，每要进行调度之前，都须先做响应比的计算，这会增加系统开销。 时间片轮转算法 在早期的时间片轮转法中，系统将所有的就绪进程按先来先服务的原则排成一个队列，每次调度时，把CPU 分配给队首进程，并令其执行一个时间片。时间片的大小从几ms 到几百ms。当执行的时间片用完时，由一个计时器发出时钟中断请求，调度程序便据此信号来停止该进程的执行，并将它送往就绪队列的末尾；然后，再把处理机分配给就绪队列中新的队首进程，同时也让它执行一个时间片。这样就可以保证就绪队列中的所有进程在一给定的时间内均能获得一时间片的处理机执行时间。换言之，系统能在给定的时间内响应所有用户的请求。 多级反馈队列调度算法 多级反馈队列调度算法则不必事先知道各种进程所需的执行时间，而且还可以满足各种类型进程的需要，因而它是目前被公认的一种较好的进程调度算法。在采用多级反馈队列调度算法的系统中，调度算法的实施过程如下所述 (1) 应设置多个就绪队列，并为各个队列赋予不同的优先级。第一个队列的优先级最高，第二个队列次之，其余各队列的优先权逐个降低。该算法赋予各个队列中进程执行时间片的大小也各不相同，在优先权愈高的队列中，为每个进程所规定的执行时间片就愈小。例如，第二个队列的时间片要比第一个队列的时间片长一倍，……，第i+1个队列的时间片要比第i个队列的时间片长一倍。 (2)当一个新进程进入内存后，首先将它放入第一队列的末尾，按FCFS原则排队等待调度。当轮到该进程执行时，如它能在该时间片内完成，便可准备撤离系统；如果它在一个时间片结束时尚未完成，调度程序便将该进程转入第二队列的末尾，再同样地按FCFS原则等待调度执行；如果它在第二队列中运行一个时间片后仍未完成，再依次将它放入第三队列，……，如此下去，当一个长作业(进程)从第一队列依次降到第n队列后，在第n 队列便采取按时间片轮转的方式运行。 (3) 仅当第一队列空闲时，调度程序才调度第二队列中的进程运行；仅当第1～(i-1)队列均空时，才会调度第i队列中的进程运行。如果处理机正在第i队列中为某进程服务时，又有新进程进入优先权较高的队列(第1～(i-1)中的任何一个队列)，则此时新进程将抢占正在运行进程的处理机，即由调度程序把正在运行的进程放回到第i队列的末尾，把处理机分配给新到的高优先权进程。 交互进程通过平均睡眠时间而被奖励； 死锁 死锁的概念 多个进程都被阻塞，并一直处于这样的状态，这种状态称为死锁 死锁的分类 两类，资源死锁和通信死锁 资源死锁是由于多个进程/线程同时获取多个资源时发生 通信死锁是由于网络延时或丢包，导致两个进程都在等待对方的数据。可以通过超时重发机制解决 死锁四个条件 互斥条件。——一个资源不能同时被多个进程访问 占有和等待条件——一个资源被另一个进程占用，该进程只能等待 不可抢占。已经分配给某个进程的资源，不能通过调度的方式抢占该资源 环路等待条件。多个进程和资源组成环路 如上图中，p1和p2表示两个进程，s1和s2表示资源。有向图成环，发生死锁。同时占有彼此等待的资源并请求 解决死锁四种策略 忽略该问题 检测死锁并恢复——意思是系统中会产生死锁 检测每种资源只有一个的情况可以通过判断资源和进程构成的有向图是否有环来判定是否有死锁，每种资源有多个的情况可以通过资源矩阵检测是否存在死锁。 恢复 抢占式恢复。——破坏不可抢占的条件 回滚恢复。恢复到上一个没有占用资源的状态，进程的部分工作丢失——进程回滚后让出资源，打破环路等待 杀死部分进程。从发生死锁的进程中，杀死部分进程，释放占用的资源——直接杀死进程来释放资源，打破环路等待条件 仔细分配资源 破坏死锁条件 破坏互斥条件。通过虚拟技术或者其他，使得资源可以同时被多个进程使用。 破坏占有和等待条件。进程在获取资源前，先判断资源是否都可取，一次性获取所有资源。问题在于，进程并不知道它后面会需要哪些资源。比如还可以用trylock，timelock来代替lock避免永久阻塞。 破坏不可抢占。虚拟化技术 避免成环。按照严格的顺序进行加锁，如果不能获取资源就回滚释放占用的部分资源。比如，所有的地方都按照对1加锁，然后对2加锁，就不会成环了。如果线程先对1加锁成功，然后对2加锁，如果加锁失败，就释放资源1。 命令行 Linux命令 在一个文件中，倒序打印第二行前100个大写字母 1cat filename | head -n 2 | tail -n 1 | grep &apos;[[:upper:]]&apos; -o | tr -d &apos;\n&apos;| cut -c 1-100 | rev 与CPU，内存，磁盘相关的命令(top，free, df, fdisk) top [参数] ​ 查看各个进程系统资源的占用情况。类似于windows的任务管理器 ​ 显示当前系统正在执行的进程的相关信息，包括进程ID、内存占用率 ​ CPU占用率等 ​ 命令参数：-b 批处理 ​ -c 显示完整的治命令 ​ -I 忽略失效过程 ​ -s 保密模式 ​ -S 累积模式 ​ -i&lt;时间&gt; 设置间隔时间 ​ -u&lt;用户名&gt; 指定用户名 ​ -p&lt;进程号&gt; 指定进程 ​ -n&lt;次数&gt; 循环显示的次数 **free [参数] ** 显示系统使用和空闲的**内存情况**，包括物理内存，交互区内存(swap)和内核缓冲区内存。共享内存将被忽略 -b 以Byte为单位显示内存使用情况。 -k 以KB为单位显示内存使用情况。 -m 以MB为单位显示内存使用情况。 -g 以GB为单位显示内存使用情况。 -o 不显示缓冲区调节列。 -s&lt;间隔秒数&gt; 持续观察内存使用状况。 -t 显示内存总和列。 -V 显示版本信息。 **df [选项] [文件]** 用来检查linux服务器的**文件系统的磁盘占用情况**。可以利用该命令来获取**硬盘被占用了多少空间，目前还剩下多少空间**等信息。 显示指定磁盘文件的可用空间。如果没有文件名被指定，则所有当前被挂载的文件系统的可用空间将被显示。默认情况下，磁盘空间将以 1KB 为单位进行显示，除非环境变量 POSIXLY_CORRECT 被指定，那样将以512字节为单位进行显示 **必要参数：** -a 全部文件系统列表 -h 方便阅读方式显示 -H 等于“-h”，但是计算式，1K=1000，而不是1K=1024 -i 显示inode信息 -k 区块为1024字节 -l 只显示本地文件系统 -m 区块为1048576字节 --no-sync 忽略 sync 命令 -P 输出格式为POSIX --sync 在取得磁盘信息前，先执行sync命令 -T 文件系统类型 **选择参数：** --block-size=&lt;区块大小&gt; 指定区块大小 -t&lt;文件系统类型&gt; 只显示选定文件系统的磁盘信息 -x&lt;文件系统类型&gt; 不显示选定文件系统的磁盘信息 --help 显示帮助信息 --version 显示版本信息 **fdisk [选项] [参数]** **fdisk命令**用于观察硬盘实体使用情况，也可对硬盘分区。它采用传统的问答式界面，而非类似DOS fdisk的cfdisk互动式操作界面，因此在使用上较为不便，但功能却丝毫不打折扣。 **必要参数：** - -l 列出素所有分区表 - -u 与&quot;-l&quot;搭配使用，显示分区数目 **选择参数：** - -s&lt;分区编号&gt; 指定分区 - -v 版本信息 网络相关的命令netstat，tcpdump等 netstat： netstat命令用于显示与IP、TCP、UDP和ICMP协议相关的统计数据，一般用于检验本机各端口的网络连接情况。netstat是在内核中访问网络及相关信息的程序，它能提供TCP连接，TCP和UDP监听，进程内存管理的相关报告。 如果你的计算机有时候接收到的数据报导致出错数据或故障，你不必感到奇怪，TCP/IP可以容许这些类型的错误，并能够自动重发数据报。但如果累计的出错情况数目占到所接收的IP数据报相当大的百分比，或者它的数目正迅速增加，那么你就应该使用netstat查一查为什么会出现这些情况了。 命令格式：[-acCeFghilMnNoprstuvVwx][-A][--ip]```123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960netstat用于显示与IP、TCP、UDP和ICMP协议相关的统计数据，一**般用于检验本机各端口的网络连接**情况。**命令参数**-a或–all 显示所有连线中的Socket。-A&lt;网络类型&gt;或–&lt;网络类型&gt; 列出该网络类型连线中的相关地址。-c或–continuous 持续列出网络状态。-C或–cache 显示路由器配置的快取信息。-e或–extend 显示网络其他相关信息。-F或–fib 显示FIB。-g或–groups 显示多重广播功能群组组员名单。-h或–help 在线帮助。-i或–interfaces 显示网络界面信息表单。-l或–listening 显示监控中的服务器的Socket。-M或–masquerade 显示伪装的网络连线。-n或–numeric 直接使用IP地址，而不通过域名服务器。-N或–netlink或–symbolic 显示网络硬件外围设备的符号连接名称。-o或–timers 显示计时器。-p或–programs 显示正在使用Socket的程序识别码和程序名称。-r或–route 显示Routing Table。-s或–statistice 显示网络工作信息统计表。-t或–tcp 显示TCP传输协议的连线状况。-u或–udp 显示UDP传输协议的连线状况。-v或–verbose 显示指令执行过程。-V或–version 显示版本信息。-w或–raw 显示RAW传输协议的连线状况。-x或–unix 此参数的效果和指定”-A unix”参数相同。–ip或–inet 此参数的效果和指定”-A inet”参数相同。**tcpdump：**是一个**运行在命令行下的抓包工具**。它允许用户拦截和显示发送或收到过网络连接到该计算机的TCP/IP和其他数据包**命令格式**： tcpdump [ -adeflnNOpqStvx ] [ -c 数量 ] [ -F 文件名 ][ -i 网络接口 ] [ -r 文件名] [ -s snaplen ][ -T 类型 ][-w 文件名 ] [表达式 ] 12345678910111213141516-a 将网络地址和广播地址转变成名字； -d 将匹配信息包的代码以人们能够理解的汇编格式给出； -dd 将匹配信息包的代码以c语言程序段的格式给出； -ddd 将匹配信息包的代码以十进制的形式给出； -e 在输出行打印出数据链路层的头部信息，包括源mac和目的mac，以及网络层的协议； -f 将外部的Internet地址以数字的形式打印出来； -l 使标准输出变为缓冲行形式； -n 指定将每个监听到数据包中的域名转换成IP地址后显示，不把网络地址转换成名字； -nn： 指定将每个监听到的数据包中的域名转换成IP、端口从应用名称转换成端口号后显示 123456789101112 -t 在输出的每一行不打印时间戳； -v 输出一个稍微详细的信息，例如在ip包中可以包括ttl和服务类型的信息； -vv 输出详细的报文信息； -c 在收到指定的包的数目后，tcpdump就会停止； -F 从指定的文件中读取表达式,忽略其它的表达式； -i 指定监听的网络接口； -p： 将网卡设置为非混杂模式，不能与host或broadcast一起使用 1234 -r 从指定的文件中读取包(这些包一般通过-w选项产生)； -w 直接将包写入文件中，并不分析和打印出来； -s snaplen snaplen表示从一个包中截取的字节数。0表示包不截断，抓完整的数据包。默认的话 tcpdump 只显示部分数据包,默认68字节。12 -T 将监听到的包直接解释为指定的类型的报文，常见的类型有rpc （远程过程调用）和snmp（简单网络管理协议；） -X 告诉tcpdump命令，需要把协议头和包内容都原原本本的显示出来（tcpdump会以16进制和ASCII的形式显示），这在进行协议分析时是绝对的利器。1234563. sed, awk, grep三个超强大的命名，分别用与格式化修改，统计，和正则查找 **sed**：格式化修改 sed 是一种在线编辑器，它一次处理一行内容。处理时，把当前处理的行存储在临时缓冲区中，称为“模式空间”（pattern space），接着用sed命令处理缓冲区中的内容，处理完成后，把缓冲区的内容送往屏幕。接着处理下一行，这样不断重复，直到文件末尾。文件内容并没有 改变，除非你使用重定向存储输出。Sed主要用来自动编辑一个或多个文件；简化对文件的反复操作；编写转换程序等 [root@www ~]# sed [-nefr] [动作]选项与参数：-n ：使用安静(silent)模式。在一般 sed 的用法中，所有来自 STDIN 的数据一般都会被列出到终端上。但如果加上 -n 参数后，则只有经过sed 特殊处理的那一行(或者动作)才会被列出来。-e ：直接在命令列模式上进行 sed 的动作编辑；-f ：直接将 sed 的动作写在一个文件内， -f filename 则可以运行 filename 内的 sed 动作；-r ：sed 的动作支持的是延伸型正规表示法的语法。(默认是基础正规表示法语法)-i ：直接修改读取的文件内容，而不是输出到终端。 动作说明： [n1[,n2]]functionn1, n2 ：不见得会存在，一般代表『选择进行动作的行数』，举例来说，如果我的动作是需要在 10 到 20 行之间进行的，则『 10,20[动作行为] 』 function：a ：新增， a 的后面可以接字串，而这些字串会在新的一行出现(目前的下一行)～c ：取代， c 的后面可以接字串，这些字串可以取代 n1,n2 之间的行！d ：删除，因为是删除啊，所以 d 后面通常不接任何咚咚；i ：插入， i 的后面可以接字串，而这些字串会在新的一行出现(目前的上一行)；p ：列印，亦即将某个选择的数据印出。通常 p 会与参数 sed -n 一起运行～s ：取代，可以直接进行取代的工作哩！通常这个 s 的动作可以搭配正规表示法！例如 1,20s/old/new/g 就是啦！ 12345678910**awk**：统计awk是一个强大的文本分析工具，相对于grep的查找，sed的编辑，awk在其对数据分析并生成报告时，显得尤为强大。简单来说awk就是把文件逐行的读入，以空格为默认分隔符将每行切片，切开的部分再进行各种分析处理。awk有3个不同版本: awk、nawk和gawk，未作特别说明，一般指gawk，gawk 是 AWK 的 GNU 版本。语法： awk [选项参数] ‘script’ var=value file(s)或awk [选项参数] -f scriptfile var=value file(s) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183 - -F fs or --field-separator fs 指定输入文件折分隔符，fs是一个字符串或者是一个正则表达式，如-F:。 - -v var=value or --asign var=value 赋值一个用户定义变量。 - -f scripfile or --file scriptfile 从脚本文件中读取awk命令。 - -mf nnn and -mr nnn 对nnn值设置内在限制，-mf选项限制分配给nnn的最大块数目；-mr选项限制记录的最大数目。这两个功能是Bell实验室版awk的扩展功能，在标准awk中不适用。 - -W compact or --compat, -W traditional or --traditional 在兼容模式下运行awk。所以gawk的行为和标准的awk完全一样，所有的awk扩展都被忽略。 - -W copyleft or --copyleft, -W copyright or --copyright 打印简短的版权信息。 - -W help or --help, -W usage or --usage 打印全部awk选项和每个选项的简短说明。 - -W lint or --lint 打印不能向传统unix平台移植的结构的警告。 - -W lint-old or --lint-old 打印关于不能向传统unix平台移植的结构的警告。 - -W posix 打开兼容模式。但有以下限制，不识别：/x、函数关键字、func、换码序列以及当fs是一个空格时，将新行作为一个域分隔符；操作符**和**=不能代替^和^=；fflush无效。 - -W re-interval or --re-inerval 允许间隔正则表达式的使用，参考(grep中的Posix字符类)，如括号表达式[[:alpha:]]。 - -W source program-text or --source program-text 使用program-text作为源代码，可与-f命令混用。 - -W version or --version 打印bug报告信息的版本。 **grep**：正则查找 Linux系统中grep命令是一种强大的文本搜索工具，它能使用正则表达式搜索文本，并把匹 配的行打印出来。grep全称是Global Regular Expression Print，表示**全局正则表达式**版本，它的使用权限是所有用户。 grep的工作方式是这样的，它在一**个或多个文件中**搜索**字符串模板**。如果模板包括空格，则必须被引用，模板后的所有字符串被看作文件名。搜索的结果被送到标准输出，不影响原文件内容。 grep可用于shell脚本，因为grep通过返回一个状态值来说明搜索的状态，如果模板搜索成功，则返回0，如果搜索不成功，则返回1，如果搜索的文件不存在，则返回2。我们利用这些返回值就可进行一些自动化的文本处理工作 **命令格式** grep [option] pattern file **命令功能** 用于过滤/搜索特定字符。可食用正则表达式 能与多种命令配合使用，十分灵活 **命令参数** -a --text #不要忽略二进制的数据。 -A&lt;显示行数&gt; --after-context=&lt;显示行数&gt; #除了显示符合范本样式的那一列之外，并显示该行之后的内容。 -b --byte-offset #在显示符合样式的那一行之前，标示出该行第一个字符的编号。 -B&lt;显示行数&gt; --before-context=&lt;显示行数&gt; #除了显示符合样式的那一行之外，并显示该行之前的内容。 -c --count #计算符合样式的列数。 -C&lt;显示行数&gt; --context=&lt;显示行数&gt;或-&lt;显示行数&gt; #除了显示符合样式的那一行之外，并显示该行之前后的内容。 -d &lt;动作&gt; --directories=&lt;动作&gt; #当指定要查找的是目录而非文件时，必须使用这项参数，否则grep指令将回报信息并停止动作。 -e&lt;范本样式&gt; --regexp=&lt;范本样式&gt; #指定字符串做为查找文件内容的样式。 -E --extended-regexp #将样式为延伸的普通表示法来使用。 -f&lt;规则文件&gt; --file=&lt;规则文件&gt; #指定规则文件，其内容含有一个或多个规则样式，让grep查找符合规则条件的文件内容，格式为每行一个规则样式。 -F --fixed-regexp #将样式视为固定字符串的列表。 -G --basic-regexp #将样式视为普通的表示法来使用。 -h --no-filename #在显示符合样式的那一行之前，不标示该行所属的文件名称。 -H --with-filename #在显示符合样式的那一行之前，表示该行所属的文件名称。 -i --ignore-case #忽略字符大小写的差别。 -l --file-with-matches #列出文件内容符合指定的样式的文件名称。 -L --files-without-match #列出文件内容不符合指定的样式的文件名称。 -n --line-number #在显示符合样式的那一行之前，标示出该行的列数编号。 -q --quiet或--silent #不显示任何信息。 -r --recursive #此参数的效果和指定“-d recurse”参数相同。 -s --no-messages #不显示错误信息。 -v --revert-match #显示不包含匹配文本的所有行。 -V --version #显示版本信息。 -w --word-regexp #只显示全字符合的列。 -x --line-regexp #只显示全列符合的列。 -y #此参数的效果和指定“-i”参数相同。 **规则表达式** ^ #锚定行的开始 如：&apos;^grep&apos;匹配所有以grep开头的行。 ```$ #锚定行的结束 如：&apos;grep$&apos;匹配所有以grep结尾的行。 ``` . #匹配一个非换行符的字符 如：&apos;gr.p&apos;匹配gr后接一个任意字符，然后是p。 \* #匹配零个或多个先前字符 如：&apos;*grep&apos;匹配所有一个或多个空格后紧跟grep的行。 .* #一起用代表任意字符。 [] #匹配一个指定范围内的字符，如&apos;[Gg]rep&apos;匹配Grep和grep。 [^] #匹配一个不在指定范围内的字符，如：&apos;[^A-FH-Z]rep&apos;匹配不包含A-R和T-Z的一个字母开头，紧跟rep的行。 \(..\) #标记匹配字符，如&apos;\(love\)&apos;，love被标记为1。 \&lt; #锚定单词的开始，如:&apos;\&lt;grep&apos;匹配包含以grep开头的单词的行。 \&gt; #锚定单词的结束，如&apos;grep\&gt;&apos;匹配包含以grep结尾的单词的行。 x\&#123;m\&#125; #重复字符x，m次，如：&apos;0\&#123;5\&#125;&apos;匹配包含5个o的行。 x\&#123;m,\&#125; #重复字符x,至少m次，如：&apos;o\&#123;5,\&#125;&apos;匹配至少有5个o的行。 x\&#123;m,n\&#125; #重复字符x，至少m次，不多于n次，如：&apos;o\&#123;5,10\&#125;&apos;匹配5--10个o的行。 \w #匹配文字和数字字符，也就是[A-Za-z0-9]，如：&apos;G\w*p&apos;匹配以G后跟零个或多个文字或数字字符，然后是p。 \W #\w的反置形式，匹配一个或多个非单词字符，如点号句号等。 \b #单词锁定符，如: &apos;\bgrep\b&apos;只匹配grep。 **POSIX字符:** 为了在不同国家的字符编码中保持一至，POSIX(The Portable Operating System Interface)增加了特殊的字符类，如[:alnum:]是[A-Za-z0-9]的另一个写法。要把它们放到[]号内才能成为正则表达式，如[A- Za-z0-9]或[[:alnum:]]。在linux下的grep除fgrep外，都支持POSIX的字符类。 [:alnum:] #文字数字字符 [:alpha:] #文字字符 [:digit:] #数字字符 [:graph:] #非空字符（非空格、控制字符） [:lower:] #小写字符 [:cntrl:] #控制字符 [:print:] #非空字符（包括空格） [:punct:] #标点符号 [:space:] #所有空白字符（新行，空格，制表符） [:upper:] #大写字符 [:xdigit:] #十六进制数字（0-9，a-f，A-F） 4. ipcs和ipcrm命令 **ipcs**： ipcs是Linux下显示进程间通信设施状态的工具。可以显示消息队列、共享内存和信号量的信息。对于程序员非常有用，普通的系统管理员一般用不到此指令。 ipcs [参数] | -a | 默认的输出信息 | | ---- | -------------------------------------- | | -m | 打印出使用共享内存进行进程间通信的信息 | | -q | 打印出使用消息队列进行进程间通信的信息 | | -s | 打印出使用信号进行进程间通信的信息 | **ipcrm**： **ipcrm命令**用来删除一个或更多的消息队列、信号量集或者共享内存标识。 ipcrm [ -m SharedMemoryID ] [ -M SharedMemoryKey ] [ -q MessageID ] [ -Q MessageKey ] [ -s SemaphoreID ] [ -S SemaphoreKey ] 12**选项** -m SharedMemory id 删除共享内存标识 SharedMemoryID。与 SharedMemoryID 有关联的共享内存段以及数据结构都会在最后一次拆离操作后删除。-M SharedMemoryKey 删除用关键字 SharedMemoryKey 创建的共享内存标识。与其相关的共享内存段和数据结构段都将在最后一次拆离操作后删除。-q MessageID 删除消息队列标识 MessageID 和与其相关的消息队列和数据结构。-Q MessageKey 删除由关键字 MessageKey 创建的消息队列标识和与其相关的消息队列和数据结构。-s SemaphoreID 删除信号量标识 SemaphoreID 和与其相关的信号量集及数据结构。-S SemaphoreKey 删除由关键字 SemaphoreKey 创建的信号标识和与其相关的信号量集和数据结构。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117 5. 查找当前目录以及字母下以.c结尾的文件，且文件中包含”hello world”的文件的路径 6. 创建定时任务 - **IO模型** 1. 五种IO模型：阻塞IO 非阻塞IO IO复用 信号驱动式IO 异步IO 网络环境下，通俗的可以将IO分为两步**等** **数据搬迁** 想要**提高IO效率**，需要将**等的时间降低** - **阻塞IO(blocking I/O)** A拿着一支鱼竿在河边钓鱼，并且一直在鱼竿前等，在等的时候不做其他的事情，十分专心。只有鱼上钩的时，才结束掉等的动作，把鱼钓上来。 在内核将**数据准备好之前**，**系统调用会一直等待**所有的套接字，**默认的是阻塞方式**。 程序的read必须在write之后执行，当write阻塞住了，read就不能执行下去，一直处于等待状态。 - **非阻塞IO（noblocking I/O）** B也在河边钓鱼，但是B不想将自己的所有时间都花费在钓鱼上，在等鱼上钩这个时间段中，B也在做其他的事情（一会看看书，一会读读报纸，一会又去看其他人的钓鱼等），但B在做这些事情的时候，每隔一个固定的时间检查鱼是否上钩。一旦检查到有鱼上钩，就停下手中的事情，把鱼钓上来。 **每次客户询问内核是否有数据准备好，即文件描述符缓冲区是否就绪。当有数据报准备好时，就进行拷贝数据报的操作。当没有数据报准备好时，也不阻塞程序，内核直接返回未准备就绪的信号，等待用户程序的下一个轮询。** 但是，轮询对于CPU来说是较大的浪费，一般只有在特定的场景下才使用。 - **信号驱动IO（signal blocking I/O）** C也在河边钓鱼，但与A、B不同的是，C比较聪明，他给鱼竿上挂一个铃铛，当有鱼上钩的时候，这个铃铛就会被碰响，C就会将鱼钓上来。 **信号驱动IO模型，应用进程告诉内核：当数据报准备好的时候，给我发送一个信号，对SIGIO信号进行捕捉，并且调用我的信号处理函数来获取数据报。** - **I/O多路转接 也叫做多路复用IO（I/O multiplexing）** D同样也在河边钓鱼，但是D生活水平比较好，D拿了很多的鱼竿，一次性有很多鱼竿在等，D不断的查看每个鱼竿是否有鱼上钩。增加了效率，减少了等待的时间。 **IO多路转接是多了一个select函数，select函数有一个参数是文件描述符集合，对这些文件描述符进行循环监听，当某个文件描述符就绪时，就对这个文件描述符进行处理。** 其中，select只负责等，recvfrom只负责拷贝。 IO多路转接是属于阻塞IO，但可以对多个文件描述符进行阻塞监听，所以效率较阻塞IO的高 - **异步I/O（asynchronous I/O）** E也想钓鱼，但E有事情，于是他雇来了F，让F帮他等待鱼上钩，一旦有鱼上钩，F就打电话给E，E就会将鱼钓上去。 **当应用程序调用aio_read时，内核一方面去取数据报内容返回，另一方面将程序控制权还给应用进程，应用进程继续处理其他事情，是一种非阻塞的状态。** **当内核中有数据报就绪时，由内核将数据报拷贝到应用程序中，返回aio_read中定义好的函数处理程序** 可以看出，阻塞程度：阻塞IO&gt;非阻塞IO&gt;多路转接IO&gt;信号驱动IO&gt;异步IO，效率是由低到高的 2. **select poll epoll区别** **都是IO多路复用的机制** I/O多路复用就通过一种机制，可以监视多个描述符，一旦某个描述符就（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作 **但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的**，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间 1）select，poll实现需要自己不断轮询所有fd集合，直到设备就绪，期间可能要睡眠和唤醒多次交替。而epoll其实也需要调用epoll_wait不断轮询就绪链表，期间也可能多次睡眠和唤醒交替，但是它是设备就绪时，调用回调函数，把就绪fd放入就绪链表中，并唤醒在epoll_wait中进入睡眠的进程。虽然都要睡眠和交替，但是**select和poll在“醒着”的时候要遍历整个fd集合，而epoll在“醒着”的时候只要判断一下就绪链表是否为空就行了，这节省了大量的CPU时间。这就是回调机制带来的性能提升。** （2）select，poll每次调用都要把fd集合从用户态往内核态拷贝一次，并且要把current往设备等待队列中挂一次，**而epoll只要一次拷贝**，而且把current往等待队列上挂也只挂一次（在epoll_wait的开始，注意这里的等待队列并不是设备等待队列，只是一个epoll内部定义的等待队列）。这也**能节省不少的开销。**- **线程池/内存池自己动手实现一遍**# Linux的API- **fork与vfork区别** fork和vfork都用于创建子进程。但是vfork创建子进程后，父进程阻塞，直到子进程调用exit()或者exec()。 对于内核中过程fork通过调用clone函数，然后clone函数调用do_fork()。do_fork()中调用copy_process()函数先复制task_struct结构体，然后复制其他关于内存，文件，寄存器等信息。fork采用**写时拷贝技术**，因此子进程和父进程的页表指向相同的页框。但是vfork不需要拷贝页表，因为父进程会一直阻塞，直接使用父进程页表。 **写时拷贝/写时复制** 有人认为这样大批量的复制会导致执行效率过低。其实在复制过程中，linux采用了写时复制的策略。 子进程复制了父进程的task_struct，系统堆栈空间和页面表，这意味着上面的程序，我们没有执行count++前，其实子进程和父进程的count指向的是同一块内存。而当子进程改变了变量时候（即对变量进行了写操作），会通过copy_on_write的手段为所涉及的页面建立一个新的副本。 所以当我们执行++count后，这时候子进程才新建了一个页面复制原来页面的内容，基本资源的复制是必须的，而且是高效的。整体看上去就像是父进程的独立存储空间也复制了一遍。 **写入时复制(Copy-on-write)**是一个被使用在程式设计领域的最佳化策略。其基础的观念是，如果有多个呼叫者(callers)同时要求相同资源，他们会共同取得相同的指标指向相同的资源，直到某个呼叫者(caller)尝试修改资源时，系统才会真正复制一个副本(private copy)给该呼叫者，以避免被修改的资源被直接察觉到，这过程对其他的呼叫只都是通透的(transparently)。此作法主要的优点是如果呼叫者并没有修改该资源，就不会有副本(private copy)被建立。 父进程和子进程共享页帧而不是复制页帧。然而，只要页帧被共享，它们就不能被修改，即页帧被保护。无论父进程还是子进程何时试图写一个共享的页帧，就产生一个异常，这时内核就把这个页复制到一个新的页帧中并标记为可写。原来的页帧仍然是写保护的：当其他进程试图写入时，内核检查写进程是否是这个页帧的唯一属主，如果是，就把这个页帧标记为对这个进程是可写的。 vfork()用法与fork()相似.但是也有区别,具体区别归结为以下3点 fork() 子进程拷贝父进程的数据段，代码段. vfork() 子进程与父进程共享数据段.|fork() 父子进程的执行次序不确定. vfork():保证子进程先运行， vfork()保证子进程先运行，在她调用exec或_exit之后父进程才可能被调度运行。如果在 调用这两个函数之前子进程依赖于父进程的进一步动作，则会导致死锁。 在调用exec或 ```_exit```之前与父进程数据是共享的,在它调用exec或_exit之后父进程才可能被调度运行。如果在调用这两个函数之前子进程依赖于父进程的进一步动作，则会导致死锁。当需要改变共享数据段中变量的值，则拷贝父进程 vfork用于创建一个新进程，而该新进程的目的是exec一个新进程，vfork和fork一样都创建一个子进程，但是它并不将父进程的地址空间完全复制到子进程中，不会复制页表。因为子进程会立即调用exec，于是也就不会存放该地址空间。不过在子进程中调用exec或exit之前，他在父进程的空间中运行。 如果在调用vfork时子进程依赖于父进程的进一步动作，则会导致死锁。由此可见，这个系统调用是用来启动一个新的应用程序。其次，子进程在vfork()返回后直接运行在父进程的栈空间，并使用父进程的内存和数据。这意味着子进程可能破坏父进程的数据结构或栈，造成失败。 为了避免这些问题，需要确保一旦调用vfork()，子进程就不从当前的栈框架中返回，并且如果子进程改变了父进程的数据结构就不能调用exit函数。 子进程还必须避免改变全局数据结构或全局变量中的任何信息，因为这些改变都有可能使父进程不能继续。通常，如果应用程序不是在fork()之后立即调用exec()，就有必要在fork()被替换成vfork()之前做仔细的检查。**关于vfork** 简单的说，vfork()跟fork()类似，都是创建一个子进程，这两个函数的的返回值也具有相同的含义。但是vfork()创建的子进程基本上只能做一件事，那就是立即调用_exit()函数或者exec函数族成员，调用任何其它函数（包括exit()）、修改任何数据（除了保存vfork()返回值的那个变量）、执行任何其它语句（包括return）都是不应该的。此外，调用vfork()之后，父进程会一直阻塞，直到子进程调用_exit()终止，或者调用exec函数族成员。 123456789101112131415161718192021222324252627282930313233343536373839**fork和vfork区别**1. fork()会复制父进程的页表，而vfork()不会复制，直接让子进程共用父进程的页表；2. fork()使用了写时复制技术，而vfork()没有，它任何时候都不会复制父进程地址空间。3. vfork()会阻塞父进程而fork()不会。***所以vfork()产生的子进程跟父进程完全共同使用同一个地址空间，甚至共享同一个函数堆栈！也就是子进程中对任何数据变量的修改，不管是局部的还是全局的，都会影响到父进程。而任何一个函数调用都会修改栈空间，这就是为什么vfork()的子进程不能随便调用别的函数。******但需要注意的是，由于vfork()毕竟还是产生一个新的进程，所以子进程拥有自己的进程描述符，拥有自己的寄存器，最重要的是，拥有自己的打开文件列表！***注意拥有自己的打开文件列表非常重要，因为如果子进程只是简单地共用父进程的打开文件列表，那么当子进程调用`_exit()`退出时，`_exit()`内部会自动关闭当前进程打开的所有文件描述符，也就是打开文件列表里面的文件，这将导致父进程恢复执行时，无法访问到自己之前已经打开过的文件，包括标准输入、标准输出和标准错误输出。所幸的是这永远不会发生，子进程会复制父进程的打开文件列表，并增加文件引用计数。那为什么vfork()子进程中可以调用`_exit()`，却不可以调用exit()，也不可以直接returnexit()是对`_exit()`的封装，它自己在调用`_exit()`前会做很多清理工作，其中包括刷新并关闭当前进程使用的流缓冲（比如stdio.h里面的printf等），由于vfork()的子进程完全共享了父进程地址空间，子进程里面的流也是共享的父进程的流，所以子进程里面是不能做这些事的。直接return就更不行了，子进程return以后，会从当前函数的外部调用点后面继续执行，这后面子进程可能将会执行很多语句，结果就没法预料了```cpp#include &lt;stdio.h&gt;#include &lt;unistd.h&gt; void stack1() &#123; vfork();&#125; void stack2() &#123; _exit(0);&#125; int main() &#123; stack1(); printf(&quot;%d goes 1\n&quot;, getpid()); stack2(); printf(&quot;%d goes 2\n&quot;, getpid()); return 0;&#125; 如果父进程pid为1000，子进程pid为1001，那么输出将会是： 1001 goes 1 1000 goes 2 exit()与_exit()区别 exit()清理后进入内核，_exit()直接陷入内核。见上 孤儿进程与僵死进程 子进程的结束和父进程的运行是一个异步过程,即父进程永远无法预测子进程 到底什么时候结束。 当一个进程完成它的工作终止之后，它的父进程需要调用wait()或者waitpid()系统调用取得子进程的终止状态。 孤儿进程：一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作。 僵尸进程：一个进程使用fork创建子进程，如果子进程退出，而父进程并没有调用wait或waitpid获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中。这种进程称之为僵死进程。 问题及危害 unix提供了一种机制可以保证只要父进程想知道子进程结束时的状态信息， 就可以得到。这种机制就是: 在每个进程退出的时候,内核释放该进程所有的资源,包括打开的文件,占用的内存等。 但是仍然为其保留一定的信息(包括进程号the process ID,退出状态the termination status of the process,运行时间the amount of CPU time taken by the process等)。直到父进程通过wait / waitpid来取时才释放。 但这样就导致了问题，如果进程不调用wait / waitpid的话， 那么保留的那段信息就不会释放，其进程号就会一直被占用，但是系统所能使用的进程号是有限的，如果大量的产生僵死进程，将因为没有可用的进程号而导致系统不能产生新的进程. 此即为僵尸进程的危害，应当避免。 孤儿进程是没有父进程的进程，孤儿进程这个重任就落到了init进程身上，init进程就好像是一个民政局，专门负责处理孤儿进程的善后工作。每当出现一个孤儿进程的时候，内核就把孤 儿进程的父进程设置为init，而init进程会循环地wait()它的已经退出的子进程。这样，当一个孤儿进程凄凉地结束了其生命周期的时候，init进程就会代表党和政府出面处理它的一切善后工作。因此孤儿进程并不会有什么危害。 任何一个子进程(init除外)在exit()之后，并非马上就消失掉，而是留下一个称为僵尸进程(Zombie)的数据结构，等待父进程处理。这是每个 子进程在结束时都要经过的阶段。如果子进程在exit()之后，父进程没有来得及处理，这时用ps命令就能看到子进程的状态是“Z”。如果父进程能及时 处理，可能用ps命令就来不及看到子进程的僵尸状态，但这并不等于子进程不经过僵尸状态。 如果父进程在子进程结束之前退出，则子进程将由init接管。init将会以父进程的身份对僵尸状态的子进程进行处理。 僵尸进程危害场景： 例如有个进程，它定期的产 生一个子进程，这个子进程需要做的事情很少，做完它该做的事情之后就退出了，因此这个子进程的生命周期很短，但是，父进程只管生成新的子进程，至于子进程 退出之后的事情，则一概不闻不问，这样，系统运行上一段时间之后，系统中就会存在很多的僵死进程，倘若用ps命令查看的话，就会看到很多状态为Z的进程。 严格地来说，僵死进程并不是问题的根源，罪魁祸首是产生出大量僵死进程的那个父进程。因此，当我们寻求如何消灭系统中大量的僵死进程时，答案就是把产生大 量僵死进程的那个元凶枪毙掉（也就是通过kill发送SIGTERM或者SIGKILL信号啦）。枪毙了元凶进程之后，它产生的僵死进程就变成了孤儿进 程，这些孤儿进程会被init进程接管，init进程会wait()这些孤儿进程，释放它们占用的系统进程表中的资源，这样，这些已经僵死的孤儿进程 就能瞑目而去了。 僵尸进程解决办法 通过信号机制 子进程退出时向父进程发送SIGCHILD信号，父进程处理SIGCHILD信号。在信号处理函数中调用wait进行处理僵尸进程。测试程序如下所示： 结束父进程，由父进程产生的僵尸进程也会回收处理，因为这时候僵尸进程变为孤儿进程 fork两次 《Unix 环境高级编程》8.6节说的非常详细。原理是将子进程成为孤儿进程，从而其的父进程变为init进程，通过init进程可以处理僵尸进程。 孤儿进程是怎么产生的？ 僵死进程是怎么产生的？ 僵死进程的危害？ 如何避免僵死进程的产生？ Linux系统如何避免内存碎片 什么是内存碎片 内存碎片包括内碎片和外碎片 内部碎片是由于采用固定大小的内存分区，当一个进程不能完全使用分给它的固定内存区域时就产生了内部碎片，通常内部碎片难以完全避免； 外部碎片是由于某些未分配的连续内存区域太小，以至于不能满足任意进程的内存分配请求，从而不能被进程利用的内存区域。 外碎片 在段式虚拟存储系统中, 作业的地址空间由若干个逻辑分段组成, 每段分配一个连续的内存区, 但各段之间不要求连续, 其内存的分配方式类似于动态分区分配.由此可知, 段式虚拟存储系统中存在外碎片. 频繁地请求和释放不同大小的内存，必然导致内存碎片问题的产生，结果就是当再次要求分配连续的内存时，即使整体内存是足够的，也无法满足连续内存的需求。该问题也称之为外碎片(external fragmentation)。我们在多次分配内存的时候，不要求多次分配的内存间连续。 内碎片 在页式虚拟存储系统中, 用户作业的地址空间被划分成若干大小相等的页面, 存储空间也分成也页大小相等的物理块, 但一般情况下, 作业的大小不可能都是物理块大小的整数倍, 因此作业的最后一页中仍有部分空间被浪费掉了. 由此可知, 页式虚拟存储系统中存在内碎片. 伙伴算法，用于管理物理内存，避免内存碎片/; 伙伴系统(buddy system)Linux采用著名的伙伴系统(buddy system)算法来解决外碎片问题。把所有的空闲页框分组为11个块链表，每个链表分别包含大小为1,2,4,8,16,32,64,128,256,512,1024个连续的页框，对1024个页框的最大请求对应着4MB大小的连续RAM（每页大小为4KB），每个块的第一个页框的物理地址是该块大小的整数倍，例如，大小为16个页框的块，其起始地址是16*2^12的倍数。我们通过一个例子来说明伙伴算法的工作原理，假设现在要请求一个256个页框的块（1MB），算法步骤如下：• 在256个页框的链表中检查是否有一个空闲快，如果没有，查找下一个更大的块，如果有，请求满足。• 在512个页框的链表中检查是否有一个空闲块，如果有，把512个页框的空闲块分为两份，第一份用于满足请求，第二份链接到256个页框的链表中。如果没有空闲块，继续寻找下一个更大的块。下图比较形象地描述了该过程。 页的请求以上过程的逆过程，就是页框块的释放过程，也是该算法名字的由来，内核试图把大小为B的一对空闲伙伴块合并为一个2B的单独块，满足以下条件的两个块称之为伙伴：• 两个块具有相同的大小• 他们的物理地址是连续的第一块的第一个页框的物理地址是2 * B * 2^12该算法是递归的，如果它成功合并了B，就会试图去合并2B，以再次试图形成更大的块。 高速缓存Slab层用于管理内核分配内存，避免碎片。 slab是Linux操作系统的一种内存分配机制。其工作是针对一些经常分配并释放的对象，如进程描述符等，这些对象的大小一般比较小，如果直接采用伙伴系统来进行分配和释放，不仅会造成大量的内存碎片，而且处理速度也太慢。而slab分配器是基于对象进行管理的，相同类型的对象归为一类(如进程描述符就是一类)，每当要申请这样一个对象，slab分配器就从一个slab列表中分配一个这样大小的单元出去，而当要释放时，将其重新保存在该列表中，而不是直接返回给伙伴系统，从而避免这些内碎片。slab分配器并不丢弃已分配的对象，而是释放并把它们保存在内存中。当以后又要请求新的对象时，就可以从内存直接获取而不用重复初始化。对象高速缓存的组织如右下图所示，高速缓存的内存区被划分为多个slab，每个slab由一个或多个连续的页框组成，这些页框中既包含已分配的对象，也包含空闲的对象。在cache和object中加入slab分配器，是在时间和空间上的折中方案。 另外为了解决多核和NUMA架构下效率问题，slab管理器kmem_cache又把slab page对象分为2层结构，从下往上依次为： 第一层为NUMA node下cpu共享page：管理器为kmem_cache_node，管理node下的slab对象，解决NUMA架构的内存访问效率问题。当本层的空闲page不足时，从伙伴系统申请空闲page；第二层为per-cpu专属page：管理器为kmem_cache_cpu，管理cpu专属的slab对象，解决多核竞争问题。当本层的空闲page不足时，从第一层申请空闲page； slab分配算法slab分配算法采用cache 存储内核对象。当创建cache 时，起初包括若干标记为空闲的对象。对象的数量与slab的大小有关。开始，所有对象都标记为空闲。当需要内核数据结构的对象时，可以直接从cache 上直接获取，并将对象初始化为使用。下面考虑内核如何将slab分配给表示进程描述符的对象。在Linux系统中，进程描述符的类型是struct task_struct ，其大小约为1.7KB。当Linux 内核创建新任务时，它会从cache 中获得struct task_struct 对象所需要的内存。Cache 上会有已分配好的并标记为空闲的struct task_struct 对象来满足请求。Linux 的slab 可有三种状态：满的：slab 中的所有对象被标记为使用。空的：slab 中的所有对象被标记为空闲。部分：slab 中的对象有的被标记为使用，有的被标记为空闲。slab 分配器首先从部分空闲的slab 进行分配。如没有，则从空的slab 进行分配。如没有，则从物理连续页上分配新的slab，并把它赋给一个cache ，然后再从新slab 分配空间。 共享内存的实现原理 共享内存的使用实现原理（必考必问，然后共享内存段被映射进进程空间之后，存在于进程空间的什么位置？共享内存段最大限制是多少？） nmap函数要求内核创建一个新额虚拟存储器区域，最好是从地质start开始的一个区域，并将文件描述符fd指定对象的一个连续的片（chunk）映射到这个新的区域。 SHMMNI为128，表示系统中最多可以有128个共享内存对象。 共享内存可以说是最有用的进程间通信方式，也是最快的IPC形式。两个不同进程A、B共享内存的意思是，同一块物理内存被映射到进程A、B各自的进程地址空间。进程A可以即时看到进程B对共享内存中数据的更新，反之亦然。由于多个进程共享同一块内存区域，必然需要某种同步机制，互斥锁和信号量都可以。 采用共享内存通信的一个显而易见的好处是效率高，因为进程可以直接读写内存，而不需要任何数据的拷贝。对于像管道和消息队列等通信方式，则需要在内核和用户空间进行四次的数据拷贝，而共享内存则只拷贝两次数据[1]：一次从输入文件到共享内存区，另一次从共享内存区到输出文件。实际上，进程之间在共享内存时，并不总是读写少量数据后就解除映射，有新的通信时，再重新建立共享内存区域。而是保持共享区域，直到通信完毕为止，这样，数据内容一直保存在共享内存中，并没有写回文件。共享内存中的内容往往是在解除映射时才写回文件的。因此，采用共享内存的通信方式效率是非常高的。 Linux的2.2.x内核支持多种共享内存方式，如mmap()系统调用，Posix共享内存，以及系统V共享内存。linux发行版本如Redhat 8.0支持mmap()系统调用及系统V共享内存，但还没实现Posix共享内存，本文将主要介绍mmap()系统调用及系统V共享内存API的原理及应用。 一、内核怎样保证各个进程寻址到同一个共享内存区域的内存页面 1、page cache及swap cache中页面的区分：一个被访问文件的物理页面都驻留在page cache或swap cache中，一个页面的所有信息由struct page来描述。struct page中有一个域为指针mapping ，它指向一个struct address_space类型结构。page cache或swap cache中的所有页面就是根据address_space结构以及一个偏移量来区分的。 2、文件与address_space结构的对应：一个具体的文件在打开后，内核会在内存中为之建立一个struct inode结构，其中的i_mapping域指向一个address_space结构。这样，一个文件就对应一个address_space结构，一个address_space与一个偏移量能够确定一个page cache 或swap cache中的一个页面。因此，当要寻址某个数据时，很容易根据给定的文件及数据在文件内的偏移量而找到相应的页面。 3、进程调用mmap()时，只是在进程空间内新增了一块相应大小的缓冲区，并设置了相应的访问标识，但并没有建立进程空间到物理页面的映射。因此，第一次访问该空间时，会引发一个缺页异常。 4、对于共享内存映射情况，缺页异常处理程序首先在swap cache中寻找目标页（符合address_space以及偏移量的物理页），如果找到，则直接返回地址；如果没有找到，则判断该页是否在交换区(swap area)，如果在，则执行一个换入操作；如果上述两种情况都不满足，处理程序将分配新的物理页面，并把它插入到page cache中。进程最终将更新进程页表。 注：对于映射普通文件情况（非共享映射），缺页异常处理程序首先会在page cache中根据address_space以及数据偏移量寻找相应的页面。如果没有找到，则说明文件数据还没有读入内存，处理程序会从磁盘读入相应的页面，并返回相应地址，同时，进程页表也会更新。 5、所有进程在映射同一个共享内存区域时，情况都一样，在建立线性地址与物理地址之间的映射之后，不论进程各自的返回地址如何，实际访问的必然是同一个共享内存区域对应的物理页面。 注：一个共享内存区域可以看作是特殊文件系统shm中的一个文件，shm的安装点在交换区上。 上面涉及到了一些数据结构，围绕数据结构理解问题会容易一些。 二、mmap()及其相关系统调用 mmap()系统调用使得进程之间通过映射同一个普通文件实现共享内存。普通文件被映射到进程地址空间后，进程可以向访问普通内存一样对文件进行访问，不必再调用read()，write（）等操作。 注：实际上，mmap()系统调用并不是完全为了用于共享内存而设计的。它本身提供了不同于一般对普通文件的访问方式，进程可以像读写内存一样对普通文件的操作。而Posix或系统V的共享内存IPC则纯粹用于共享目的，当然mmap()实现共享内存也是其主要应用之一。 1、mmap()系统调用形式如下： mmap ( void * addr , size_t len , int prot , int flags , int fd , off_t offset )```12345参数fd为即将映射到进程空间的文件描述字，一般由open()返回，同时，fd可以指定为-1，此时须指定flags参数中的MAP_ANON，表明进行的是匿名映射（不涉及具体的文件名，避免了文件的创建及打开，很显然只能用于具有亲缘关系的进程间通信）。len是映射到调用进程地址空间的字节数，它从被映射文件开头offset个字节开始算起。prot 参数指定共享内存的访问权限。可取如下几个值的或：PROT_READ（可读） , PROT_WRITE （可写）, PROT_EXEC （可执行）, PROT_NONE（不可访问）。flags由以下几个常值指定：MAP_SHARED , MAP_PRIVATE , MAP_FIXED，其中，MAP_SHARED , MAP_PRIVATE必选其一，而MAP_FIXED则不推荐使用。offset参数一般设为0，表示从文件头开始映射。参数addr指定文件应被映射到进程空间的起始地址，一般被指定一个空指针，此时选择起始地址的任务留给内核来完成。函数的返回值为最后文件映射到进程空间的地址，进程可直接操作起始地址为该值的有效地址。这里不再详细介绍mmap()的参数，读者可参考mmap()手册页获得进一步的信息。2、系统调用mmap()用于共享内存的两种方式：（1）使用普通文件提供的内存映射：适用于任何进程之间；此时，需要打开或创建一个文件，然后再调用mmap()；典型调用代码如下： fd=open(name, flag, mode); if(fd&lt;0) ... ptr=mmap(NULL, len , PROT_READ|PROT_WRITE, MAP_SHARED , fd , 0); 通过mmap()实现共享内存的通信方式有许多特点和要注意的地方，我们将在范例中进行具体说明。 （2）使用特殊文件提供匿名内存映射：适用于具有亲缘关系的进程之间；由于父子进程特殊的亲缘关系，在父进程中先调用mmap()，然后调用fork()。那么在调用fork()之后，子进程继承父进程匿名映射后的地址空间，同样也继承mmap()返回的地址，这样，父子进程就可以通过映射区域进行通信了。注意，这里不是一般的继承关系。一般来说，子进程单独维护从父进程继承下来的一些变量。而mmap()返回的地址，却由父子进程共同维护。 对于具有亲缘关系的进程实现共享内存最好的方式应该是采用匿名内存映射的方式。此时，不必指定具体的文件，只要设置相应的标志即可，参见范例2。 3、系统调用munmap() int munmap( void * addr, size_t len ) 该调用在进程地址空间中解除一个映射关系，addr是调用mmap()时返回的地址，len是映射区的大小。当映射关系解除后，对原来映射地址的访问将导致段错误发生。 4、系统调用msync() int msync ( void * addr , size_t len, int flags) 一般说来，进程在映射空间的对共享内容的改变并不直接写回到磁盘文件中，往往在调用munmap（）后才执行该操作。可以通过调用msync()实现磁盘上文件内容与共享内存区的内容一致。 共享内存允许两个或多个进程共享一给定的存储区，因为数据不需要来回复制，所以是最快的一种进程间通信机制。共享内存可以通过mmap()映射普通文件（特殊情况下还可以采用匿名映射）机制实现，也可以通过系统V共享内存机制实现。应用接口和原理很简单，内部机制复杂。为了实现更安全通信，往往还与信号灯等同步机制共同使用。 共享内存涉及到了存储管理以及文件系统等方面的知识，深入理解其内部机制有一定的难度，关键还要紧紧抓住内核使用的重要数据结构。系统V共享内存是以文件的形式组织在特殊文件系统shm中的。通过shmget可以创建或获得共享内存的标识符。取得共享内存标识符后，要通过shmat将这个内存区映射到本进程的虚拟地址空间。 1. 互斥锁，自旋锁，信号量，读写锁，屏障 2. 互斥锁与自旋锁的区别：互斥锁得不到资源的时候阻塞，不占用cpu资源。自旋锁得不到资源的时候，不停的查询，而然占用cpu资源。]]></content>
      <categories>
        <category>201909</category>
      </categories>
      <tags>
        <tag>Note</tag>
        <tag>OS</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[编程之法：面试和算法心得201909]]></title>
    <url>%2F2019%2F09%2F29%2F%E7%BC%96%E7%A8%8B%E4%B9%8B%E6%B3%95%EF%BC%9A%E9%9D%A2%E8%AF%95%E5%92%8C%E7%AE%97%E6%B3%95%E5%BF%83%E5%BE%97201909%2F</url>
    <content type="text"><![CDATA[海量数据问题是指基于海量数据的存储 处理 操作 数据量太大的暗示：无法短时间内迅速解决，无法一次性装入内存 ！！！针对时间问题——巧妙的算法搭配合适的数据结构 如 布隆过滤器 哈希 位图 堆 数据库 倒排索引 Trie树 ！！！针对空间问题——采取分而治之(哈希映射)的方法 也就是规模大的数据转化为规模小的，从而各个击破 哈希映射的一个重要特性：相同的元素肯定映射到同一个文件中 此外，针对常说的单机及集群问题，通俗来讲，单机就是指处理装载数据的机器有限（只要考虑CPU、内存、和硬盘之间的数据交互），而集群的意思是指机器有多台，适合分布式处理或并行计算，更多考虑节点与节点之间的数据交互。 处理海量数据问题，有以下十种典型方法 哈希分治 simhash算法 外排序 MapReduce 多层划分 位图 布隆过滤器 Trie树 数据库 倒排索引 关联式容器STL容器氛围序列式容器(vector/list/queue/deque/stack/heap)，和关联式容器。 关联式容器分为set(集合)和map(映射表)两大类，以及衍生的mulitset和multimap。这些容器均以RB-tree完成 此外还有第三类关联式容器，如hashtable(散列表)，以及以hashtable为底层机制完成的hash_set(散列结合)/hash_map(散列映射表)/hash_multiset(散列多键集合)/hash_multimap(散列多键映射表)， 也就是说，set/map/multiset/multimap都内含一个RB-tree，而hash_set/hash_map/hash_multiset/hash_multimap都内含一个hashtable。 所谓关联式容器，类似关联式数据库，每笔数据或每个元素都有一个键值(key)和一个实值(value)，即所谓的Key-Value(键-值对)。当元素被插入到关联式容器中时，容器内部结构(RB-tree/hashtable)便依照其键值大小，以某种特定规则将这个元素放置于适当位置。 包括在非关联式数据库中，比如，在MongoDB内，文档(document)是最基本的数据组织形式，每个文档也是以Key-Value（键-值对）的方式组织起来。一个文档可以有多个Key-Value组合，每个Value可以是不同的类型，比如String、Integer、List等等。 123&#123; &quot;name&quot; : &quot;July&quot;, &quot;sex&quot; : &quot;male&quot;, &quot;age&quot; : 23 &#125; set/map/multiset/multimap set，同map一样，所有元素都会根据元素的键值自动被排序，因为set/map两者的所有各种操作，都只是转而调用RB-tree的操作行为，不过，值得注意的是，两者都不允许两个元素有相同的键值。 不同的是：set的元素不像map那样可以同时拥有实值(value)和键值(key)，set元素的键值就是实值，实值就是键值，而map的所有元素都是pair，同时拥有实值(value)和键值(key)，pair的第一个元素被视为键值，第二个元素被视为实值。 至于multiset/multimap，他们的特性及用法和set/map完全相同，唯一的差别就在于它们允许键值重复，即所有的插入操作基于RB-tree的insert_equal()而非insert_unique()。 hash_set/hash_map/hash_multiset/hash_multimap hash_set/hash_map，两者的一切操作都是基于hashtable之上。不同的是，hash_set同set一样，同时拥有实值和键值，且实质就是键值，键值就是实值，而hash_map同map一样，每一个元素同时拥有一个实值(value)和一个键值(key)，所以其使用方式，和上面的map基本相同。但由于hash_set/hash_map都是基于hashtable之上，所以不具备自动排序功能。为什么？因为hashtable没有自动排序功能。 至于hash_multiset/hash_multimap的特性与上面的multiset/multimap完全相同，唯一的差别就是它们hash_multiset/hash_multimap的底层实现机制是hashtable（而multiset/multimap，上面说了，底层实现机制是RB-tree），所以它们的元素都不会被自动排序，不过也都允许键值重复。 所以，综上，说白了，什么样的结构决定其什么样的性质，因为set/map/multiset/multimap都是基于RB-tree之上，所以有自动排序功能，而hashset/hash_map/hash_multiset/hash_multimap都是基于hashtable之上，所以不含有自动排序功能，至于加个前缀multi无非就是允许键值重复而已。 分而治之先映射，后统计，最后排序 hash映射：保证同一个元素在hash后，不会映射到不同的文件中去。换言之，同一个元素只会存在于同一个文件中 一般来讲： 映射 如果一次放不下，那就用hash映射到多个文件 再进行操作 如果放的下，那就跳过这一步 统计 如果是字符串/单词，考虑Trie树 如果是其他数据，考虑hash_map或者hash_set 去重/统计频率，看具体情况选择合适的数据结构 排序 最后如果需要top排序，一般是堆排序 如果是全体排序，一般是归并排序（外排+内排） simhash算法背景如果某一天，面试官问你如何设计一个比较两篇文章相似度的算法？可能你会回答几个比较传统点的思路： 一种方案是先将两篇文章分别进行分词，得到一系列特征向量，然后计算特征向量之间的距离（可以计算它们之间的欧氏距离、海明距离或者夹角余弦等等），从而通过距离的大小来判断两篇文章的相似度。 另外一种方案是传统hash，我们考虑为每一个web文档通过hash的方式生成一个指纹（finger print）。 下面，我们来分析下这两种方法。 采取第一种方法，若是只比较两篇文章的相似性还好，但如果是海量数据呢，有着数以百万甚至亿万的网页，要求你计算这些网页的相似度。你还会去计算任意两个网页之间的距离或夹角余弦么？想必你不会了。 而第二种方案中所说的传统加密方式md5，其设计的目的是为了让整个分布尽可能地均匀，但如果输入内容一旦出现哪怕轻微的变化，hash值就会发生很大的变化 传统hash，我们考虑为每一个web文档通过hash的方式生成一个指纹（finger print）。 传统加密方式md5，其设计的目的是为了让整个分布尽可能地均匀，但如果输入内容一旦出现哪怕轻微的变化，hash值就会发生很大的变化。 使用传统hash可能会得到如下的结果： irb(main):006:0&gt; p1 = ‘the cat sat on the mat’ irb(main):007:0&gt; p1.hash =&gt; 415542861 irb(main):005:0&gt; p2 = ‘the cat sat on a mat’ irb(main):007:0&gt; p2.hash =&gt; 668720516 irb(main):007:0&gt; p3 = ‘we all scream for ice cream’ irb(main):007:0&gt; p3.hash =&gt; 767429688 “ 可理想当中的hash函数，需要对几乎相同的输入内容，产生相同或者相近的hash值，换言之，hash值的相似程度要能直接反映输入内容的相似程度，故md5等传统hash方法也无法满足我们的需求。 引入simhashps：海明距离 在信息编码中，两个合法代码对应位上编码不同的位数称为码距，又称海明距离。举例如下：10101和00110从第一位开始依次有第一位、第四、第五位不同，则海明距离为3 simhash算法，专门用来解决亿万级别的网页的去重任务。 其主要思想是降维，将高维的特征向量映射成低维的特征向量，通过两个向量的Hamming Distance来确定文章是否重复或者高度近似。 通过比较多个文档的simHash值的海明距离，可以获取它们的相似度。 分为五个步骤 分词 哈希 加权 合并 降维 分词 一段语句，进行分词，得到有效的特征向量，然后为每一个特征向量设置1-5等5个级别的权重 hash 通过hash函数计算各个特征向量的hash值，hash值为二进制数01组成的n-bit签名。比如“CSDN”的hash值Hash(CSDN)为100101，“博客”的hash值Hash(博客)为“101011”。就这样，字符串就变成了一系列数字。 加权 在hash值的基础上，给所有特征向量进行加权，$即W = Hash*weight$，且遇到1则hash值和权值正相乘，遇到0则hash值和权值负相乘。例如给“CSDN”的hash值“100101”加权得到：W(CSDN) = 100101*4 = 4 -4 -4 4 -4 4​，给“博客”的hash值“101011”加权得到：​W(博客)=101011*5 = 5 -5 5 -5 5 5​，其余特征向量类似此般操作。 合并 将上述各个特征向量的加权结果累加，变成只有一个序列串。拿前两个特征向量举例，例如“CSDN”的“4 -4 -4 4 -4 4”和“博客”的“5 -5 5 -5 5 5”进行累加，得到“4+5 -4+-5 -4+5 4+-5 -4+5 4+5”，得到“9 -9 1 -1 1”。 一个文本有多个特征向量 降维 对于n-bit签名的累加结果，如果大于0则置1，否则置0，从而得到该语句的simhash值，最后我们便可以根据不同语句simhash的海明距离来判断它们的相似度。例如把上面计算出来的“9 -9 1 -1 1 9”降维（某位大于0记为1，小于0记为0），得到的01串为：“1 0 1 0 1 1”，从而形成它们的simhash签名。 每篇文档得到SimHash签名值后，接着计算两个签名的海明距离即可 海明距离的求法：异或时，只有在两个比较的位不同时其结果是1 ，否则结果为0，两个二进制“异或”后得到1的个数即为海明距离的大小。 现在问题转换为：对于64位的SimHash值，我们只要找到海明距离在3以内的所有签名（3以内可以认为是相似度比较高），即可找出所有相似的文本/短语。 扩展到海量数据，在海量的样本库中查询海明距离3以内的记录 一种方案是查找待查询文本的64位simhash code的所有3位以内变化的组合 大约需要四万多次的查询。 另一种方案是预生成库中所有样本simhash code的3位变化以内的组合 大约需要占据4万多倍的原始空间。 这两种方案，要么时间复杂度高，要么空间复杂度复杂，能否有一种方案可以达到时空复杂度的绝佳平衡呢？答案是肯定的： 我们可以把 64 位的二进制simhash签名均分成4块，每块16位。根据鸽巢原理（也称抽屉原理），如果两个签名的海明距离在 3 以内，它们必有一块完全相同。如下图所示： 在google的论文给出的数据中，64位的签名，在海明距离为3的情况下，可认为两篇文档是相似的或者是重复的，当然这个值只是参考值，针对自己的应用可能又不同的测试取值 到这里相似度问题基本解决，但是按这个思路，在海量数据几百亿的数量下，效率问题还是没有解决的，因为数据是不断添加进来的，不可能每来一条数据，都要和全库的数据做一次比较，按照这种思路，处理速度会越来越慢，线性增长。 然后把分成的4 块中的每一个块分别作为前16位来进行查找，建倒排索引。 ps：倒排索引（英语：Inverted index），也常被称为反向索引、置入档案或反向档案，是一种索引方法，被用来存储在全文搜索下某个单词在一个文档或者一组文档中的存储位置的映射。它是文档检索系统中最常用的数据结构。 如下图所示： 如此，如果样本库中存有2^34（差不多171亿）的simhash签名，则每个table返回2^(34-16)=262144个候选结果，大大减少了海明距离的计算成本。 假设数据是均匀分布，16位的数据，产生的像限为2^16个，则平均每个像限分布的文档数则为2^34/2^16 = 2^(34-16)) ，四个块返回的总结果数为 4* 262144 （大概 100 万）。 这样，原本需要比较10亿次，经过索引后，大概只需要处理100万次。 针对每一个签名，要查找的次数：相当于2^34 变为 2^(34-16)*(64/16) 对于ABCD都是第一个字段的疑问：对于1/4 整段（较长）的文本来说，调换下顺序，对相似度影响不高。。 总结一下： 相似度的计算由simhash算法得到hash签名+海明距离计算（一般64位hash签名的海明距离&lt;=3认为相似）解决 现在需要进行对一个64位签名，查询样本中海明距离在3以内的相似签名数 一种方案是查找待查询文本的64位simhash code的所有3位以内变化的组合 大约需要四万多次的查询。每次都要比较2^34次比较，但是不需要额外空间 另一种方案是预生成库中所有样本simhash code的3位变化以内的组合 大约需要占据4万多倍的原始空间。但是查询时间是40000多次 我们现在选取一个空间和时间折衷的方案 需要空间：额外一点的空间，小于1倍，这里存储的是倒排索引不是签名 2^16次方种16位签名，每个签名对应一个倒排索引，加起来索引数是原来的签名的数目。 需要时间：每一次查询，64位分成4部分，对应4个倒排索引表，假设文件在2^16个象限内分布是均匀的，那么就是4*2^(34-16)次比较。差不多100万次 相当于我们见了个表，直接把不相似的拿走了。——通过抽屉原理 抽屉原理见上 所以我们这里会有一个额外的建立倒排索引表的操作,但是这个表是任意一次查询都可永久使用的，所以是值得的 这个表的形式可以是线性表，因为16位是连续的，每个线性表里面存放对应的反倒排索引。 这样首先16位的查询只需要O(1)的时间，然后得到一个64位签名对应的 外排序外排序，顾名思义，即是在内存外面的排序，因为当要处理的数据量很大，而不能一次装入内存时，此时只能放在读写较慢的外存储器（通常是硬盘）上。 外排序通常采用的是一种“排序-归并”的策略。 在排序阶段，先读入能放在内存中的数据量，将其排序输出到一个临时文件，依此进行，将待排序数据组织为多个有序的临时文件； 尔后在归并阶段将这些临时文件组合为一个大的有序文件，也即排序结果。 比如，要对900 MB的数据进行排序，但机器只有100 MB的可用内存时，外归并排序按如下方法操作： 读入100 MB的数据至内存中，用某种常规方式（如快速排序、堆排序、归并排序等方法）在内存中完成排序。 将排序完成的数据写入磁盘。 重复步骤1和2直到所有的数据都存入了不同的100 MB的块（临时文件）中。在这个例子中，有900 MB数据，单个临时文件大小为100 MB，所以会产生9个临时文件。 读入每个临时文件（顺串）的前10 MB（ = 100 MB / (9块 + 1)）的数据放入内存中的输入缓冲区，最后的10 MB作为输出缓冲区。（实践中，将输入缓冲适当调小，而适当增大输出缓冲区能获得更好的效果。） 执行九路归并算法，将结果输出到输出缓冲区。一旦输出缓冲区满，将缓冲区中的数据写出至目标文件，清空缓冲区。一旦9个输入缓冲区中的一个变空，就从这个缓冲区关联的文件，读入下一个10M数据，除非这个文件已读完。这是“外归并排序”能在主存外完成排序的关键步骤 – 因为“归并算法”(merge algorithm)对每一个大块只是顺序地做一轮访问(进行归并)，每个大块不用完全载入主存。 为了增加每一个有序的临时文件的长度，可以采用置换选择排序（Replacement selection sorting）。它可以产生大于内存大小的顺串。具体方法是在内存中使用一个最小堆进行排序，设该最小堆的大小为{\displaystyle M}。算法描述如下： 初始时将输入文件读入内存，建立最小堆。 将堆顶元素输出至输出缓冲区。然后读入下一个记录： 若该元素的关键码值不小于刚输出的关键码值，将其作为堆顶元素并调整堆，使之满足堆的性质； 否则将新元素放入堆底位置，将堆的大小减1。 重复第2步，直至堆大小变为0。 此时一个顺串已经产生。将堆中的所有元素建堆，开始生成下一个顺串。[3] 此方法能生成平均长度为{\displaystyle 2M}的顺串，可以进一步减少访问外部存储器的次数，节约时间，提高算法效率。 置换选择排序步骤 假设内存最大可以存大小为N的数组，首先读入数据数组array[N]，然后数组建最小堆 将堆顶输出，然后来一个元素，如果这个元素大于等于刚刚输出的元素，放到堆顶，然后堆维护，如果小于刚刚的元素，和堆底元素互换，并把堆的大小减1，然后堆维护 重复上述步骤直到堆的大小变为0 平均可以生成2N长度的顺串——因为每次我都会输出一个元素，而堆的大小可能减1，可能不减1，假设概率五五开，那么2N次才能结束，就输出了2N个数字，所以平均是2N 提升外排序的效率&lt;=&gt;减少磁盘I/O次数&lt;=&gt;减少顺串数量和使用多路归并 减少顺串数量/增加顺串长度可以使用上述的置换选择排序 多路归并我们采用败者树而不是堆 首先介绍败者树和胜者树： 胜败：子结点比较，小者胜 所有数据储存在叶结点，非叶结点存储败者or胜者 胜者树非叶结点存储胜者，败者树败者 都是胜者进入下一轮比赛 败者树会在根结点再记录胜者， 可以推出，败者树和胜者树根结点存储的胜者都是该树的最小值。 败者树的维护： 新进入的结点 放在堆底的后面，然后与其父结点进行比赛，败者存在父结点，胜者再与上一级父结点进行比较，直到根结点，败者存在结点ls [1]中，胜者放在ls[0]中，如下图 和堆维护的区别： 堆维护从根结点到叶结点，败者树维护从新建的叶结点到根结点 堆维护和左右子结点比较两次，败者树维护和父结点比较一次 堆维护在比较的过程中可能终止，败者树维护会一直比较到根结点 堆实现： 维护一个大小为k的小顶堆，每来一个数都和堆顶进行比较，如果比堆顶小，直接舍弃，否则替换堆顶，维护堆，直到n个数都处理完毕，时间复杂度为O(nlogk) 败者树实现：当用数组来实现败者树时， 维护一个叶子节点个数为k的败者树，注意是叶子节点个数而不是所有节点个数，数字较小者取胜，则最顶层保存的是值最小的叶子节点，每来一个数和最小值比较，如果比最小值还小，直接舍弃，否则替换最小值的节点值，从下往上维护败者树，最后的k个叶子节点中保存的就是所有数中值最大的k的，时间复杂度为O(nlogk) 用数组实现败者树的时候，因为只有叶子节点存储的是数据，因此败者树使用的内存空间是堆的两倍。 完全树的内部，度数(分叉数)为2的节点个数是叶子节点个数减一 ，所以使用的数组大小为2k-1, 如果把最值也存入数组中，则需要的数组大小为2k 败者树的构造 思路： 先构造一颗空的败者树，然后把叶子节点一个一个的插入败者树，自底向上不断的调整，保持内部节点保存的都是失败者的节点编号，优胜者一直向上不断比较，最终得到一颗合格的败者树。 leaves[K+1] : 叶子节点的个数为K，下标从1到K，下标0处存储一个最小值，用来初始化败者树 loserTree[K]: 冠军节点存储在下标0，下标1到K-1存储内部节点 叶子结点直接存就行了，需要改变/构建的是中间结点 12345678910111213141516171819202122232425262728293031int loserTree[K]; /* 存储中间节点值，下标0处存储冠军节点 */int leaves[K+1]; /* 从下标1开始存储叶子节点值，下标0处存储一个最小值节点 */void adjust(int i)&#123; int parent=(i+K-1)/2; /* 求出父节点的下标 */ while(parent&gt;0) &#123; if(leaves[i]&gt;leaves[loserTree[parent]]) &#123; int temp=loserTree[parent]; loserTree[parent]=i; /* i指向的是优胜者 */ i= temp; &#125; parent = parent / 2; &#125; loserTree[0]=i;&#125;void initLoserTree()&#123; int i; for(i=1;i&lt;K+1;i++) scanf("%d",&amp;leaves[i]);//叶子结点存入Leaves leaves[0]=MIN; for(int i=0;i&lt;K;i++) loserTree[i]=0;//中间结点初始化全0 for(int i=K;i&gt;0;i--) adjust(i);&#125; 有时间看一下败者树和胜者树的构建，因为性质的不同而很不同 MapReduce分布式处理之MapReduce 方法介绍 MapReduce是一种计算模型，简单的说就是将大批量的工作（数据）分解（MAP）执行，然后再将结果合并成最终结果（REDUCE）。这样做的好处是可以在任务被分解后，可以通过大量机器进行并行计算，减少整个操作的时间。但如果你要我再通俗点介绍，那么，说白了，Mapreduce的原理就是一个归并排序。 适用范围：数据量大，但是数据种类小可以放入内存 基本原理及要点：将数据交给不同的机器去处理，数据划分，结果归约。 读者必须先要明确以下几点，以作为阅读后续内容的基础知识储备： MapReduce是一种模式。 Hadoop是一种框架。 Hadoop是一个实现了MapReduce模式的开源的分布式并行编程框架。 所以，你现在，知道了什么是MapReduce，什么是hadoop，以及这两者之间最简单的联系，而本文的主旨即是，一句话概括：在hadoop的框架上采取MapReduce的模式处理海量数据。下面，咱们可以依次深入学习和了解MapReduce和hadoop这两个东西了。 多层划分多层划分:重点落在“层”上 多层划分法，本质上还是分而治之的思想，因为元素范围很大，不能利用直接寻址表，所以通过多次划分，逐步确定范围，然后最后在一个可以接受的范围内进行。 问题实例1、2.5亿个整数中找出不重复的整数的个数，内存空间不足以容纳这2.5亿个整数 分析：有点像鸽巢原理，整数个数为2^32,也就是，我们可以将这2^32个数，划分为2^8个区域(比如用单个文件代表一个区域)，然后将数据分离到不同的区域，然后不同的区域在利用bitmap就可以直接解决了。也就是说只要有足够的磁盘空间，就可以很方便的解决。 2、5亿个int找它们的中位数 分析：首先我们将int划分为2^16个区域，然后读取数据统计落到各个区域里的数的个数，之后我们根据统计结果就可以判断中位数落到那个区域，同时知道这个区域中的第几大数刚好是中位数。然后第二次扫描我们只统计落在这个区域中的那些数就可以了。 实际上，如果不是int是int64，我们可以经过3次这样的划分即可降低到可以接受的程度。即可以先将int64分成2^24个区域，然后确定区域的第几大数，在将该区域分成2^20个子区域，然后确定是子区域的第几大数，然后子区域里的数的个数只有2^20，就可以直接利用direct addr table进行统计了。 Bitmap所谓的Bit-map就是用一个bit位来标记某个元素对应的Value， 而Key即是该元素。由于采用了Bit为单位来存储数据，因此在存储空间方面，可以大大节省。 for example 要表示8个数，我们就只需要8个Bit（1Bytes），首先我们开辟1Byte的空间，将这些空间的所有Bit位都置为0,然后遍历这5个元素，首先第一个元素是4，那么就把4对应的位置为1,然后再处理第二个元素7，将第八位置为1,，接着再处理第三个元素，一直到最后处理完所有的元素，将相应的位置为1 然后我们现在遍历一遍Bit区域，将该位是一的位的编号输出，这样就达到了排序的目的。 应用可进行数据的快速查找，判重，删除，一般来说数据范围是int的10倍以下 问题实例注意：位图的意义就在于“位”，所以在使用位图的标记时，一定要精确到位 比如一位就代表存在 or 不存在 两位就可以代表 存在 存在一次 存在多次 ！！！ 不要用整数标记 因为整数太大！！！ 1、在2.5亿个整数中找出不重复的整数，注，内存不足以容纳这2.5亿个整数 解法一：采用2-Bitmap（每个数分配2bit，00表示不存在，01表示出现一次，10表示多次，11无意义）进行，共需内存2^32 * 2 bit=1 GB内存，还可以接受。然后扫描这2.5亿个整数，查看Bitmap中相对应位，如果是00变01，01变10，10保持不变。所描完事后，查看bitmap，把对应位是01的整数输出即可。 有点像状态机的意思 解法二：也可采用与第1题类似的方法，进行划分小文件的方法。然后在小文件中找出不重复的整数，并排序。然后再进行归并，注意去除重复的元素。” 2、给40亿个不重复的unsigned int的整数，没排过序的，然后再给一个数，如何快速判断这个数是否在那40亿个数当中？ 解法一：可以用位图/Bitmap的方法，申请512M的内存，一个bit位代表一个unsigned int值。读入40亿个数，设置相应的bit位，读入要查询的数，查看相应bit位是否为1，为1表示存在，为0表示不存在。 位图在这里有点哈希表的意思，key是数值，value是”状态”(特别强调下状态的意思，不出现 出现一次 出现多次等等) Bloom Filter（布隆过滤器）布隆过滤器，是一种空间效率很高的随机数据结构，Bloom filter可以看做是对bit-map的扩展,它的原理是： 当一个元素被加入集合时，通过K个Hash函将这个元素映射成一个位阵列（Bit array）中的K个点，把它们置为1。检索时，我们只要看看这些点是不是都是1就（大约）知道集合中有没有它了： 如果这些点有任何一个0，则被检索元素一定不在； 如果都是1，则被检索元素很可能在。 其可以用来实现数据字典，进行数据的判重，或者集合求交集。 但Bloom Filter的这种高效是有一定代价的：在判断一个元素是否属于某个集合时，有可能会把不属于这个集合的元素误认为属于这个集合（false positive）。因此，Bloom Filter不适合那些“零错误”的应用场合。而在能容忍低错误率的应用场合下，Bloom Filter通过极少的错误换取了存储空间的极大节省。 集合表示和元素查询初始状态时，Bloom Filter是一个包含m位的位数组，每一位都置为0。 为了表达S={x1, x2,…,xn}这样一个n个元素的集合，Bloom Filter使用k个相互独立的哈希函数（Hash Function），它们分别将集合中的每个元素映射到{1,…,m}的范围中。对任意一个元素x，第i个哈希函数映射的位置hi(x)就会被置为1（1≤i≤k）。注意，如果一个位置多次被置为1，那么只有第一次会起作用，后面几次将没有任何效果。在下图中，k=3，且有两个哈希函数选中同一个位置（从左边数第五位，即第二个“1“处）。 注意上述表述，元素是n个，哈希函数是k个，映射的范围是1..m 假设集合里面有3个元素{x, y, z}，哈希函数的个数为3。首先将位数组进行初始化，将里面每个位都设置位0。对于集合里面的每一个元素，将元素依次通过3个哈希函数进行映射，每次映射都会产生一个哈希值，这个值对应位数组上面的一个点，然后将位数组对应的位置标记为1。查询W元素是否存在集合中的时候，同样的方法将W通过哈希映射到位数组上的3个点。如果3个点的其中有一个点不为1，则可以判断该元素一定不存在集合中。反之，如果3个点都为1，则该元素可能存在集合中。注意：此处不能判断该元素是否一定存在集合中，可能存在一定的误判率。可以从图中可以看到：假设某个元素通过映射对应下标为4，5，6这3个点。虽然这3个点都为1，但是很明显这3个点是不同元素经过哈希得到的位置，因此这种情况说明元素虽然不在集合中，也可能对应的都是1，这是误判率存在的原因。 布隆过滤器添加元素 将要添加的元素给k个哈希函数 得到对应于位数组上的k个位置 将这k个位置设为1 布隆过滤器查询元素 将要查询的元素给k个哈希函数 得到对应于位数组上的k个位置 如果k个位置有一个为0，则肯定不在集合中 如果k个位置全部为1，则可能在集合中 应用从布隆过滤的特性来看，主要是查询是否存在 适合两个文件查找相同元素 问题实例1、给你A,B两个文件，各存放50亿条URL，每条URL占用64字节，内存限制是4G，让你找出A,B文件共同的URL。如果是三个乃至n个文件呢？ 分析：如果允许有一定的错误率，可以使用Bloom filter，4G内存大概可以表示340亿bit。将其中一个文件中的url使用Bloom filter映射为这340亿bit，然后挨个读取另外一个文件的url，检查是否与Bloom filter，如果是，那么该url应该是共同的url（注意会有一定的错误率）。” Trie树见前 问题实例1、一个文本文件，大约有一万行，每行一个词，要求统计出其中最频繁出现的前10个词，请给出思想，给出时间复杂度分析 提示：用trie树统计每个词出现的次数，时间复杂度是O(n*le)（le表示单词的平均长度），然后是找出出现最频繁的前10个词。当然，也可以用堆来实现，时间复杂度是O(n*lg10)。所以总的时间复杂度，是O(n*le)与O(n*lg10)中较大的哪一个。 2、寻找热门查询 原题：搜索引擎会通过日志文件把用户每次检索使用的所有检索串都记录下来，每个查询串的长度为1-255字节。假设目前有一千万个记录，这些查询串的重复读比较高，虽然总数是1千万，但是如果去除重复和，不超过3百万个。一个查询串的重复度越高，说明查询它的用户越多，也就越热门。请你统计最热门的10个查询串，要求使用的内存不能超过1G。 提示：利用trie树，关键字域存该查询串出现的次数，没有出现为0。最后用10个元素的最小推来对出现频率进行排序。 数据库方法介绍当遇到大数据量的增删改查时，一般把数据装进数据库中，从而利用数据的设计实现方法，对海量数据的增删改查进行处理。 动态规划学习一个算法，可分为3个步骤： 首先了解算法本身解决什么问题， 然后学习它的解决策略， 最后了解某些相似算法之间的联系 图算法中 广搜是一层一层往外遍历，寻找最短路径，其策略是采取队列的方法。 最小生成树是最小代价连接所有点，其策略是贪心，比如Prim的策略是贪心+权重队列。 Dijkstra是寻找单源最短路径，其策略是贪心+非负权重队列。 Floyd是多结点对的最短路径，其策略是动态规划。 而贪心和动态规划是有联系的，贪心是“最优子结构+局部最优”，动态规划是“最优独立重叠子结构+全局最优”。一句话理解动态规划，则是枚举所有状态，然后剪枝，寻找最优状态，同时将每一次求解子问题的结果保存在一张“表格”中，以后再遇到重叠的子问题，从表格中保存的状态中查找（俗称记忆化搜索）。 动态规划求解题目最重要的是要找到状态转移方程 最大连续乘积子串给一个浮点数序列，取最大乘积连续子串的值，例如 -2.5，4，0，3，0.5，8，-1，则取出的最大乘积连续子串为3，0.5，8。也就是说，上述数组中，3 0.5 8这3个数的乘积$30.58=12$是最大的，而且是连续的。 分析与解法此最大乘积连续子串与最大乘积子序列不同，请勿混淆，前者子串要求连续，后者子序列不要求连续。也就是说，最长公共子串（Longest CommonSubstring）和最长公共子序列（LongestCommon Subsequence，LCS）是： 子串（Substring）是串的一个连续的部分， 子序列（Subsequence）则是从不改变序列的顺序，而从序列中去掉任意的元素而获得的新序列； 更简略地说，前者（子串）的字符的位置必须连续，后者（子序列LCS）则不必。比如字符串“ acdfg ”同“ akdfc ”的最长公共子串为“ df ”，而它们的最长公共子序列LCS是“ adf ”，LCS可以使用动态规划法解决。 解法一：暴力解法 两次for循环 时间复杂度O(n^2) 解法二：动态规划 针对这道题目，我们使用两个变量记录当前最大值maxEnd, 和当前最小值minEnd。为什么记录当前最小值呢？因为,数组中会出现负数，乘以一个负数的话，当前最小值是会逆袭的！！ 状态转移方程 12maxEnd=max(max(maxEnd*a[i], minEnd*a[i]), a[i]); //更新当前最大值minEnd=min(min(maxEnd*a[i], minEnd*a[i]), a[i]); //更新当前最小值 代码 自己写的 12345678910111213141516171819202122232425#include&lt;iostream&gt;#include&lt;vector&gt;using namespace std;double findMaxSubStringProduct(vector&lt;double&gt;&amp; Seq)&#123; double maxEnd = Seq[0]; double minEnd = Seq[0]; double maxResult = Seq[0]; for(int i = 1;i&lt;Seq.size();i++)&#123; //cout &lt;&lt; Seq[i] &lt;&lt; endl; maxEnd = max(max(maxEnd*Seq[i],minEnd*Seq[i]),Seq[i]); minEnd = min(min(maxEnd*Seq[i],minEnd*Seq[i]),Seq[i]); //cout &lt;&lt; "maxEnd is: " &lt;&lt; maxEnd &lt;&lt; endl; //cout &lt;&lt; "maxResult is: " &lt;&lt; maxResult &lt;&lt; endl; maxResult = max(maxEnd,maxResult); &#125; return maxResult;&#125;int main(void)&#123; vector&lt;double&gt; Seq&#123;-2.5, 4, 0, 3, 0.5, 8, -1&#125;; double result = findMaxSubStringProduct(Seq); cout &lt;&lt; "MaxSubStringProduct is : " &lt;&lt; result &lt;&lt; endl; return 0;&#125; 动态规划求解的方法一个for循环搞定，所以时间复杂度为O(n)。 举一反三1、给定一个长度为N的整数数组，只允许用乘法，不能用除法，计算任意（N-1）个数的组合中乘积最大的一组，并写出算法的时间复杂度。 字符串编辑距离给定一个源串和目标串，能够对源串进行如下操作： 在给定位置上插入一个字符 替换任意字符 删除任意字符 写一个程序，返回最小操作数，使得对源串进行这些操作后等于目标串，源串和目标串的长度都小于2000。 分析与解法此题常见的思路是动态规划，假如令$dp[i][j]$ 表示源串S[0…i] 和目标串T[0…j] 的最短编辑距离，其边界：dp[0][j] = j，dp[i][0] = i，那么我们可以得出状态转移方程： 1234567 dp[i][j] =min&#123; dp[i-1][j] + 1 , S[i]不在T[0…j]中 dp[i-1][j-1] + 1/0 , S[i]在T[j] dp[i][j-1] + 1 , S[i]在T[0…j-1]中&#125; 接下来，咱们重点解释下上述3个式子的含义 关于dp[i-1][j] + 1, s.t. s[i]不在T[0…j]中的说明 s[i]没有落在T[0…j]中，即s[i]在中间的某一次编辑操作被删除了。因为删除操作没有前后相关性，不妨将其在第1次操作中删除。除首次操作时删除外，后续编辑操作是将长度为i-1的字符串，编辑成长度为j的字符串：即dp[i-1][j]。 因此：dp[i][j] = dp[i-1][j] + 1。 关于dp[i-1][j-1] + 0/1, s.t. s[i] 在T[j]的说明 若s[i]经过编辑，最终落在T[j]的位置。 则要么s[i] == t[j]，s[i]直接落在T[j]。这种情况，编辑操作实际上是将长度为i-1的S’串，编辑成长度为j-1的T’串：即dp[i-1][j-1]； 要么s[i] ≠ t[j]，s[i] 落在T[j]后，要将s[i]修改成T[j]，即在上一种情况的基础上，增加一次修改操作：即dp[i-1][j-1] + 1。 关于dp[i][j-1] + 1, s.t. s[i]在T[0…j-1]中的说明 若s[i]落在了T[1…j-1]的某个位置，不妨认为是k，因为最小编辑步数的定义，那么，在k+1到j-1的字符，必然是通过插入新字符完成的。因为共插入了(j-k)个字符，故编辑次数为(j-k)次。而字符串S[1…i]经过编辑，得到了T[1…k]，编辑次数为dp[i][k]。故： dp[i][j] = dp[i][k] + (j-k)。 由于最后的(j-k)次是插入操作，可以讲(j-k)逐次规约到dp[i][k]中。即：dp[i][k]+(j-k)=dp[i][k+1] + (j-k-1) 规约到插入操作为1次，得到 dp[i][k]+(j-k) =dp[i][k+1] + (j-k-1) =dp[i][k+2] + (j-k-2)=… =dp[i][k+(j-k-1)] + (j-k)-(j-k-1) =dp[i][j-1] + 1。 上述的解释清晰规范，但为啥这样做呢？ 换一个角度，其实就是字符串对齐的思路。例如把字符串“ALGORITHM”，变成“ALTRUISTIC”，那么把相关字符各自对齐后，如下图所示： 把图中上面的源串S[0…i] = “ALGORITHM”编辑成下面的目标串T[0…j] = “ALTRUISTIC”，我们枚举字符串S和T最后一个字符s[i]、t[j] 对应四种情况：（字符-空白）（空白-字符）(字符-字符)（空白-空白）其实压根就没有空白到空白。 由于其中的（空白-空白）是多余的编辑操作。所以，事实上只存在以下3种情况： 下面的目标串空白，即S + 字符X，T + 空白，S变成T，意味着源串要删字符 dp[i - 1, j] + 1 上面的源串空白，S + 空白，T + 字符，S变成T，最后，在S的最后插入“字符”，意味着源串要添加字符 dp[i, j - 1] + 1 上面源串中的的字符跟下面目标串中的字符不一样，即S + 字符X，T + 字符Y，S变成T，意味着源串要修改字符 dp[i - 1, j - 1] + (s[i] == t[j] ? 0 : 1) 综上，可以写出简单的DP状态方程： 123//dp[i,j]表示表示源串S[0…i] 和目标串T[0…j] 的最短编辑距离dp[i, j] = min &#123; dp[i - 1, j] + 1, dp[i, j - 1] + 1, dp[i - 1, j - 1] + (s[i] == t[j] ? 0 : 1) &#125;//分别表示：删除1个，添加1个，替换1个（相同就不用替换）。 举一反三1、传统的编辑距离里面有三种操作，即增、删、改，我们现在要讨论的编辑距离只允许两种操作，即增加一个字符、删除一个字符。我们求两个字符串的这种编辑距离，即把一个字符串变成另外一个字符串的最少操作次数。假定每个字符串长度不超过1000，只有大写英文字母组成。 这个简单，把出现替换情况的部分，把数值1改为2，因为由原来的一次替换操作变成了先删除后插入的2次操作 2、有一亿个数，输入一个数，找出与它编辑距离在3以内的数，比如输入6（0110），找出0010等数，数是32位的。 这道题的话，如果都是32位的，，可以直接通过比较不同的位来判断编辑距离，因为只用替换一种操作即可，所以可以直接两数相异或然后求解疑惑结果中1的个数（用那个最高效的算法） ,得到的结果就是编辑距离 然后直接遍历一遍即可。 问题扩展实际上，关于这个“编辑距离”问题在搜索引擎中有着重要的作用，如搜索引擎关键字查询中拼写错误的提示，如下图所示，当你输入“Jult”后，因为没有这个单词“Jult”，所以搜索引擎猜测你可能是输入错误，进而会提示你是不是找“July”： 当然，面试官还可以继续问下去，如请问，如何设计一个比较这篇文章和上一篇文章相似性的算法？ 格子取数问题题目描述 有n*n个格子，每个格子里有正数或者0，从最左上角往最右下角走，只能向下和向右，一共走两次（即从左上角走到右下角走两趟），把所有经过的格子的数加起来，求最大值SUM，且两次如果经过同一个格子，则最后总和SUM中该格子的计数只加一次。 保证了连续的两次走法都是最优的，但却不能保证总体最优 局部贪优不行，我们可以考虑穷举，但最终将导致复杂度过高，所以咱们得另寻良策。 先对矩阵做一个编号，且以5*5的矩阵为例（给这个矩阵起个名字叫M1） M1 0 1 2 3 4 1 2 3 4 5 2 3 4 5 6 3 4 5 6 7 4 5 6 7 8 注意上面的每个数字都代表了到这个结点要走的步数 从左上(0)走到右下(8)共需要走8步（2*5-2）。我们设所走的步数为s。因为限定了只能向右和向下走，因此无论如何走，经过8步后（s = 8)都将走到右下。而DP的状态也是依据所走的步数来记录的。 再来分析一下经过其他s步后所处的位置，根据上面的讨论，可以知道： 经过8步后，一定处于右下角(8)； 那么经过5步后(s = 5)，肯定会处于编号为5的位置； 3步后肯定处于编号为3的位置； s = 4的时候，处于编号为4的位置，此时对于方格中，共有5（相当于n）个不同的位置，也是所有编号中最多的。 故推广来说，对于n*n的方格，总共需要走2n - 2步，且当s = n - 1时，编号为n个，也是编号数最多的。 如果用DP[s,i,j]来记录2次所走的状态获得的最大值，其中s表示走s步，i和j分别表示在s步后第1趟走的位置和第2趟走的位置。 为了方便描述，再对矩阵做一个编号（给这个矩阵起个名字叫M2）： M2 0 0 0 0 0 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 4 4 4 4 4 M1 0 1 2 3 4 1 2 3 4 5 2 3 4 5 6 3 4 5 6 7 4 5 6 7 8 我们先看M1，在经过5步后，肯定处于M1中编号为5的位置。而M1中共有3个编号为5的，它们分别对应M2中的2 3 4。故对于M2来说，假设第1次经过5步走到了M2中的2，第2次经过5步走到了M2中的4，DP[s,i,j] 则对应 DP[5,2,4]。由于s = 2n - 2,0 &lt;= i &lt;= j &lt;= n，所以这个DP共有O(n^3)个状态。 分析一下状态转移，以DP[6,2,3]为例(就是上面M1中加粗的部分)，可以到达DP[6,2,3]的状态包括DP[5,1,2]，DP[5,1,3]，DP[5,2,2]，DP[5,2,3]。 因此： 1DP[6,2,3] = Max(DP[5,1,2] ，DP[5,1,3]，DP[5,2,2]，DP[5,2,3]) + 6,2和6,3格子中对应的数值 （式一） 上面（式一）所示的这个递推看起来没有涉及：“如果两次经过同一个格子，那么该数只加一次的这个条件”，讨论这个条件需要换一个例子，以DP[6,2,2]为例：DP[6,2,2]可以由DP[5,1,1]，DP[5,1,2]，DP[5,2,2]到达，但由于i = j，也就是2次走到同一个格子，那么数值只能加1次。 所以当i = j时， 1DP[6,2,2] = Max(DP[5,1,1]，DP[5,1,2]，DP[5,2,2]) + 6,2格子中对应的数值 （式二） 故，综合上述的（式一），（式二）最后的递推式就是 1234if(i != j) DP[s, i ,j] = Max(DP[s - 1, i - 1, j - 1], DP[s - 1, i - 1, j], DP[s - 1, i, j - 1], DP[s - 1, i, j]) + W[s,i] + W[s,j] else DP[s, i ,j] = Max(DP[s - 1, i - 1, j - 1], DP[s - 1, i - 1, j], DP[s - 1, i, j]) + W[s,i] 其中W[s,i]表示经过s步后，处于i位置，位置i对应的方格中的数字。下一节我们将根据上述DP方程编码实现。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263//copyright@caopengcs 2013const int N = 202;const int inf = 1000000000; //无穷大int dp[N * 2][N][N];bool IsValid(int step, int x1, int x2, int n) //判断状态是否合法&#123; int y1 = step - x1, y2 = step - x2; return ((x1 &gt;= 0) &amp;&amp; (x1 &lt; n) &amp;&amp; (x2 &gt;= 0) &amp;&amp; (x2 &lt; n) &amp;&amp; (y1 &gt;= 0) &amp;&amp; (y1 &lt; n) &amp;&amp; (y2 &gt;= 0) &amp;&amp; (y2 &lt; n));&#125;int GetValue(int step, int x1, int x2, int n) //处理越界 不存在的位置 给负无穷的值&#123; return IsValid(step, x1, x2, n) ? dp[step][x1][x2] : (-inf);&#125;//状态表示dp[step][i][j] 并且i &lt;= j, 第step步 两个人分别在第i行和第j行的最大得分 时间复杂度O(n^3) 空间复杂度O(n^3)int MinPathSum(int a[N][N], int n)&#123; int P = n * 2 - 2; //最终的步数 int i, j, step; //不能到达的位置 设置为负无穷大 for (i = 0; i &lt; n; ++i) &#123; for (j = i; j &lt; n; ++j) &#123; dp[0][i][j] = -inf; &#125; &#125; dp[0][0][0] = a[0][0]; for (step = 1; step &lt;= P; ++step) &#123; for (i = 0; i &lt; n; ++i) &#123; for (j = i; j &lt; n; ++j) &#123; dp[step][i][j] = -inf; if (!IsValid(step, i, j, n)) //非法位置 &#123; continue; &#125; //对于合法的位置进行dp if (i != j) &#123; dp[step][i][j] = max(dp[step][i][j], GetValue(step - 1, i - 1, j - 1, n)); dp[step][i][j] = max(dp[step][i][j], GetValue(step - 1, i - 1, j, n)); dp[step][i][j] = max(dp[step][i][j], GetValue(step - 1, i, j - 1, n)); dp[step][i][j] = max(dp[step][i][j], GetValue(step - 1, i, j, n)); dp[step][i][j] += a[i][step - i] + a[j][step - j]; //不在同一个格子，加两个数 &#125; else &#123; dp[step][i][j] = max(dp[step][i][j], GetValue(step - 1, i - 1, j - 1, n)); dp[step][i][j] = max(dp[step][i][j], GetValue(step - 1, i - 1, j, n)); dp[step][i][j] = max(dp[step][i][j], GetValue(step - 1, i, j, n)); dp[step][i][j] += a[i][step - i]; // 在同一个格子里，只能加一次 &#125; &#125; &#125; &#125; return dp[P][n - 1][n - 1];&#125; 举一反三1、给定m*n的矩阵，每个位置是一个非负整数，从左上角开始，每次只能朝右和下走，走到右下角，但只走一次，求总和最小的路径。 提示：因为只走一次，所以相对来说比较简单，dp[0, 0]=a[0, 0]，且dp[x, y] = min(dp[x-1, y] + a[x, y]dp[x, y-1] + a[x, y])。 2、给定m*n的矩阵，每个位置是一个整数，从左上角开始，每次只能朝右、上和下走，并且不允许两次进入同一个格子，走到右上角，最小和。 分析：@cpcs ：我们按列dp，假设前一列的最优值已经算好了，一旦往右就回不去了。枚举我们从对固定的(y-1)列，我们已经算好了最优值，我们枚举行x，朝右走到(x,y),然后再从(x,y)朝上走到(x,0)，再从(x,y)朝下走到(x,n-1)，所有这些第y列的值，作为第y列的候选值，取最优。 实际上，我们枚举了进入第y列的位置和在最终停在第y列的位置。这样保证我们不重复经过一个格子，也能保证我们不会往“左”走。 交替字符串题目描述输入三个字符串s1、s2和s3，判断第三个字符串s3是否由前两个字符串s1和s2交错而成，即不改变s1和s2中各个字符原有的相对顺序，例如当s1 = “aabcc”，s2 = “dbbca”，s3 = “aadbbcbcac”时，则输出true，但如果s3=“accabdbbca”，则输出false。 分析与解法此题不能简单的排序，因为一旦排序，便改变了s1或s2中各个字符原始的相对顺序，既然不能排序，咱们可以考虑下用动态规划的方法，令12345678910111213141516171819202122232425262728293031323334353637383940414243444546- 如果s1当前字符（即s1[i-1]）等于s3当前字符（即s3[i+j-1]），而且```dp[i-1][j]```为真，那么可以取s1当前字符而忽略s2的情况，```dp[i][j]```返回真；- 如果s2当前字符等于s3当前字符，并且```dp[i][j-1]```为真，那么可以取s2而忽略s1的情况，`dp[i][j]`返回真，其它情况，```dp[i][j]```返回假代码（自己写的）：```cpp#include&lt;iostream&gt;#include&lt;string&gt;using namespace std;bool crossStringCheck(string s1, string s2, string s3)&#123; int result = false; int row = s1.size(); int col = s2.size(); int length = s3.size(); if(row+col != length) return result; bool dp[row+1][col+1];// we start with &apos;&apos; rather than &apos;x&apos;, we suppose that &apos;&apos; can be composed by &apos;&apos; and &apos;&apos; which means dp[0][0] is true dp[0][0] = true; for(int i=0; i&lt;row+1; i++)&#123; for(int j = 0;j&lt;col+1;j++)&#123; if((i-1&gt;=0&amp;&amp;dp[i-1][j]==true&amp;&amp;s1[i-1]==s3[i-1+j])||(j-1&gt;=0&amp;&amp;dp[i][j-1]==true&amp;&amp;s2[j-1]==s3[i+j-1])||dp[i][j]) // attention: why &quot;||dp[i][j]&quot;? ——we need to take dp[0][0] into account dp[i][j] = true; else dp[i][j] = false; &#125; &#125; return dp[row][col];&#125;int main(void)&#123; string s1 = &quot;clear&quot;; string s2 = &quot;farm&quot;; string s3 = &quot;cfleaarrm&quot;; bool result1 = crossStringCheck(s1,s2,s3); bool result2 = crossStringCheck(s1,s3,s2); bool result3 = crossStringCheck(s2,s3,s1); cout &lt;&lt; &quot;s3 can be crossed by s1&amp;s2: &quot; &lt;&lt; result1 &lt;&lt; endl; cout &lt;&lt; &quot;s2 can be crossed by s1&amp;s3: &quot; &lt;&lt; result2 &lt;&lt; endl; cout &lt;&lt; &quot;s1 can be crossed by s2&amp;s3: &quot; &lt;&lt; result3 &lt;&lt; endl; return 0;&#125; 程序员如何准备面试中的算法大部分的面试题都在围绕一个点：基于各种数据结构上的增删改查。如字符串的查找翻转，链表的查找遍历合并删除，树和图的查找遍历，后来为了更好的查找，我们想到了排序，排序仍然不够，我们有了贪心、动态规划，再后来东西多了，于是有了海量数据处理，资源有限导致人们彼此竞争，出现了博弈组合概率。 如果学数据结构，可以看我们在大学里学的任一本数据结构教材都行，如果你觉得实在不够上档次，那么可以再看看《STL源码剖析》。 如果你已经学完了一本数据结构教材，那么建议你着重看贪心、动态规划、图论等内容，这3个议题每一个议题都大有题目可出。同时，熟悉常用算法的时间复杂度。 字符串导读6个经典的字符串问题，分别是旋转字符串、字符串包含、字符串转换成整数、回文判断、最长回文子串、字符串的全排列 读完本章后会发现，好的思路都是在充分考虑到问题本身的特征的前提下，或巧用合适的数据结构，或选择合适的算法降低时间复杂度（避免不必要的操作），或选用效率更高的算法。 旋转字符串给定一个字符串，要求把字符串前面的若干个字符移动到字符串的尾部，如把字符串“abcdef”前面的2个字符’a’和’b’移动到字符串的尾部，使得原字符串变成字符串“cdefab”。请写一个函数完成此功能，要求对长度为n的字符串操作的时间复杂度为 O(n)，空间复杂度为 O(1)。 特别注意，我们这里空间复杂度为O(1)，所以我们是不能直接全部存储字符串尾部的部分，因为这部分的空间复杂度可以认为是O(n) 合适的解法——三步反转法 对于这个问题，换一个角度思考一下。 将一个字符串分成X和Y两个部分，在每部分字符串上定义反转操作，如X^T，即把X的所有字符反转（如，X=”abc”，那么X^T=”cba”），那么就得到下面的结论：(X^TY^T)^T=YX，显然就解决了字符串的反转问题。 例如，字符串 abcdef ，若要让def翻转到abc的前头，只要按照下述3个步骤操作即可： 首先将原字符串分为两个部分，即X:abc，Y:def； 将X反转，X-&gt;X^T，即得：abc-&gt;cba；将Y反转，Y-&gt;Y^T，即得：def-&gt;fed。 反转上述步骤得到的结果字符串X^TY^T，即反转字符串cbafed的两部分（cba和fed）给予反转，cbafed得到defabc，形式化表示为(X^TY^T)^T=YX，这就实现了整个反转。 相当于是，把两部分分别反转，然后对整体反转 代码（自己写的） 移动前m个字符到后面 12345678910111213141516171819202122232425262728#include&lt;iostream&gt;#include&lt;string&gt;using namespace std;void strReverseCore(string&amp; str, int start, int end)&#123; char tmp ; for(int i=start;i&lt;=(start+end)/2;i++)&#123; char tmp = str[i]; str[i] = str[end+start-i]; str[end+start-i] = tmp; &#125;&#125;void strReverse(string&amp; str, int m)&#123; int length = str.size(); strReverseCore(str,0,m-1); strReverseCore(str,m,length-1); strReverseCore(str,0,length-1);&#125;int main(void)&#123; string str = "abcdefghi"; int m = 5; strReverse(str,m); cout &lt;&lt; "Reverse Str is: " &lt;&lt; str &lt;&lt; endl; return 0;&#125; 字符串包含题目描述给定两个分别由字母组成的字符串A和字符串B，字符串B的长度比字符串A短。请问，如何最快地判断字符串B中所有字母是否都在字符串A里？ 为了简单起见，我们规定输入的字符串只包含大写英文字母，请实现函数bool StringContains(string &amp;A, string &amp;B) 比如，如果是下面两个字符串： String 1：ABCD String 2：BAD 答案是true，即String2里的字母在String1里也都有，或者说String2是String1的真子集。 如果是下面两个字符串： String 1：ABCD String 2：BCE 答案是false，因为字符串String2里的E字母不在字符串String1里。 同时，如果string1：ABCD，string 2：AA，同样返回true。 重复出现算一次 直接就想到了最好的算法——哈希表 可以先把长字符串a中的所有字符都放入一个Hashtable里，然后轮询短字符串b，看短字符串b的每个字符是否都在Hashtable里，如果都存在，说明长字符串a包含短字符串b，否则，说明不包含。 再进一步，我们可以对字符串A，用位运算（26bit整数表示)计算出一个“签名”，再用B中的字符到A里面进行查找。 26 位的签名代替了长度为26的数组，虽然都是O(1)，但是占用空间更小了，厉害！！！ 位签名——好好消化 这个方法的实质是用一个整数代替了hashtable，空间复杂度为O(1)，时间复杂度还是O(n + m)。 代码 注意移位 或的操作——位运算 注意在 多种运算符出现在同一个表达式中，注意使用括号来区分优先级 1234567891011121314151617181920212223242526272829303132#include&lt;string&gt;#include&lt;iostream&gt;using namespace std;bool isInclude(string s1, string s2)&#123; int hash = 0; for(int i = 0;i&lt;s2.size();i++) hash |= 1&lt;&lt;(s2[i]-'a') ; for(int j = 0;j&lt;s1.size();j++)&#123; if(((1&lt;&lt;(s1[j]-'a'))&amp;hash) == 0) return false; &#125; return true;&#125;int main(void)&#123; string s1 = "bfcd"; string s2 = "hah"; string s3 = "bhafcd"; bool result1 = isInclude(s1,s2); bool result2 = isInclude(s1,s3); bool result3 = isInclude(s2,s3); cout &lt;&lt; "s2 include s1 : " &lt;&lt; result1 &lt;&lt; endl; cout &lt;&lt; "s3 include s1 : " &lt;&lt; result2 &lt;&lt; endl; cout &lt;&lt; "s3 include s2 : " &lt;&lt; result3 &lt;&lt; endl; return 0;&#125; 举一反三1、变位词 如果两个字符串的字符一样，但是顺序不一样，被认为是兄弟字符串，比如bad和adb即为兄弟字符串，现提供一个字符串，如何在字典中迅速找到它的兄弟字符串，请描述数据结构和查询过程。 签名一致 字符串转换成整数题目描述输入一个由数字组成的字符串，把它转换成整数并输出。例如：输入字符串”123”，输出整数123。 给定函数原型int StrToInt(const char \*str) ，实现字符串转换成整数的功能，不能使用库函数atoi 这个问题中边界问题很重要 基本思路便是：从左至右扫描字符串，把之前得到的数字乘以10，再加上当前字符表示的数字。 以下细节： 空指针输入：输入的是指针，在访问空指针时程序会崩溃，因此在使用指针之前需要先判断指针是否为空。 正负符号：整数不仅包含数字，还有可能是以’+’或’-‘开头表示正负整数，因此如果第一个字符是’-‘号，则要把得到的整数转换成负整数。 非法字符：输入的字符串中可能含有不是数字的字符。因此，每当碰到这些非法的字符，程序应停止转换。 整型溢出：输入的数字是以字符串的形式输入，因此输入一个很长的字符串将可能导致溢出。 上述其它问题比较好处理，但溢出问题比较麻烦，所以咱们来重点看下溢出问题。 一般说来，当发生溢出时，取最大或最小的int值。 即大于正整数能表示的范围时返回MAX_INT：2147483647； 小于负整数能表示的范围时返回MIN_INT：-2147483648。 针对这种由于输入了一个很大的数字转换之后会超过能够表示的最大的整数而导致的溢出情况，我们有两种处理方式可以选择： 一个取巧的方式是把转换后返回的值n定义成long long，即long long n； 另外一种则是只比较n和MAX_INT / 10的大小，即： 若n &gt; MAX_INT / 10，那么说明最后一步转换时，n*10必定大于MAX_INT，所以在得知n &gt; MAX_INT / 10时，当即返回MAX_INT&lt;。 若n == MAX_INT / 10时，那么比较最后一个数字c跟MAX_INT % 10的大小，即如果n == MAX_INT / 10且c &gt; MAX_INT % 10，则照样返回MAX_INT。 对于上面第一种方式，虽然我们把n定义了长整型，但最后返回时系统会自动转换成整型。咱们下面主要来看第二种处理方式。 对于上面第二种方式，先举两个例子说明下： 如果我们要转换的字符串是”2147483697”，那么当我扫描到字符’9’时，判断出214748369 &gt; MAX_INT / 10 = 2147483647 / 10 = 214748364（C语言里，整数相除自动取整，不留小数），则返回MAX_INT； 如果我们要转换的字符串是”2147483648”，那么判断最后一个字符’8’所代表的数字8与MAX_INT % 10 = 7的大小，前者大，依然返回MAX_INT。 代码 自己写的 尤其注意：区分数字和字符串，比较的时候 ‘9’-‘0’才是9，不要忘了字符串要 -‘0’ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263#include&lt;iostream&gt;#include&lt;string&gt;using namespace std;bool isSign(char x)&#123; return ((x=='-')||(x=='+'))?true:false;&#125;bool isValid(char x)&#123; return ((x&gt;='0')&amp;&amp;(x&lt;='9'))?true:false;&#125;int atoi_(char* ptr)&#123; char* tmp = ptr; if(tmp==nullptr) throw "Input is invalid!(nullptr)" ; if(!isValid(*tmp)&amp;&amp;!isSign(*tmp)) throw "Input is invalid!"; bool sgn = (*tmp=='-')?false:true; if(isSign(*tmp)) tmp++; int result = 0; while(*tmp!='\0')&#123; if(!isValid(*tmp)) throw "Input is invalid"; if(result&gt;INT_MAX/10||((result==INT_MAX/10)&amp;&amp;((*tmp-'0')&gt;(INT_MAX%10+1-sgn))))&#123; cout &lt;&lt; "Overflow!" &lt;&lt; endl; result = sgn?INT_MAX:(INT_MIN); sgn = 1; break; &#125; result = result*10 + (*tmp-'0'); tmp++; &#125; return sgn?result:-result;&#125;int main(void)&#123; string s1 = "fadsfasdf"; string s2 = "+1234"; string s3 = "-12341324"; string s4 = "-2345a232"; string s5 = "111111111111111111111111"; string s6 = "-11111111111111111111111"; string s7 = "2147483647"; string s8 = "2147483648"; string s9 = "-2147483648"; string s10 = "-2147483649";// cout &lt;&lt; "s1 is:" &lt;&lt; atoi_(&amp;(s1[0])) &lt;&lt; endl; cout &lt;&lt; "s2 is:" &lt;&lt; atoi_(&amp;s2[0]) &lt;&lt; endl; cout &lt;&lt; "s3 is:" &lt;&lt; atoi_(&amp;s3[0]) &lt;&lt; endl;// cout &lt;&lt; "s4 is:" &lt;&lt; atoi_(&amp;s4[0]) &lt;&lt; endl; cout &lt;&lt; "s5 is:" &lt;&lt; atoi_(&amp;s5[0]) &lt;&lt; endl; cout &lt;&lt; "s7 is:" &lt;&lt; atoi_(&amp;s7[0]) &lt;&lt; endl; cout &lt;&lt; "s8 is:" &lt;&lt; atoi_(&amp;s8[0]) &lt;&lt; endl; cout &lt;&lt; "s9 is:" &lt;&lt; atoi_(&amp;s9[0]) &lt;&lt; endl; cout &lt;&lt; "s10 is:" &lt;&lt; atoi_(&amp;s10[0]) &lt;&lt; endl;// cout &lt;&lt; "nullptr is:" &lt;&lt; atoi_(nullptr) &lt;&lt; endl; return 0;&#125; 还是那四个点 nullptr 正负号 非法字符 溢出 举一反三 实现string到double的转换 分析：此题虽然类似于atoi函数，但毕竟double为64位，而且支持小数，因而边界条件更加严格，写代码时需要更加注意。 回文判断题目描述 回文，英文palindrome，指一个顺着读和反过来读都一样的字符串，比如madam、我爱我，这样的短句在智力性、趣味性和艺术性上都颇有特色，中国历史上还有很多有趣的回文诗。 那么，我们的第一个问题就是：判断一个字串是否是回文？ 有两种： 解法一：从首尾开始 向中间靠拢，依次判断两指针指向元素是否相等 解法二：从中间开始，向首尾扩散，依次判断两指针指向元素是否相等 虽然解法二的时空复杂度和解法一是一样的，但很快我们会看到，在某些回文问题里面，这个方法二有着自己的独到之处，可以方便的解决一类问题。 举一反三 1、判断一条单向链表是不是“回文” 分析：对于单链表结构，可以用两个指针从两端或者中间遍历并判断对应字符是否相等。但这里的关键就是如何朝两个方向遍历。由于单链表是单向的，所以要向两个方向遍历的话，可以采取经典的快慢指针的方法，即先位移到链表的中间位置，再将链表的后半逆置，最后用两个指针同时从链表头部和中间开始同时遍历并比较即可。 2、判断一个栈是不是“回文” 分析：对于栈的话，只需要将字符串全部压入栈，然后依次将各字符出栈，这样得到的就是原字符串的逆置串，分别和原字符串各个字符比较，就可以判断了。逆置串和原串相等，就是回文，这是等价的 最长回文子串[Manacher算法][https://segmentfault.com/a/1190000003914228] 字符串的全排列题目描述输入一个字符串，打印出该字符串中字符的所有排列。 例如输入字符串abc，则输出由字符a、b、c 所能排列出来的所有字符串 abc、acb、bac、bca、cab 和 cba。 分析与解法解法一 递归实现 从集合中依次选出每一个元素，作为排列的第一个元素，然后对剩余的元素进行全排列，如此递归处理，从而得到所有元素的全排列。以对字符串abc进行全排列为例，我们可以这么做：以abc为例 固定a，求后面bc的排列：abc，acb，求好后，a和b交换，得到bac 固定b，求后面ac的排列：bac，bca，求好后，c放到第一位置，得到cba 固定c，求后面ba的排列：cba，cab。 通过交换完成全排列 for 循环第二三步 千万不要写反了 代码（自己写的）： 1234567891011121314151617181920212223242526272829303132333435#include&lt;iostream&gt;#include&lt;string&gt;using namespace std;void PermutationCore(string&amp; str, int start, int end)&#123; if(start==end)&#123; for(int i = 0;i&lt;=end;i++) cout &lt;&lt; str[i]; cout &lt;&lt; endl; &#125; else&#123; for(int i = start;i&lt;=end;i++)&#123; swap(str[i],str[start]); PermutationCore(str, start+1, end); swap(str[i],str[start]); &#125; &#125;&#125;void Permutation(string&amp; str)&#123; int length = str.size(); PermutationCore(str,0,length-1);&#125;int main(void)&#123; string s1 = "abc";// string s2 = "dfaosdgfa"; Permutation(s1);// Permutation(s2); return 0;&#125; 解法二 字典序排列 什么是字典序 维基百科的定义：给定两个偏序集A和B,(a,b)和(a′,b′)属于笛卡尔集 A × B，则字典序定义为: (a,b) ≤ (a′,b′) 当且仅当 a &lt; a′ 或 (a = a′ 且 b ≤ b′)。 所以给定两个字符串，逐个字符比较，那么先出现较小字符的那个串字典顺序小，如果字符一直相等，较短的串字典顺序小。例如：abc &lt; abcd &lt; abde &lt; afab。 那有没有这样的算法，使得 起点： 字典序最小的排列, 1-n , 例如12345 终点： 字典序最大的排列，n-1, 例如54321 过程： 从当前排列生成字典序刚好比它大的下一个排列 答案是肯定的：有，即是STL中的next_permutation算法。 先分析下下一个排列的性质 假定现有字符串(A)x(B)，它的下一个排列是：(A)y(B’)，其中A、B和B’是“字符串”(可能为空），x和y是“字符”，前缀相同，都是A，且一定有y &gt; x。 那么，为使下一个排列字典顺序尽可能小，必有： A尽可能长 y尽可能小 B’里的字符按由小到大递增排列 现在的问题是：找到x和y。怎么找到呢？咱们来看一个例子。 比如说，现在我们要找21543的下一个排列，我们可以从左至右逐个扫描每个数，看哪个能增大（至于如何判定能增大，是根据如果一个数右面有比它大的数存在，那么这个数就能增大），我们可以看到最后一个能增大的数是：x = 1。 而1应该增大到多少？1能增大到它右面比它大的那一系列数中最小的那个数，即：y = 3，故此时21543的下一个排列应该变为23xxx，显然 xxx(对应之前的B’）应由小到大排，于是我们最终找到比“21543”大，但字典顺序尽量小的23145，找到的23145刚好比21543大。 由这个例子可以得出next_permutation算法流程为： next_permutation算法 定义 升序：相邻两个位置ai &lt; ai+1，ai 称作该升序的首位 步骤（二找、一交换、一翻转） 找到排列中最后（最右）一个升序的首位位置i，x = ai *ps：最后一个升序，说明后面都是降序排列* 找到排列中第i位右边最后一个比ai 大的位置j，y = aj 交换x，y 把第(i+ 1)位到最后的部分翻转 *ps：i+1位到最后都是降序，反转后是升序，是最小的情况* 我们现在使用next_permutation算法 这里我们需要保存当前的一个排列，要么更改原有字符串，要么额外开辟O(n)空间 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162#include&lt;iostream&gt;#include&lt;string&gt;using namespace std;void swap(char&amp; a, char&amp; b)&#123; char tmp = a; a = b; b = tmp;&#125;void Reverse(string&amp; s1, int indexOfLastAscend, int indexOfFirstLess)&#123; for(int i = indexOfLastAscend; i&lt;=(indexOfFirstLess+indexOfLastAscend)/2;i++) swap(s1[i], s1[indexOfFirstLess+indexOfLastAscend-i]);&#125;bool hasNextPermutation(string&amp; s1, int&amp; length)&#123; int indexOfLastAscend = -1; int indexOfFirstLess = -1; for(int i = length-1;i&gt;0;i--)&#123; if(s1[i]&gt;s1[i-1])&#123; indexOfLastAscend = i-1; break; &#125; &#125;// cout &lt;&lt; "indexOfLastAscend is:" &lt;&lt; indexOfLastAscend &lt;&lt; endl; if(indexOfLastAscend==-1) return false; for(int j = length-1;j&gt;=indexOfLastAscend;j--)&#123; if(s1[j]&gt;s1[indexOfLastAscend])&#123; indexOfFirstLess = j; break; &#125; &#125;// cout &lt;&lt; "indexOfFirstLess is:" &lt;&lt; indexOfFirstLess &lt;&lt; endl; if(indexOfFirstLess==-1) return false; swap(s1[indexOfLastAscend],s1[indexOfFirstLess]); //cout &lt;&lt; s1 &lt;&lt; endl; Reverse(s1, indexOfLastAscend+1, length-1); //cout &lt;&lt; s1 &lt;&lt; endl; return true; &#125; void Permutation(string&amp; s1)&#123; int length = s1.size(); cout &lt;&lt; s1 &lt;&lt; endl; while(hasNextPermutation(s1,length))&#123; cout &lt;&lt; s1 &lt;&lt; endl; &#125;&#125;int main(void)&#123; string s1 = "abc"; // we use original sort here; so we will change s1 or you can create a copy of s1 string s2 = "1234"; Permutation(s1); Permutation(s2); return 0;&#125; 解法总结由于全排列总共有n!种排列情况，所以不论解法一中的递归方法，还是上述解法二的字典序排列方法，这两种方法的时间复杂度都为O(n!)。 类似问题1、已知字符串里的字符是互不相同的，现在任意组合，比如ab，则输出aa，ab，ba，bb，编程按照字典序输出所有的组合。 分析：非简单的全排列问题（跟全排列的形式不同,abc全排列的话，只有6个不同的输出）。 本题可用递归的思想，设置一个变量表示已输出的个数，然后当个数达到字符串长度时，就输出。 首先，输出个数是长度的长度次方（上面说了互不相同，所以没有重复的可能性） 每次递归都是在字符串末尾+（所有字符中的一个，用for循环），然后递归，一个计数变量判断是否到达长度，达到就输出 类似于一个度为长度，深度为1+长度的树，然后我我们到子结点就输出字符串 2、如果不是求字符的所有排列，而是求字符的所有组合，应该怎么办呢？当输入的字符串中含有相同的字符串时，相同的字符交换位置是不同的排列，但是同一个组合。举个例子，如果输入abc，它的组合有a、b、c、ab、ac、bc、abc。 两层循环，第一层固定住前k个字符 第二层，从剩下的n-k字符中挑选出来apped到第k+1个字符上 O(n^2)：因为一共有这么多种组合 3、写一个程序，打印出以下的序列。 (a),(b),(c),(d),(e)……..(z) (a,b),(a,c),(a,d),(a,e)……(a,z),(b,c),(b,d)…..(b,z),(c,d)…..(y,z) (a,b,c),(a,b,d)….(a,b,z),(a,c,d)….(x,y,z) …. (a,b,c,d,…..x,y,z) 思路同第2题 数组笔试和面试中，除了字符串，另一类出现频率极高的问题便是与数组相关的问题。在阅读完第1章和本第二章后，读者会慢慢了解到解决面试编程题的有几种常用思路。首先一般考虑“万能的”暴力穷举（递归、回溯），如求n个数的全排列或八皇后（N皇后问题）。但因为穷举时间复杂度通常过高，所以需要考虑更好的方法，如分治法（通过分而治之，然后归并），以及空间换时间（如活用哈希表）。 此外，选择合适的数据结构可以显著提升效率，如寻找最小的k个数中，用堆代替数组。 再有，如果题目允许排序，则可以考虑排序。比如，寻找和为定值的两个数中，先排序，然后用前后两个指针往中间扫。而如果如果已经排好序了（如杨氏矩阵查找中），则想想有无必要二分。但是，如果题目不允许排序呢？这个时候，我们可以考虑不改变数列顺序的贪心算法（如最小生成树Prim、Kruskal及最短路dijkstra），或动态规划（如 01背包问题，每一步都在决策）。 最后，注意细节处理，不要忽略边界条件，如字符串转换成整数。 寻找最小的k个数题目描述输入n个整数 输出最小的k个 解法一要求一个序列中最小的k个数，按照惯有的思维方式，则是先对这个序列从小到大排序，然后输出前面的最小的k个数。 至于选取什么的排序方法，我想你可能会第一时间想到快速排序（我们知道，快速排序平均所费时间为n\*logn），然后再遍历序列中前k个元素输出即可。因此，总的时间复杂度：O（n * log n)+O(k)=O（n * log n）。 解法二咱们再进一步想想，题目没有要求最小的k个数有序，也没要求最后n-k个数有序。既然如此，就没有必要对所有元素进行排序。这时，咱们想到了用选择或交换排序，即： 1、遍历n个数，把最先遍历到的k个数存入到大小为k的数组中，假设它们即是最小的k个数；2、对这k个数，利用选择或交换排序找到这k个元素中的最大值kmax（找最大值需要遍历这k个数，时间复杂度为O（k））；3、继续遍历剩余n-k个数。假设每一次遍历到的新的元素的值为x，把x与kmax比较：如果x &lt; kmax ，用x替换kmax，并回到第二步重新找出k个元素的数组中最大元素kmax‘；如果x &gt;= kmax，则继续遍历不更新数组。 每次遍历，更新或不更新数组的所用的时间为O（k）或O（0）。故整趟下来，时间复杂度为n\*O（k）=O（n\*k）。 解法三更好的办法是维护容量为k的最大堆，原理跟解法二的方法相似：() 解法二是维护topk的数组，解法三是维护topk的堆 1、用容量为k的最大堆存储最先遍历到的k个数，同样假设它们即是最小的k个数； 2、堆中元素是有序的，令k1&lt;k2&lt;…&lt;kmax（kmax设为最大堆中的最大元素） 3、遍历剩余n-k个数。假设每一次遍历到的新的元素的值为x，把x与堆顶元素kmax比较：如果x &lt; kmax，用x替换kmax，然后更新堆（用时logk）；否则不更新堆。 这样下来，总的时间复杂度:O（k+（n-k）\*logk）=O（n\*logk）——O(n*lgk)。此方法得益于堆中进行查找和更新的时间复杂度均为：O(logk)（若使用解法二：在数组中找出最大元素，时间复杂度：O（k））。 解法四在《数据结构与算法分析–c语言描述》一书，第7章第7.7.6节中，阐述了一种在平均情况下，时间复杂度为O（N）的快速选择算法。如下述文字： 选取S中一个元素作为枢纽元v，将集合S-{v}分割成S1和S2，就像快速排序那样 如果k &lt;= |S1|，那么第k个最小元素必然在S1中。在这种情况下，返回QuickSelect(S1, k)。 如果k = 1 + |S1|，那么枢纽元素就是第k个最小元素，即找到，直接返回它。 否则，这第k个最小元素就在S2中，即S2中的第（k - |S1| - 1）个最小元素，我们递归调用并返回QuickSelect(S2, k - |S1| - 1)。 此算法的平均运行时间为O(n)。——这部分需要证明 在《数据结构与算法分析–c语言描述》一书，第7章第7.7.6节中，阐述了一种在平均情况下，时间复杂度为O（N）的快速选择算法。如下述文字： + 选取S中一个元素作为枢纽元v，将集合S-{v}分割成S1和S2，就像快速排序那样 如果k &lt;= |S1|，那么第k个最小元素必然在S1中。在这种情况下，返回QuickSelect(S1, k)。 如果k = 1 + |S1|，那么枢纽元素就是第k个最小元素，即找到，直接返回它。 否则，这第k个最小元素就在S2中，即S2中的第（k - |S1| - 1）个最小元素，我们递归调用并返回QuickSelect(S2, k - |S1| - 1)。 此算法的平均运行时间为O(n)。 示例代码如下： 12345678910111213141516171819202122232425262728293031//QuickSelect 将第k小的元素放在 a[k-1] void QuickSelect( int a[], int k, int left, int right )&#123; int i, j; int pivot; if( left + cutoff &lt;= right ) &#123; pivot = median3( a, left, right ); //取三数中值作为枢纽元，可以很大程度上避免最坏情况 i = left; j = right - 1; for( ; ; ) &#123; while( a[ ++i ] &lt; pivot )&#123; &#125; while( a[ --j ] &gt; pivot )&#123; &#125; if( i &lt; j ) swap( &amp;a[ i ], &amp;a[ j ] ); else break; &#125; //重置枢纽元 swap( &amp;a[ i ], &amp;a[ right - 1 ] ); if( k &lt;= i ) QuickSelect( a, k, left, i - 1 ); else if( k &gt; i + 1 ) QuickSelect( a, k, i + 1, right ); &#125; else InsertSort( a + left, right - left + 1 );&#125; 这个快速选择SELECT算法，类似快速排序的划分方法。N个数存储在数组S中，再从数组中选取“中位数的中位数”作为枢纽元X，把数组划分为Sa和Sb俩部分，Sa&lt;=X&lt;=Sb，如果要查找的k个元素小于Sa的元素个数，则返回Sa中较小的k个元素，否则返回Sa中所有元素+Sb中小的k-|Sa|个元素，这种解法在平均情况下能做到O(n)的复杂度。 更进一步，《算法导论》第9章第9.3节介绍了一个最坏情况下亦为O(n)时间的SELECT算法，有兴趣的读者可以参看。 举一反三1、谷歌面试题：输入是两个整数数组，他们任意两个数的和又可以组成一个数组，求这个和中前k个数怎么做？ 分析： 1234567“假设两个整数数组为A和B，各有N个元素，任意两个数的和组成的数组C有N^2个元素。 那么可以把这些和看成N个有序数列： A[1]+B[1] &lt;= A[1]+B[2] &lt;= A[1]+B[3] &lt;=… A[2]+B[1] &lt;= A[2]+B[2] &lt;= A[2]+B[3] &lt;=… … A[N]+B[1] &lt;= A[N]+B[2] &lt;= A[N]+B[3] &lt;=… 问题转变成，在这N^2个有序数列里，找到前k小的元素” 需要n个指针，每次对n个比较（不需要排序，只需要找最小值），然后最小值的那个指针向后移动，然后重复上述操作k次，即找到MinK 2、有两个序列A和B,A=(a1,a2,…,ak),B=(b1,b2,…,bk)，A和B都按升序排列。对于1&lt;=i,j&lt;=k，求k个最小的（ai+bj）。要求算法尽量高效。 3、给定一个数列a1,a2,a3,…,an和m个三元组表示的查询，对于每个查询(i，j，k)，输出ai，ai+1，…，aj的升序排列中第k个数。 寻找和为定值的两个数题目描述输入一个数组和一个数字，在数组中查找两个数，使得它们的和正好是输入的那个数字。 要求时间复杂度是O(N)。如果有多对数字的和等于输入的数字，输出任意一对即可。 例如输入数组1、2、4、7、11、15和数字15。由于4+11=15，因此输出4和11。 分析与解法咱们试着一步一步解决这个问题（注意阐述中数列有序无序的区别）： 直接穷举，从数组中任意选取两个数，判定它们的和是否为输入的那个数字。此举复杂度为O(N^2)。很显然，我们要寻找效率更高的解法 题目相当于，对每个a[i]，查找sum-a[i]是否也在原始序列中，每一次要查找的时间都要花费为O(N)，这样下来，最终找到两个数还是需要O（N^2）的复杂度。那如何提高查找判断的速度呢？ 答案是二分查找，可以将O(N)的查找时间提高到O(log N)，这样对于N个a[i]，都要花logN的时间去查找相对应的sum-a[i]是否在原始序列中，总的时间复杂度已降为O(N log N)，且空间复杂度为O(1)。 （如果有序，直接二分O(N log N)，如果无序，先排序后二分，复杂度同样为O（N log N + N log N）= O(N log N)，空间复杂度总为O(1)）。 可以继续优化做到时间O(N)么 注意 二分查找可以将O(N) 变O(lgN)——常规思路 解法一根据前面的分析，a[i]在序列中，如果a[i]+a[k]=sum的话，那么sum-a[i]（a[k])也必然在序列中。 举个例子，如下： 原始序列： 1、 2、 4、 7、11、15 用输入数字15减一下各个数，得到对应的序列为： 14、13、11、8、4、 0 第一个数组以一指针i 从数组最左端开始向右扫描，第二个数组以一指针j 从数组最右端开始向左扫描，如果第一个数组出现了和第二个数组一样的数，即a[*i]=a[*j]，就找出这俩个数来了。 如上，i，j最终在第一个，和第二个序列中找到了相同的数4和11，所以符合条件的两个数，即为4+11=15。 怎么样，两端同时查找，时间复杂度瞬间缩短到了O(N)，但却同时需要O(N)的空间存储第二个数组。 两端如何同时查找是O(N)?? 解法二当题目对时间复杂度要求比较严格时，我们可以考虑下用空间换时间，上述解法一即是此思想，此外，构造hash表也是典型的用空间换时间的处理办法。 即给定一个数字，根据hash映射查找另一个数字是否也在数组中，只需用O(1)的时间，前提是经过O(N)时间的预处理，和用O(N)的空间构造hash表。 但能否做到在时间复杂度为O(N)的情况下，空间复杂度能进一步降低达到O(1)呢？ 用哈希表确实可以查找是O(N) 解法三如果数组是无序的，先排序(N log N)，然后用两个指针i，j，各自指向数组的首尾两端，令i=0，j=n-1，然后i++，j–，逐次判断a[i]+a[j]?=sum， 如果某一刻a[i]+a[j] &gt; sum，则要想办法让sum的值减小，所以此刻i不动，j–； 如果某一刻a[i]+a[j] &lt; sum，则要想办法让sum的值增大，所以此刻i++，j不动。 所以，数组无序的时候，时间复杂度最终为O(N log N + N)=O(N log N)。 如果原数组是有序的，则不需要事先的排序，直接用两指针分别从头和尾向中间扫描，O(N)搞定，且空间复杂度还是O(1)。 下面，咱们先来实现此思路（这里假定数组已经是有序的），代码可以如下编写： 解法总结不论原序列是有序还是无序，解决这类题有以下三种办法： 1、二分（若无序，先排序后二分），时间复杂度总为O(N log N)，空间复杂度为O（1）； 2、扫描一遍X-S[i] 映射到一个数组或构造hash表，时间复杂度为O(N)，空间复杂度为O(N)； 3、两个指针两端扫描（若无序，先排序后扫描），时间复杂度最后为：有序O(N)，无序O(N log N + N)=O(N log N)，空间复杂度都为O(1)。 所以，要想达到时间O(N)，空间O(1)的目标，除非原数组是有序的（指针扫描法），不然，当数组无序的话，就只能先排序，后指针扫描法或二分（时间 O(Nlog N)，空间O(1)），或映射或hash（时间O(N)，空间O(N)）。时间或空间，必须牺牲一个，达到平衡。 综上，若是数组有序的情况下，优先考虑两个指针两端扫描法，以达到最佳的时O(N)，空O(1)效应。否则，如果要排序的话，时间复杂度最快当然是只能达到O(N log N)，空间O(1)则不在话下。 问题扩展 如果在返回找到的两个数的同时，还要求你返回这两个数的位置列？ 如果需要输出所有满足条件的整数对呢? 如果把题目中的要你寻找的两个数改为“多个数”，或任意个数列? 举一反三1、在二元树中找出和为某一值的所有路径 输入一个整数和一棵二元树，从树的根结点开始往下访问一直到叶结点所经过的所有结点形成一条路径，然后打印出和与输入整数相等的所有路径。 例如输入整数22和如下二元树 110 / 5 12/ 4 7 则打印出两条路径：10, 12和10, 5, 7。 其中，二元树节点的数据结构定义为： 123456struct BinaryTreeNode // a node in the binary tree&#123; int m_nValue; // value of node BinaryTreeNode *m_pLeft; // left child of node BinaryTreeNode *m_pRight; // right child of node&#125;; 2、有一个数组a，设有一个值n。在数组中找到两个元素a[i]和a[j]，使得a[i]+a[j]等于n，求出所有满足以上条件的i和j。 3、3-sum问题 给定一个整数数组，判断能否从中找出3个数a、b、c，使得他们的和为0，如果能，请找出所有满足和为0个3个数对。 4、4-sum问题 给定一个整数数组，判断能否从中找出4个数a、b、c、d，使得他们的和为0，如果能，请找出所有满足和为0个4个数对。 寻找和为定值的多个数题目描述输入两个整数n和sum，从数列1，2，3…….n 中随意取几个数，使其和等于sum，要求将其中所有的可能组合列出来。 注意到取n，和不取n个区别即可，考虑是否取第n个数的策略，可以转化为一个只和前n-1个数相关的问题。 如果取第n个数，那么问题就转化为“取前n-1个数使得它们的和为sum-n”，对应的代码语句就是sumOfkNumber(sum - n, n - 1)； 如果不取第n个数，那么问题就转化为“取前n-1个数使得他们的和为sum”，对应的代码语句为sumOfkNumber(sum, n - 1) 形成递推式 代码（自己写的） 特别注意：list数据结构是没有下标操作的 所以我们取值要使用迭代器 123456789101112131415161718192021222324252627282930#include&lt;list&gt;#include&lt;iostream&gt;using namespace std;void sumOfkNumber(int sum , int K, list&lt;int&gt;&amp; list1)&#123;// cout &lt;&lt; "sum is:" &lt;&lt;sum &lt;&lt; endl;// cout &lt;&lt; "K is:" &lt;&lt; K &lt;&lt; endl; if(sum&lt;=0 || K&lt;=0) return; if(sum==K)&#123; list1.reverse();// reverse here is to get a reverse sort (or descend sort) rather than reverse the number!!! for(list&lt;int&gt;::iterator iter = list1.begin();iter!=list1.end();iter++) cout &lt;&lt; *iter &lt;&lt; ' ' ; cout &lt;&lt; K &lt;&lt; endl; list1.reverse(); &#125; list1.push_front(K); sumOfkNumber(sum-K, K-1, list1); list1.pop_front(); sumOfkNumber(sum, K-1, list1);&#125;int main(void)&#123; int sum = 10; int K = 10; list&lt;int&gt; list1; sumOfkNumber(sum, K, list1); return 0;&#125; 解法二 没懂 有时间再看这个问题属于子集和问题（也是背包问题）。本程序采用回溯法+剪枝，其中X数组是解向量，t=∑(1,..,k-1)Wi*Xi, r=∑(k,..,n)Wi，且 若t+Wk+W(k+1)&lt;=M,则Xk=true，递归左儿子(X1,X2,..,X(k-1),1)；否则剪枝； 若t+r-Wk&gt;=M &amp;&amp; t+W(k+1)&lt;=M,则置Xk=0，递归右儿子(X1,X2,..,X(k-1),0)；否则剪枝； 本题中W数组就是(1,2,..,n),所以直接用k代替WK值。 代码编写如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950//输入t， r， 尝试Wkvoid SumOfkNumber(int t, int k, int r, int&amp; M, bool&amp; flag, bool* X)&#123; X[k] = true; // 选第k个数 if (t + k == M) // 若找到一个和为M，则设置解向量的标志位，输出解 &#123; flag = true; for (int i = 1; i &lt;= k; ++i) &#123; if (X[i] == 1) &#123; printf("%d ", i); &#125; &#125; printf("\n"); &#125; else &#123; // 若第k+1个数满足条件，则递归左子树 if (t + k + (k + 1) &lt;= M) &#123; SumOfkNumber(t + k, k + 1, r - k, M, flag, X); &#125; // 若不选第k个数，选第k+1个数满足条件，则递归右子树 if ((t + r - k &gt;= M) &amp;&amp; (t + (k + 1) &lt;= M)) &#123; X[k] = false; SumOfkNumber(t, k + 1, r - k, M, flag, X); &#125; &#125;&#125;void search(int&amp; N, int&amp; M)&#123; // 初始化解空间 bool* X = (bool*)malloc(sizeof(bool)* (N + 1)); memset(X, false, sizeof(bool)* (N + 1)); int sum = (N + 1) * N * 0.5f; if (1 &gt; M || sum &lt; M) // 预先排除无解情况 &#123; printf("not found\n"); return; &#125; bool f = false; SumOfkNumber(0, 1, sum, M, f, X); if (!f) &#123; printf("not found\n"); &#125; free(X);&#125; 0-1 背包问题（背景介绍）0-1背包问题是最基础的背包问题，其具体描述为：有N件物品和一个容量为V的背包。放入第i件物品耗费的容量是Ci，得到的价值是Wi。求解将哪些物品装入背包可使价值总和最大。 简单分析下：这是最基础的背包问题，特点是每种物品仅有一件，可以选择放或不放。用子问题定义状态：即F[i, v]表示前i件物品恰放入一个容量为v的背包可以获得的最大价值。则其状态转移方程便是： F[i, v] = max{F[i-1, v], F[i-1, v-Ci ] + Wi} 根据前面的分析，我们不难理解这个方程的意义：“将前i件物品放入容量为v的背包中”这个子问题，若只考虑第i件物品的策略（放或不放），那么就可以转化为一个只和前 i-1 件物品相关的问题。即： 如果不放第i件物品，那么问题就转化为“前i-1件物品放入容量为v的背包中”，价值为 F[i-1, v ]； 如果放第i件物品，那么问题就转化为“前i-1件物品放入剩下的容量为v-Ci的背包中”，此时能获得的最大价值就是F[i-1, v-Ci]再加上通过放入第i件物品获得的价值Wi。 这段代码的时间和空间复杂度均为 O(VN)，其中时间复杂度应该已经不能再优化了，但空间复杂度却可以优化到O(V)。感兴趣的读者可以继续思考或者参考网上一个不错的文档《背包问题九讲》。 举一反三1、《挑战程序设计竞赛》的开篇有个类似的抽签问题，挺有意思，题目如下： 将写有数字的n个纸片放入一个纸箱子中，然后你和你的朋友从纸箱子中抽取4张纸片，每次记下纸片上的数字后放回子箱子中，如果这4个数字的和是m，代表你赢，否则就是你的朋友赢。 请编写一个程序，当纸片上所写的数字是k1，k2，k3，k4，..，kn时，是否存在抽取4次和为m的方案，如果存在，输出YES；否则，输出NO。 限制条件： 1 &lt;= n &lt;= 50 1 &lt;= m &lt;= 10^8 1 &lt;= ki &lt;= 10^8 分析：最容易想到的方案是用4个for循环直接穷举所有方案，时间复杂度为O（N^4）,主体代码如下： 1234567891011121314151617//通过4重for循环枚举所有方案for (int a = 0; a &lt; n, a++)&#123; for (int b = 0; b &lt; n; b++) &#123; for (int c = 0; c &lt; n; c++) &#123; for (int d = 0; d &lt; n; d++) &#123; if (k[a] + k[b] + k[c] + k[d] == m) &#123; f = true; &#125; &#125; &#125; &#125;&#125; 但如果当n远大于50时，则程序会显得非常吃力，如此，我们需要找到更好的办法。 提供两个思路： ①最内侧关于d的循环所做的事情：检查是否有d满足ka+ kb +kc + kd = m，移动下式子，等价于：检查是否有d使得kd = m - ka - kb - kc，也就是说，只要检查k中所有元素，判断是否有等于m-ka-kb-ka 的元素即可。设m-ka-kb-ka = x，接下来，就是要看x是否存在于数组k中，此时，可以先把数组k排序，然后利用二分查找在数组k中找x； ②进一步，内侧的两个循环所做的事情：检查是否有c和d满足kc + kd = m - ka -kb。同样，可以预先枚举出kc+kd所得的n^2数字并排好序，便可以利用二分搜索继续求解。 2、给定整数a1、a2、a3、…、an，判断是否可以从中选出若干个数，使得它们的和等于k（k任意给定，且满足-10^8 &lt;= k &lt;= 10^8）。 分析：此题相对于本节“寻找满足条件的多个数”如出一辙，不同的是此题只要求判断，不要求把所有可能的组合给输出来。因为此题需要考虑到加上a[i]和不加上a[i]的情况，故可以采用深度优先搜索的办法，递归解决。 3、有n个数，输出期中所有和为s的k个数的组合。 分析：此题有两个坑，一是这里的n个数是任意给定的，不一定是：1,2,3…n，所以可能有重复的数（如果有重复的数怎么处理？）；二是不要求你输出所有和为s的全部组合，而只要求输出和为s的k个数的组合。 举个例子，假定n=6，这6个数为：1 2 1 3 0 1，如果要求输出和为3的全部组合的话， 1 2 1 2 0 0 3 1 1 1 1 1 1 0 而题目加了个限制条件，若令k=2，则只要求输出：[{1,2}, {0,3}] 即可。 最大连续子数组和题目描述输入一个整形数组，数组里有正数也有负数。数组中连续的一个或多个整数组成一个子数组，每个子数组都有一个和。 求所有子数组的和的最大值，要求时间复杂度为O(n)。 例如输入的数组为1, -2, 3, 10, -4, 7, 2, -5，和最大的子数组为3, 10, -4, 7, 2， 因此输出为该子数组的和18。 解法一暴力解法。。 解法二关键还是找到状态转移 事实上，当我们令currSum为当前最大子数组的和，maxSum为最后要返回的最大子数组的和，当我们往后扫描时， 对第j+1个元素有两种选择：要么放入前面找到的子数组，要么做为新子数组的第一个元素； 如果currSum加上当前元素a[j]后不小于a[j]，则令currSum加上a[j]，否则currSum重新赋值，置为下一个元素，即currSum = a[j]。 同时，当currSum &gt; maxSum，则更新maxSum = currSum，否则保持原值，不更新。 即 12currSum = max(a[j], currSum + a[j])maxSum = max(maxSum, currSum) 代码，（自己写的） 注意：maxSum的初始值和currSum的初始值的不同 1234567891011121314151617181920212223242526272829303132333435#include&lt;iostream&gt;#include&lt;vector&gt;using namespace std;int max_(vector&lt;int&gt;&amp; s1)&#123; int result = s1[0]; for(vector&lt;int&gt;::iterator iter = s1.begin();iter!=s1.end();iter++)&#123; if(*iter&gt;result) result = *iter; &#125; return result;&#125;int getMaxSumSubArray(vector&lt;int&gt;&amp; array1)&#123; //int maxSum = max_(array1); int maxSum = array1[0]; int currSum = 0; for(int i = 0;i&lt;array1.size();i++)&#123; currSum = array1[i]&gt;array1[i]+currSum?array1[i]:array1[i]+currSum; maxSum = currSum&gt;maxSum?currSum:maxSum; &#125; return maxSum;&#125;int main(void)&#123; vector&lt;int&gt; array1&#123;1, -2, 3, 10, -4, 7, 2, -5&#125;; vector&lt;int&gt; array2&#123;-9,-2,-3,-1,-1000,-9&#125;; int maxSum = getMaxSumSubArray(array1); cout &lt;&lt; "Max sum of sub array is :" &lt;&lt; maxSum &lt;&lt; endl; maxSum = getMaxSumSubArray(array2); cout &lt;&lt; "Max sum of sub array2 is:" &lt;&lt; maxSum &lt;&lt; endl; return 0;&#125; 问题扩展 如果数组是二维数组，同样要你求最大子数组的和列? 如果是要你求子数组的最大乘积列? 如果同时要求输出子段的开始和结束列? 举一反三1 给定整型数组，其中每个元素表示木板的高度，木板的宽度都相同，求这些木板拼出的最大矩形的面积。并分析时间复杂度。 此题类似leetcode里面关于连通器的题，需要明确的是高度可能为0，长度最长的矩形并不一定是最大矩形，还需要考虑高度很高，但长度较短的矩形。如[5,4,3,2,4,5,0,7,8,4,6]中最大矩形的高度是[7,8,4,6]组成的矩形，面积为16。 2、环面上的最大子矩形 《算法竞赛入门经典》 P89 页。 3、最大子矩阵和 一个M\*N的矩阵，找到此矩阵的一个子矩阵，并且这个子矩阵的元素的和是最大的，输出这个最大的值。如果所有数都是负数，就输出0。 例如：3\*5的矩阵： 1 2 0 3 4 2 3 4 5 1 1 1 5 3 0 和最大的子矩阵是： 4 5 5 3 最后输出和的最大值17。 4、允许交换两个数的位置 求最大子数组和。 跳台阶问题题目描述一个台阶总共有n 级，如果一次可以跳1 级，也可以跳2 级。 求总共有多少总跳法，并分析算法的时间复杂度。 也是找状态转移，——斐波那契数列 我们把上面的分析用一个公式总结如下： 123 / 1 n = 1f(n)= 2 n = 2 \ f(n-1) + f(n-2) n &gt; 2 原来上述问题就是我们平常所熟知的Fibonacci数列问题。可编写代码，如下： 12345678long long Fibonacci(unsigned int n)&#123; int result[3] = &#123;0, 1, 2&#125;; if (n &lt;= 2) return result[n]; return Fibonacci(n - 1) + Fibonacci(n - 2);&#125; 那么，如果一个人上台阶可以一次上1个，2个，或者3个呢？这个时候，公式是这样写的： 1234 / 1 n = 1f(n)= 2 n = 2 4 n = 3 //111, 12, 21, 3 \ f(n-1)+f(n-2)+f(n-3) n &gt; 3 解法二解法一用的递归的方法有许多重复计算的工作，事实上，我们可以从后往前推，一步步利用之前计算的结果递推。 ——递归转循环 初始化时，dp[0]=dp[1]=1，然后递推计算即可：dp[n] = dp[n-1] + dp[n-2]。 参考代码如下： 12345678910111213141516//1, 1, 2, 3, 5, 8, 13, 21..int ClimbStairs(int n)&#123; int dp[3] = &#123; 1, 1 &#125;; if (n &lt; 2) &#123; return 1; &#125; for (int i = 2; i &lt;= n; i++) &#123; dp[2] = dp[0] + dp[1]; dp[0] = dp[1]; dp[1] = dp[2]; &#125; return dp[2];&#125; 举一反三1、兔子繁殖问题 13世纪意大利数学家斐波那契在他的《算盘书》中提出这样一个问题：有人想知道一年内一对兔子可繁殖成多少对，便筑了一道围墙把一对兔子关在里面。已知一对兔子每一个月可以生一对小兔子，而一对兔子出生后.第三个月（注意是第几个月）开始生小兔子假如一年内没有发生死亡，则一对兔子一年内能繁殖成多少对？ 分析：这就是斐波那契数列的由来，本节的跳台阶问题便是此问题的变形，只是换了种表述形式。 2、换硬币问题。 想兑换100元钱，有1,2,5,10四种钱，问总共有多少兑换方法。 相当于每次可以跳1 2 5 10 问总共有多少种跳法。 好好理解下面的代码， 通过一个简单的循环嵌套完成了在不同区间不同表达式的统一代码，数学原理是通过将表达式拆分再相加，利用循环把区间区别开 而且 由于表达式没有一致性，我们这里用一个数组来存储value 12345678910const int N = 100;int dimes[] = &#123; 1, 2, 5, 10 &#125;;int arr[N + 1] = &#123; 1 &#125;; //这里如果不这么初始化，其他部分可能不是0！！！，所以数组还是要显式初始化，不要默认初始化for (int i = 0; i &lt; sizeof(dimes) / sizeof(int); ++i)&#123; for (int j = dimes[i]; j &lt;= N; ++j) &#123; arr[j] += arr[j - dimes[i]]; &#125;&#125; 此问题还有一个变形，就是打印出路径目前只想到要使用递归来解决这个问题。对此，利用一个vector来保存路径，每进入一层，push_back一个路径，每退出一层，pop_back一个路径。 奇偶排序题目描述输入一个整数数组，调整数组中数字的顺序，使得所有奇数位于数组的前半部分，所有偶数位于数组的后半部分。要求时间复杂度为O(n)。 分析与解法还是暴力解法。。。pass 事实上，若把奇数看做是小的数，偶数看做是大的数，那么按照题目所要求的奇数放在前面偶数放在后面，就相当于小数放在前面大数放在后面，联想到快速排序中的partition过程，不就是通过一个主元把整个数组分成大小两个部分么，小于主元的小数放在前面，大于主元的大数放在后面。 partition过程有以下两种实现： 一头一尾两个指针往中间扫描，如果头指针遇到的数比主元大且尾指针遇到的数比主元小，则交换头尾指针所分别指向的数字； 按照题目要求，最终是为了让奇数排在数组的前面，偶数排在数组的后面，所以头指针理应指向的就是奇数，尾指针理应指向的就是偶数，故当头指针指向的是偶数且尾指针指向的是奇数时，我们就当立即交换它们所指向的数字。 注意头尾指针++和—的时机 代码（自己写的） 12345678910111213141516171819202122232425262728293031323334353637383940#include&lt;iostream&gt;#include&lt;vector&gt;using namespace std;void swap(int&amp; a , int&amp; b)&#123; int tmp = a; a = b; b = tmp;&#125;bool isEven(int&amp; num)&#123; return 1&amp;(num-1);&#125;void oddEvenSort(vector&lt;int&gt;&amp; array1)&#123; int length = array1.size(); int head = 0; int tail = length - 1; while(head&lt;tail)&#123; if(isEven(array1[head])&amp;&amp;!isEven(array1[tail]))&#123; swap(array1[head++],array1[tail--]); continue; &#125; if(!isEven(array1[head])) head++; if(isEven(array1[tail])) tail--; &#125;&#125;int main(void)&#123; vector&lt;int&gt; array1 &#123;2, 8,7, 1, 3, 5, 6, 4&#125;; oddEvenSort(array1); for(vector&lt;int&gt;::iterator iter = array1.begin(); iter != array1.end(); iter++) cout &lt;&lt; *iter &lt;&lt; ' ' ; cout &lt;&lt; endl; return 0;&#125; 一前一后两个指针同时从左往右扫，如果前指针遇到的数比主元小，则后指针右移一位，然后交换各自所指向的数字。 举一反三一个未排序整数数组，有正负数，重新排列使负数排在正数前面，并且要求不改变原来的正负数之间相对顺序，比如： input: 1,7,-5,9,-12,15 ans: -5,-12,1,7,9,15 要求时间复杂度O(n),空间O(1)。 分析：如果本题没有这个要求“并且要求不改变原来的正负数之间相对顺序”，那么同奇偶数排序是一道题，但加上这个不能改变正负数之间的相对顺序后，便使得问题变得比较艰难了，若有兴趣，读者可以参考这篇论文《STABLE MINIMUM SPACE PARTITIONING IN LINEAR TIME》。 荷兰国旗题目描述拿破仑席卷欧洲大陆之后，代表自由，平等，博爱的竖色三色旗也风靡一时。荷兰国旗就是一面三色旗（只不过是横向的），自上而下为红白蓝三色。 该问题本身是关于三色球排序和分类的，由荷兰科学家Dijkstra提出。由于问题中的三色小球有序排列后正好分为三类，Dijkstra就想象成他母国的国旗，于是问题也就被命名为荷兰旗问题（Dutch National Flag Problem）。 下面是问题的正规描述： 现有n个红白蓝三种不同颜色的小球，乱序排列在一起，请通过两两交换任意两个球，使得从左至右，依次是一些红球、一些白球、一些蓝球。 分析与解法初看此题，我们貌似除了暴力解决并无好的办法，但联想到我们所熟知的快速排序算法呢？ 我们知道，快速排序依托于一个partition分治过程，在每一趟排序的过程中，选取的主元都会把整个数组排列成一大一小的部分，那我们是否可以借鉴partition过程设定三个指针完成重新排列，使得所有球排列成三个不同颜色的球呢？ Partition其实是一个分类的思想 好好利用，分类但不排序，通过递归可以完成快排 解法通过前面的分析得知，这个问题类似快排中partition过程，只是需要用到三个指针：一个前指针begin，一个中指针current，一个后指针end，current指针遍历整个数组序列，当 current指针所指元素为0时，与begin指针所指的元素交换，而后current++，begin++ ； 这个地方begin所指向：如果begin current相同 那么是0，否则是1 ，不会指向2（注意理解逻辑） current指针所指元素为1时，不做任何交换（即球不动），而后current++ ； current指针所指元素为2时，与end指针所指的元素交换，而后，current指针不动，end– 。 为什么上述第3点中，current指针所指元素为2时，与end指针所指元素交换之后，current指针不能动呢？因为第三步中current指针所指元素与end指针所指元素交换之前，如果end指针之前指的元素是0，那么与current指针所指元素交换之后，current指针此刻所指的元素是0，此时，current指针能动么？不能动，因为如上述第1点所述，如果current指针所指的元素是0，还得与begin指针所指的元素交换。 代码（自己写的） 1234567891011121314151617181920212223242526272829303132333435#include&lt;iostream&gt;#include&lt;vector&gt;using namespace std;void threeColorSort(vector&lt;int&gt;&amp; array)&#123; vector&lt;int&gt;::iterator begin = array.begin(); vector&lt;int&gt;::iterator current = array.begin(); vector&lt;int&gt;::iterator end = array.end(); while(current&lt;end)&#123; if(*current == 0)&#123; swap(*current, *begin); begin++; current++; // *begin must be 1 &#125; else if(*current == 1)&#123; current++; &#125; else&#123; swap(*current, *end); end--; &#125; &#125;&#125;int main(void)&#123; vector&lt;int&gt; array = &#123;1,2,0,1,1,0,0,1,1,1,2,0,2,1,2&#125;; threeColorSort(array); for(vector&lt;int&gt;::iterator iter=array.begin(); iter!=array.end() ; iter++) cout &lt;&lt; *iter &lt;&lt; ' ' ; cout &lt;&lt; endl; return 0;&#125; 举一反三给定一个字符串里面只有”R” “G” “B” 三个字符，请排序，最终结果的顺序是R在前 G中 B在后。 要求：空间复杂度是O(1)，且只能遍历一次字符串。 矩阵相乘题目描述请编程实现矩阵乘法，并考虑当矩阵规模较大时的优化方法。 分析与解法根据wikipedia上的介绍：两个矩阵的乘法仅当第一个矩阵A的行数和另一个矩阵B的列数相等时才能定义。如A是m×n矩阵，B是n×p矩阵，它们的乘积AB是一个m×p矩阵，它的一个元素其中 1 ≤ i ≤ m, 1 ≤ j ≤ p。 值得一提的是，矩阵乘法满足结合律和分配率，但并不满足交换律，如下图所示的这个例子，两个矩阵交换相乘后，结果变了： 下面咱们来具体解决这个矩阵相乘的问题。 解法一 暴力解法其实，通过前面的分析，我们已经很明显的看出，两个具有相同维数的矩阵相乘，其复杂度为O(n^3)，参考代码如下： 123456789101112131415//矩阵乘法，3个for循环搞定 void MulMatrix(int** matrixA, int** matrixB, int** matrixC) &#123; for(int i = 0; i &lt; 2; ++i) &#123; for(int j = 0; j &lt; 2; ++j) &#123; matrixC[i][j] = 0; for(int k = 0; k &lt; 2; ++k) &#123; matrixC[i][j] += matrixA[i][k] * matrixB[k][j]; &#125; &#125; &#125; &#125; 解法二 Strassen 算法。。。 完美洗牌算法题目详情有个长度为2n的数组{a1,a2,a3,…,an,b1,b2,b3,…,bn}，希望排序后{a1,b1,a2,b2,….,an,bn}，请考虑有无时间复杂度O(n)，空间复杂度O(1)的解法。 题目来源：此题是去年2013年UC的校招笔试题，看似简单，按照题目所要排序后的字符串蛮力变化即可，但若要完美的达到题目所要求的时空复杂度，则需要我们花费不小的精力。OK，请看下文详解，一步步优化。 有时间看 。。 第三章 树本章导读想要更好地理解红黑树，可以先理解二叉查找树和2-3树。为何呢？首先，二叉查找树中的结点是2-结点（一个键两条链），引入3-结点（两个键三条链），即成2-3树；然后将2-3树中3-结点分解，即成红黑树，故结合二叉查找树易查找和2-3树易插入的特点，便成了红黑二叉查找树，简称红黑树。 进一步而言，理解了2-3树，也就理解了B树、B+树、B*树，因为2-3树就是一棵3阶的B树，而一颗3阶的B树各个结点关键字数满足1-2，故当结点关键字数多于2时则达到饱和，此时需要分裂结点，而结点关键字数少于1时则从兄弟结点“借”关键字补充。 但为何有了红黑树，还要发明B树呢？原因是，当计算机要处理的数据量一大，便无法一次性装入内存进行处理，于此，计算机会把大部分备用的数据存在磁盘中，有需要的时候，就从磁盘中调取数据到在内存中处理，如果处理时修改了数据，则再次将数据写入磁盘，如此导致了不断的磁盘IO读写，而树的高度越高，查找文件所需要的磁盘IO读写次数越多，所以为了减少磁盘的IO读写，要想办法进一步降低树的高度。 因此，具有多个孩子的B树便应运而生，因为B树每一个结点可以有几个到几千个孩子，使得在结点数目一定的情况下，树的高度会大大降低，从而有效减少磁盘IO读写消耗。 此外，无论是B树，还是B+树、B\*树，由于根或者树的上面几层被反复查询，所以树上层几块的数据可以存在内存中。换言之，B树、B+树、B\*树的根结点和部分顶层数据存在内存中，大部分下层数据存在磁盘上。 红黑树二叉查找树（Binary Search Tree），也称有序二叉树（ordered binary tree）,排序二叉树（sorted binary tree），是指一棵空树或者具有下列性质的二叉树： 若任意结点的左子树不空，则左子树上所有结点的值均小于它的根结点的值； 若任意结点的右子树不空，则右子树上所有结点的值均大于它的根结点的值； 任意结点的左、右子树也分别为二叉查找树。 没有键值相等的结点（no duplicate nodes）。 红黑树本质上来说就是一棵二叉查找树，但它在二叉查找树的基础上增加了着色和相关的性质使得红黑树相对平衡，从而保证了红黑树的查找、插入、删除的时间复杂度最坏为O(log n)。 但它是如何保证一棵n个结点的红黑树的高度始终保持在h = logn的呢？这就引出了红黑树的5条性质： 123451）每个结点要么是红的，要么是黑的。 2）根结点是黑的。 3）每个叶结点（叶结点即指树尾端NIL指针或NULL结点）是黑的。 4）如果一个结点是红的，那么它的俩个儿子都是黑的。 5）对于任一结点而言，其到叶结点树尾端NIL指针的每一条路径都包含相同数目的黑结点。 正是红黑树的这5条性质，使得一棵n个结点是红黑树始终保持了logn的高度，从而也就解释了上面我们所说的“红黑树的查找、插入、删除的时间复杂度最坏为O(log n)”这一结论的原因。 省略。。。有时间看 B树二叉查找树结构由于树的深度过大而造成磁盘I/O读写过于频繁，进而导致查询效率低下，因此我们该想办法降低树的深度，从而减少磁盘查找存取的次数。一个基本的想法就是：采用多叉树结构（由于树节点元素数量是有限的，自然该节点的子树数量也就是有限的）。 平衡多路查找树，即B-tree（B-tree树即B树*，B即Balanced，平衡的意思） 后面我们会看到，B树的各种操作能使B树保持较低的高度，从而有效避免磁盘过于频繁的查找存取操作，达到有效提高查找效率的目的。然在开始介绍Btree之前，先了解下相关的硬件知识，才能很好的了解为什么需要Btree这种外存数据结构。 许多数据库系统都一般使用B树或者B树的各种变形结构 B树与红黑树最大的不同在于，B树的结点可以有许多子女，从几个到几千个。不过B树与红黑树一样，一棵含n个结点的B树的高度也为O(lgn)，但可能比一棵红黑树的高度小许多，因为它的分支因子比较大。所以，B树可以在O（logn）时间内，实现各种如插入（insert），删除（delete）等动态集合操作。 。。。详看以前，之前学习过 最近公共祖先LCA问题问题描述求有根树的任意两个结点的最近公共祖先 解答这个问题之前，咱们得先搞清楚到底什么是最近公共祖先。最近公共祖先简称LCA（Lowest Common Ancestor），所谓LCA，是当给定一个有根树T时，对于任意两个结点u、v，找到一个离根最远的结点x，使得x同时是u和v的祖先，x 便是u、v的最近公共祖先。（参见：http://en.wikipedia.org/wiki/Lowest_common_ancestor ）原问题涵盖一般性的有根树，本文为了简化，多使用二叉树来讨论。 是不是二叉查找树 解法一 暴力对待 是二叉查找树 那么从树根开始： 如果当前结点t 大于结点u、v，说明u、v都在t 的左侧，所以它们的共同祖先必定在t 的左子树中，故从t 的左子树中继续查找； 如果当前结点t 小于结点u、v，说明u、v都在t 的右侧，所以它们的共同祖先必定在t 的右子树中，故从t 的右子树中继续查找； 如果当前结点t 满足 u &lt;t &lt; v，说明u和v分居在t 的两侧，故当前结点t 即为最近公共祖先； 而如果u是v的祖先，那么返回u的父结点，同理，如果v是u的祖先，那么返回v的父结点。 代码如下所示： 1234567891011121314151617181920212223242526//copyright@eriol 2011 //modified by July 2014 public int query(Node t, Node u, Node v) &#123; int left = u.value; int right = v.value; //二叉查找树内，如果左结点大于右结点，不对，交换 if (left &gt; right) &#123; int temp = left; left = right; right = temp; &#125; while (true) &#123; //如果t小于u、v，往t的右子树中查找 if (t.value &lt; left) &#123; t = t.right; //如果t大于u、v，往t的左子树中查找 &#125; else if (t.value &gt; right) &#123; t = t.left; &#125; else &#123; return t.value; &#125; &#125; &#125; 不是二叉查找树 但如果这棵树不是二叉查找树，只是一棵普通的二叉树呢？如果每个结点都有一个指针指向它的父结点，于是我们可以从任何一个结点出发，得到一个到达树根结点的单向链表。因此这个问题转换为两个单向链表的第一个公共结点。 此外，如果给出根节点，LCA问题可以用递归很快解决。而关于树的问题一般都可以转换为递归（因为树本来就是递归描述），参考代码如下： 1234567891011121314151617181920//copyright@allantop 2014-1-22-20:01 node* getLCA(node* root, node* node1, node* node2) &#123; if(root == null) return null; if(root== node1 || root==node2) return root; node* left = getLCA(root-&gt;left, node1, node2); node* right = getLCA(root-&gt;right, node1, node2); if(left != null &amp;&amp; right != null) return root; else if(left != null) return left; else if (right != null) return right; else return null; &#125; 然不论是针对普通的二叉树，还是针对二叉查找树，上面的解法有一个很大的弊端就是：如需N 次查询，则总体复杂度会扩大N 倍，故这种暴力解法仅适合一次查询，不适合多次查询。 接下来的解法，将不再区别对待是否为二叉查找树，而是一致当做是一棵普通的二叉树。总体来说，由于可以把LCA问题看成是询问式的，即给出一系列询问，程序对每一个询问尽快做出反应。故处理这类问题一般有两种解决方法： 一种是在线算法，相当于循序渐进处理； 另外一种则是离线算法，如Tarjan算法，相当于一次性批量处理，一开始就知道了全部查询，只待询问。 解法二：Tarjan算法如上文末节所述，不论咱们所面对的二叉树是二叉查找树，或不是二叉查找树，都可以把求任意两个结点的最近公共祖先，当做是查询的问题，如果是只求一次，则是单次查询；如果要求多个任意两个结点的最近公共祖先，则相当于是批量查询。 涉及到批量查询的时候，咱们可以借鉴离线处理的方式，这就引出了解决此LCA问题的Tarjan离线算法。 2.1、什么是Tarjan算法Tarjan算法 （以发现者Robert Tarjan命名）是一个在图中寻找强连通分量的算法。算法的基本思想为：任选一结点开始进行深度优先搜索dfs（若深度优先搜索结束后仍有未访问的结点，则再从中任选一点再次进行）。搜索过程中已访问的结点不再访问。搜索树的若干子树构成了图的强连通分量。 应用到咱们要解决的LCA问题上，则是：对于新搜索到的一个结点u，先创建由u构成的集合，再对u的每颗子树进行搜索，每搜索完一棵子树，这时候子树中所有的结点的最近公共祖先就是u了。 举一个例子，如下图（不同颜色的结点相当于不同的集合）： 假设遍历完10的孩子,要处理关于10的请求了，取根节点到当前正在遍历的节点的路径为关键路径,即1-3-8-10，集合的祖先便是关键路径上距离集合最近的点。 比如： 1，2，5，6为一个集合,祖先为1，集合中点和10的LCA为1 3，7为一个集合，祖先为3，集合中点和10的LCA为3 8，9，11为一个集合，祖先为8，集合中点和10的LCA为8 10，12为一个集合，祖先为10，集合中点和10的LCA为10 得出的结论便是：LCA(u,v)便是根至u的路径上到节点v最近的点。 2.2、Tarjan算法如何而来但关键是 Tarjan算法是怎么想出来的呢？再给定下图，你是否能看出来：分别从结点1的左右子树当中，任取一个结点，设为u、v，这两个任意结点u、v的最近公共祖先都为1。 于此，我们可以得知：若两个结点u、v分别分布于某节点t 的左右子树，那么此节点 t即为u和v的最近公共祖先。更进一步，考虑到一个节点自己就是LCA的情况，得知： 若某结点t 是两结点u、v的祖先之一，且这两结点并不分布于该结点t 的一棵子树中，而是分别在结点t 的左子树、右子树中，那么该结点t 即为两结点u、v的最近公共祖先。 这个定理就是Tarjan算法的基础。 一如上文1.1节我们得到的结论：“如果当前结点t 满足 u &lt;t &lt; v，说明u和v分居在t 的两侧，故当前结点t 即为最近公共祖先”。 而对于本节开头我们所说的“如果要求多个任意两个结点的最近公共祖先，则相当于是批量查询”，即在很多组的询问的情况下，或许可以先确定一个LCA。例如是根节点1，然后再去检查所有询问，看是否满足刚才的定理，不满足就忽视，满足就赋值，全部弄完，再去假设2号节点是LCA，再去访问一遍。 可此方法需要判断一个结点是在左子树、还是右子树，或是都不在，都只能遍历一棵树，而多次遍历的代价实在是太大了，所以我们需要找到更好的方法。这就引出了下面要阐述的Tarjan算法，即每个结点只遍历一次，怎么做到的呢，请看下文讲解。 2.3、Tarjan算法流程Tarjan算法流程为： 123456789Procedure dfs（u）； begin 设置u号节点的祖先为u 若u的左子树不为空，dfs（u - 左子树）； 若u的右子树不为空，dfs（u - 右子树）； 访问每一条与u相关的询问u、v -若v已经被访问过，则输出v当前的祖先t（t即u,v的LCA） 标记u为已经访问，将所有u的孩子包括u本身的祖先改为u的父亲 end 普通的dfs 不能直接解决LCA问题，故Tarjan算法的原理是dfs + 并查集，它每次把两个结点对的最近公共祖先的查询保存起来，然后dfs 更新一次。如此，利用并查集优越的时空复杂度，此算法的时间复杂度可以缩小至O(n＋Q)，其中，n为数据规模，Q为询问个数。 看完图的部分再回来看 第四章 查找匹配有序数组的查找题目描述给定一个有序的数组，查找某个数是否在数组中，请编程实现 使用二分查找O(lgn) 以下是一份参考实现： 123456789101112131415161718192021222324252627int BinarySearch(int array[], int n, int value)&#123; int left = 0; int right = n - 1; //如果这里是int right = n 的话，那么下面有两处地方需要修改，以保证一一对应： //1、下面循环的条件则是while(left &lt; right) //2、循环内当 array[middle] &gt; value 的时候，right = mid while (left &lt;= right) //循环条件，适时而变 &#123; int middle = left + ((right - left) &gt;&gt; 1); //防止溢出，移位也更高效。同时，每次循环都需要更新。 if (array[middle] &gt; value) &#123; right = middle - 1; //right赋值，适时而变 &#125; else if(array[middle] &lt; value) &#123; left = middle + 1; &#125; else return middle; //可能会有读者认为刚开始时就要判断相等，但毕竟数组中不相等的情况更多 //如果每次循环都判断一下是否相等，将耗费时间 &#125; return -1;&#125; 行列递增矩阵的查找题目描述在一个m行n列二维数组中，每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。 例如下面的二维数组就是每行、每列都递增排序。如果在这个数组中查找数字6，则返回true；如果查找数字5，由于数组不含有该数字，则返回false。 定位法：详见 剑指 offer 举一反三1、给定 n×n 的实数矩阵，每行和每列都是递增的，求这 n^2 个数的中位数。 2、我们已经知道杨氏矩阵的每行的元素从左到右单调递增，每列的元素从上到下也单调递增的矩阵。那么，如果给定从1-n这n个数，我们可以构成多少个杨氏矩阵呢？ 例如n = 4的时候，我们可以构成1行4列的矩阵： 1 2 3 4 2个2行2列的矩阵: 1 2 3 4 和 1 3 2 4 还有一个4行1列的矩阵 1 2 3 4 因此输出4。 出现次数超过一半的数字题目描述数组中有一个数组的次数超过了数组长度的一半，找出这个数字 解法一哈希表 空间换时间 解法二Hash表需要O(n)的空间开销，且要设计hash函数，还有没有更好的办法呢？我们可以试着这么考虑，如果每次删除两个不同的数（不管是不是我们要查找的那个出现次数超过一半的数字），那么，在剩下的数中，我们要查找的数（出现次数超过一半）出现的次数仍然超过总数的一半。通过不断重复这个过程，不断排除掉其它的数，最终找到那个出现次数超过一半的数字。这个方法，免去了排序，也避免了空间O(n)的开销，总得说来，时间复杂度只有O(n)，空间复杂度为O(1)，貌似不失为最佳方法。 举个简单的例子，如数组a[5] = {0, 1, 2, 1, 1}; 很显然，若我们要找出数组a中出现次数超过一半的数字，这个数字便是1，若根据上述思路4所述的方法来查找，我们应该怎么做呢？通过一次性遍历整个数组，然后每次删除不相同的两个数字，过程如下简单表示： 10 1 2 1 1 =&gt;2 1 1=&gt;1 最终1即为所找。 此外，对于序列{5, 5, 5, 5, 1}，每次分别从数组两端尝试各删除一个数(左边删除5, 右边删除1，两个数不相同)，之后剩余{5, 5, 5}，这时无法找到两个不同的数进行删除，说明剩余元素全部相同，返回5作为结果即可 解法四更进一步，考虑到这个问题本身的特殊性，我们可以在遍历数组的时候保存两个值：一个candidate，用来保存数组中遍历到的某个数字；一个nTimes，表示当前数字的出现次数，其中，nTimes初始化为1。当我们遍历到数组中下一个数字的时候： 如果下一个数字与之前candidate保存的数字相同，则nTimes加1； 如果下一个数字与之前candidate保存的数字不同，则nTimes减1； 每当出现次数nTimes变为0后，用candidate保存下一个数字，并把nTimes重新设为1。 直到遍历完数组中的所有数字为止。 举个例子，假定数组为{0, 1, 2, 1, 1}，按照上述思路执行的步骤如下： 1.开始时，candidate保存数字0，nTimes初始化为1； 2.然后遍历到数字1，与数字0不同，则nTimes减1变为0； 3.因为nTimes变为了0，故candidate保存下一个遍历到的数字2，且nTimes被重新设为1； 4.继续遍历到第4个数字1，与之前candidate保存的数字2不同，故nTimes减1变为0； 5.因nTimes再次被变为了0，故我们让candidate保存下一个遍历到的数字1，且nTimes被重新设为1。最后返回的就是最后一次把nTimes设为1的数字1。 思路清楚了，完整的代码如下： 12345678910111213141516171819202122//a代表数组，length代表数组长度int FindOneNumber(int* a, int length)&#123; int candidate = a[0]; int nTimes = 1; for (int i = 1; i &lt; length; i++) &#123; if (nTimes == 0) &#123; candidate = a[i]; nTimes = 1; &#125; else &#123; if (candidate == a[i]) nTimes++; else nTimes--; &#125; &#125; return candidate;&#125; 即针对数组{0, 1, 2, 1, 1}，套用上述程序可得： 123456i=0，candidate=0，nTimes=1；i=1，a[1] != candidate，nTimes--，=0；i=2，candidate=2，nTimes=1；i=3，a[3] != candidate，nTimes--，=0；i=4，candidate=1，nTimes=1；如果是0，1，2，1，1，1的话，那么i=5，a[5] == candidate，nTimes++，=2；...... 举一反三加强版水王：找出出现次数刚好是一半的数字 分析：我们知道，水王问题：有N个数，其中有一个数出现超过一半，要求在线性时间求出这个数。那么，我的问题是，加强版水王：有N个数，其中有一个数刚好出现一半次数，要求在线性时间内求出这个数。 因为，很明显，如果是刚好出现一半的话，如此例： 0，1，2，1 ： 1234遍历到0时，candidate为0，times为1遍历到1时，与candidate不同，times减为0遍历到2时，times为0，则candidate更新为2，times加1遍历到1时，与candidate不同，则times减为0；我们需要返回所保存candidate（数字2）的下一个数字，即数字1。 分治 dp 贪心 回溯 分支界定 常用算法思想： 分治 动态规划 贪心 回溯 分支界定 分治 设计思想：将一个难以直接解决的大问题，分割成一些规模较小的相同问题，以便各个击破，分而治之 问题的规模越小，越容易直接求解，解题所需的计算时间也越少 分治策略是：对于一个规模为n的问题，若该问题可以容易地解决（比如说规模n较小）则直接解决，否则将其分解为k个规模较小的子问题，这些子问题互相独立且与原问题形式相同，递归地解这些子问题，然后将各子问题的解合并得到原问题的解。这种算法设计策略叫做分治法。 三、分治法适用的情况 分治法所能解决的问题一般具有以下几个特征： 1) 该问题的规模缩小到一定的程度就可以容易地解决 2) 该问题可以分解为若干个规模较小的相同问题，即该问题具有最优子结构性质。 3) 利用该问题分解出的子问题的解可以合并为该问题的解； 4) 该问题所分解出的各个子问题是相互独立的，即子问题之间不包含公共的子子问题。第一条特征是绝大多数问题都可以满足的，因为问题的计算复杂性一般是随着问题规模的增加而增加； 第二条特征是应用分治法的前提它也是大多数问题可以满足的，此特征反映了递归思想的应用；、 第三条特征是关键，能否利用分治法完全取决于问题是否具有第三条特征，如果具备了第一条和第二条特征，而不具备第三条特征，则可以考虑用贪心法或动态规划法。 第四条特征涉及到分治法的效率，如果各子问题是不独立的则分治法要做许多不必要的工作，重复地解公共的子问题，此时虽然可用分治法，但一般用动态规划法较好。四、分治法的基本步骤 分治法在每一层递归上都有三个步骤： step1 分解：将原问题分解为若干个规模较小，相互独立，与原问题形式相同的子问题； step2 解决：若子问题规模较小而容易被解决则直接解，否则递归地解各个子问题 step3 合并：将各个子问题的解合并为原问题的解。它的一般的算法设计模式如下： Divide-and-Conquer(P) 1. if |P|≤n0 2. then return(ADHOC(P)) 3. 将P分解为较小的子问题 P1 ,P2 ,...,Pk 4. for i←1 to k 5. do yi ← Divide-and-Conquer(Pi) △ 递归解决Pi 6. T ← MERGE(y1,y2,...,yk) △ 合并子问题 7. return(T) 其中|P|表示问题P的规模；n0为一阈值，表示当问题P的规模不超过n0时，问题已容易直接解出，不必再继续分解。ADHOC(P)是该分治法中的基本子算法，用于直接解小规模的问题P。因此，当P的规模不超过n0时直接用算法ADHOC(P)求解。算法MERGE(y1,y2,...,yk)是该分治法中的合并子算法，用于将P的子问题P1 ,P2 ,...,Pk的相应的解y1,y2,...,yk合并为P的解。五、分治法的复杂性分析 一个分治法将规模为n的问题分成k个规模为n／m的子问题去解。设分解阀值n0=1，且adhoc解规模为1的问题耗费1个单位时间。再设将原问题分解为k个子问题以及用merge将k个子问题的解合并为原问题的解需用f(n)个单位时间。用T(n)表示该分治法解规模为|P|=n的问题所需的计算时间，则有： T（n）= k T(n/m)+f(n) 通过迭代法求得方程的解： 递归方程及其解只给出n等于m的方幂时T(n)的值，但是如果认为T(n)足够平滑，那么由n等于m的方幂时T(n)的值可以估计T(n)的增长速度。通常假定T(n)是单调上升的，从而当mi≤n&lt;mi+1时，T(mi)≤T(n)&lt;T(mi+1)。 六、可使用分治法求解的一些经典问题 （1）二分搜索 （2）大整数乘法 （3）Strassen矩阵乘法 （4）棋盘覆盖 （5）合并排序 （6）快速排序 （7）线性时间选择 （8）最接近点对问题 （9）循环赛日程表 （10）汉诺塔七、依据分治法设计程序时的思维过程实际上就是类似于数学归纳法，找到解决本问题的求解方程公式，然后根据方程公式设计递归程序。1、一定是先找到最小问题规模时的求解方法2、然后考虑随着问题规模增大时的求解方法3、找到求解的递归函数式后（各种规模或因子），设计递归程序即可。 动态规划算法 一 . 基本概念 ​ 动态规划的过程：每次决策依赖于当前状态，又随即引起状态的转移。一个决策序列就是在变化的状态中产生出来的，所以这种多阶段最优化决策解决问题的过程就称为动态规划 二. 基本思想和策略 基本思想与分治法类似，也是将待求解的问题分解为若干个子问题（阶段），按顺序求解子阶段，前一子问题的解，为后一子问题的求解提供了有用的信息。在求解任一子问题时，列出各种可能的局部解，通过决策保留那些有可能达到最优的局部解，丢弃其他局部解。依次解决各子问题，最后一个子问题就是初始问题的解。 由于动态规划解决的问题多数有重叠子问题这个特点，为减少重复计算，对每一个子问题只解一次，将其不同阶段的不同状态保存在一个二维数组中。 **与分治法最大的差别是：适合于用动态规划法求解的问题，经分解后得到的子问题往往不是互相独立的**（即下一个子阶段的求解是建立在上一个子阶段的解的基础上，进行进一步的求解）。三. 适用的情况 一般要具有以下三个性质： 最优化原理 如果问题的最优解所包含的子问题的解也是最优的，就称该问题具有最优子结构，即满足最优化原理。 无后效性 即某阶段状态一旦确定，就不受这个状态以后决策的影响。也就是说，某状态以后的过程不会影响以前的状态，只与当前状态有关 有重叠子问题 即子问题之间是不独立的，一个子问题在下一阶段决策中可能被多次使用到。（该性质并不是动态规划适用的必要条件，但是如果没有这条性质，动态规划算法同其他算法相比就不具备优势） 四. 求解的基本步骤 动态规划所处理的问题是一个多阶段决策问题，一般由初始状态开始，通过对中间阶段决策的选择，达到结束状态。这些决策形成了一个决策序列，同时确定了完成整个过程的一条活动路线(通常是求最优的活动路线)。如图所示。动态规划的设计都有着一定的模式，一般要经历以下几个步骤。 初始状态→│决策１│→│决策２│→…→│决策ｎ│→结束状态 图1 动态规划决策过程示意图 (1)划分阶段：按照问题的时间或空间特征，把问题分为若干个阶段。在划分阶段时，注意划分后的阶段一定要是有序的或者是可排序的，否则问题就无法求解。(2)确定状态和状态变量：将问题发展到各个阶段时所处于的各种客观情况用不同的状态表示出来。当然，状态的选择要满足无后效性。(3)确定决策并写出状态转移方程：因为决策和状态转移有着天然的联系，状态转移就是根据上一阶段的状态和决策来导出本阶段的状态。所以如果确定了决策，状态转移方程也就可写出。但事实上常常是反过来做，根据相邻两个阶段的状态之间的关系来确定决策方法和状态转移方程。(4)寻找边界条件：给出的状态转移方程是一个递推式，需要一个递推的终止条件或边界条件。一般，只要解决问题的阶段、状态和状态转移决策确定了，就可以写出状态转移方程（包括边界条件）。 实际应用中可以按以下几个简化的步骤进行设计： （1）分析最优解的性质，并刻画其结构特征。（2）递归的定义最优解。（3）以自底向上或自顶向下的记忆化方式（备忘录法）计算出最优值（4）根据计算最优值时得到的信息，构造问题的最优解 五.算法实现的说明 动态规划的主要难点在于理论上的设计，也就是上面4个步骤的确定，一旦设计完成，实现部分就会非常简单。 使用动态规划求解问题，最重要的就是确定动态规划三要素： （1）问题的阶段 （2）每个阶段的状态 （3）从前一个阶段转化到后一个阶段之间的递推关系。 递推关系必须是从次小的问题开始到较大的问题之间的转化(也就是要注意递推的方向)，从这个角度来说，动态规划往往可以用递归程序来实现，不过因为递推可以充分利用前面保存子问题的解来减少重复计算，所以对于大规模问题来说，有递归不可比拟的优势，这也是动态规划算法的核心之处。 确定了动态规划的这三要素，整个求解过程就可以用一个最优决策表来描述，最优决策表是一个二维表，其中行表示决策的阶段，列表示问题状态，表格需要填写的数据一般对应此问题的在某个阶段某个状态下的最优值（如最短路径，最长公共子序列，最大价值等），填表的过程就是根据递推关系，从1行1列开始，以行或者列优先的顺序，依次填写表格，最后根据整个表格的数据通过简单的取舍或者运算求得问题的最优解。 f(n,m)=max{f(n-1,m), f(n-1,m-w[n])+P(n,m)} 贪心算法 一.基本概念 所谓贪心算法是指，在对问题求解时，总是做出在当前看来是最好的选择。也就是说，不从整体最优上加以考虑，他所做出的仅是在某种意义上的局部最优解。 贪心算法没有固定的算法框架，算法设计的**关键是贪心策略的选择**。必须注意的是，贪心算法不是对所有问题都能得到整体最优解，**选择的贪心策略必须具备无后效性，即某个状态以后的过程不会影响以前的状态，只与当前状态有关。**所以对所采用的贪心策略一定要仔细分析其是否满足无后效性。二、贪心算法的基本思路： 1.建立数学模型来描述问题。 2.把求解的问题**&lt;font color=blue&gt;分解&lt;/font&gt;**成若干个子问题。 3.对每一子问题求解，得到**&lt;font color=blue&gt;子问题的局部最优解&lt;/font&gt;**。 4.把子问题的解局部最优解**&lt;font color=blue&gt;合成&lt;/font&gt;**原来解问题的一个解。三、贪心算法适用的问题 贪心策略适用的**前提是：局部最优策略能导致产生全局最优解。** **实际上，贪心算法适用的情况很少**。一般，对一个问题分析是否适用于贪心算法，可以先选择该问题下的几个实际数据进行分析，就可做出判断。四、贪心算法的实现框架 从问题的某一初始解出发； while （能朝给定总目标前进一步） { 利用可行的决策，求出可行解的一个解元素； } 由所有解元素组合成问题的一个可行解；五、贪心策略的选择 因为用贪心算法只能通过解局部最优解的策略来达到全局最优解，因此，一定要注意判断问题是否适合采用贪心算法策略，找到的解是否一定是问题的最优解。六、例题分析 下面是一个可以试用贪心算法解的题目，贪心解的确不错，可惜不是最优解。 [背包问题]有一个背包，背包容量是M=150。有7个物品，物品可以分割成任意大小。 要求尽可能让装入背包中的物品总价值最大，但不能超过总容量。 物品 A B C D E F G 重量 35 30 60 50 40 10 25 价值 10 40 30 50 35 40 30 分析： 目标函数： ∑pi最大 约束条件是装入的物品总重量不超过背包容量：∑wi&lt;=M( M=150) （1）根据贪心的策略，每次挑选价值最大的物品装入背包，得到的结果是否最优？ （2）每次挑选所占重量最小的物品装入是否能得到最优解？ （3）每次选取单位重量价值最大的物品，成为解本题的策略。 值得注意的是，贪心算法并不是完全不可以使用，贪心策略一旦经过证明成立后，它就是一种高效的算法。 贪心算法还是很常见的算法之一，这是由于它简单易行，构造贪心策略不是很困难。 可惜的是，它需要证明后才能真正运用到题目的算法中。 一般来说，贪心算法的证明围绕着：整个问题的最优解一定由在贪心策略中存在的子问题的最优解得来的。 对于例题中的3种贪心策略，都是无法成立（无法被证明）的，解释如下： （1）贪心策略：选取价值最大者。反例： W=30 物品：A B C 重量：28 12 12 价值：30 20 20 根据策略，首先选取物品A，接下来就无法再选取了，可是，选取B、C则更好。 （2）贪心策略：选取重量最小。它的反例与第一种策略的反例差不多。 （3）贪心策略：选取单位重量价值最大的物品。反例： W=30 物品：A B C 重量：28 20 10 价值：28 20 10 根据策略，三种物品单位重量价值一样，程序无法依据现有策略作出判断，如果选择A，则答案错误 回溯法 概念 回溯算法实际上一个类似枚举的搜索尝试过程，主要是在搜索尝试过程中寻找问题的解，当发现已不满足求解条件时，就“回溯”返回，尝试别的路径。 回溯法是一种选优搜索法，按选优条件向前搜索，以达到目标。但当探索到某一步时，发现原先选择并不优或达不到目标，就退回一步重新选择，这种走不通就退回再走的技术为回溯法，而满足回溯条件的某个状态的点称为“回溯点”。许多复杂的，规模较大的问题都可以使用回溯法，有“通用解题方法”的美称。 基本思想 在包含问题的所有解的解空间树中，按照深度优先搜索的策略，从根结点出发深度探索解空间树。当探索到某一结点时，要先判断该结点是否包含问题的解，如果包含，就从该结点出发继续探索下去，如果该结点不包含问题的解，则逐层向其祖先结点回溯。（其实回溯法就是对隐式图的深度优先搜索算法）。 若用回溯法求问题的所有解时，要回溯到根，且根结点的所有可行的子树都要已被搜索遍才结束。 而若使用回溯法求任一个解时，只要搜索到问题的一个解就可以结束。 用回溯法解题的一般步骤 （1）针对所给问题，确定问题的解空间： ​ 首先应明确定义问题的解空间，问题的解空间应至少包含问题的一个（最 优）解。（2）确定结点的扩展搜索规则 （3）以深度优先方式搜索解空间，并在搜索过程中用剪枝函数避免无效搜索。 分支限界法 一. 基本描述类似于回溯法，也是一种在问题的解空间树T上搜索问题解的算法。但在一般情况下，分支限界法与回溯法的求解目标不同。回溯法的求解目标是找出T中满足约束条件的所有解，而分支限界法的求解目标则是找出满足约束条件的一个解，或是在满足约束条件的解中找出使某一目标函数值达到极大或极小的解，即在某种意义下的最优解。 所谓“分支”就是采用广度优先的策略(回溯是深度优先)，依次搜索E-结点的所有分支，也就是所有相邻结点，抛弃不满足约束条件的结点，其余结点加入活结点表。然后从表中选择一个结点作为下一个E-结点，继续搜索。 选择下一个E-结点的方式不同，则会有几种不同的分支搜索方式。 FIFO搜索 LIFO搜索 优先队列搜索 分支限界搜索算法 二、分支限界法的一般过程由于求解目标不同，导致分支限界法与回溯法在解空间树T上的搜索方式也不相同。回溯法以深度优先的方式搜索解空间树T，而分支限界法则以广度优先或以最小耗费优先的方式搜索解空间树T。 分支限界法的搜索策略是：在扩展结点处，先生成其所有的儿子结点（分支），然后再从当前的活结点表中选择下一个扩展对点。为了有效地选择下一扩展结点，以加速搜索的进程，在每一活结点处，计算一个函数值（限界），并根据这些已计算出的函数值，从当前活结点表中选择一个最有利的结点作为扩展结点，使搜索朝着解空间树上有最优解的分支推进，以便尽快地找出一个最优解。 分支限界法常以广度优先或以最小耗费（最大效益）优先的方式搜索问题的解空间树。问题的解空间树是表示问题解空间的一棵有序树，常见的有子集树和排列树。在搜索问题的解空间树时，分支限界法与回溯法对当前扩展结点所使用的扩展方式不同。在分支限界法中，每一个活结点只有一次机会成为扩展结点。活结点一旦成为扩展结点，就一次性产生其所有儿子结点。在这些儿子结点中，那些导致不可行解或导致非最优解的儿子结点被舍弃，其余儿子结点被子加入活结点表中。此后，从活结点表中取下一结点成为当前扩展结点，并重复上述结点扩展过程。这个过程一直持续到找到所求的解或活结点表为空时为止。 三、回溯法和分支限界法的一些区别有一些问题其实无论用回溯法还是分支限界法都可以得到很好的解决，但是另外一些则不然。也许我们需要具体一些的分析——到底何时使用分支限界而何时使用回溯呢？ 回溯法和分支限界法的一些区别： 方法对解空间树的搜索方式 存储结点的常用数据结构 结点存储特性常用应用 回溯法深度优先搜索堆栈活结点的所有可行子结点被遍历后才被从栈中弹出找出满足约束条件的所有解 分支限界法广度优先或最小消耗优先搜索队列、优先队列每个结点只有一次成为活结点的机会找出满足约束条件的一个解或特定意义下的最优解]]></content>
      <categories>
        <category>201909</category>
      </categories>
      <tags>
        <tag>Note</tag>
        <tag>Interview</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[查缺补漏_Start_2019Fall]]></title>
    <url>%2F2019%2F09%2F29%2F%E6%9F%A5%E7%BC%BA%E8%A1%A5%E6%BC%8F_Start_2019Fall%2F</url>
    <content type="text"><![CDATA[查缺补漏 模板特化 定位内存泄漏 valgrind memcheck 对应一个表 桶排序 排序算法稳定性 稳定：基数排序 冒泡排序 插入排序 归并排序 不稳定：堆排序 快速排序 希尔排序 选择排序 排序算法首推 快排 归并 冒泡排序思想：通过与相邻元素比较和交换把最小的数交换到最前面，这个过程类似于水泡向上升一样，因此而得名。 步骤： 从后往前冒泡，找到最小的那个数并拍到（当前要排序列的）最前面，直到要排的序列为空，说明所有排序完成 代码（自己写的）： 123456789101112131415161718192021222324252627282930313233#include&lt;iostream&gt;#include&lt;vector&gt;using namespace std;void swap(int&amp;a , int&amp;b)&#123; int tmp = a; a = b; b = tmp; return;&#125;void Bubble(vector&lt;int&gt;&amp; numbers, int&amp; N)&#123; for(int i = 0;i&lt;N;i++)&#123; for(int j = N-1;j&gt;i;j--)&#123; if(numbers[j]&lt;numbers[j-1]) swap(numbers[j],numbers[j-1]); &#125; &#125;&#125;int main(void)&#123; int N = 0; cin &gt;&gt; N; vector&lt;int&gt; numbers(N); for(int i = 0;i&lt;N;i++) scanf("%d",&amp;(numbers[i])); Bubble(numbers,N); for(int i = 0;i&lt;N;i++) cout &lt;&lt; numbers[i] &lt;&lt; ' ' ; return 0;&#125; 时间复杂度：O(n^2)，——稳定 选择排序思想：有点和冒泡排序类似，都是在一次排序后把最小的元素放在最前面， 其实是对冒泡排序的优化，我们中间不需要交换那么多次，只需要找到要排序序列的最小值，然后把该值与要放到的位置交换即可，每次排序只交换一次，所以总共交换n-1次 为什么叫选择呢，可能是选择了最小的来交换的意思 代码（自己写的） 123456789101112131415161718192021222324252627282930313233343536#include&lt;iostream&gt;#include&lt;vector&gt;using namespace std;void swap(int&amp;a , int&amp;b)&#123; int tmp = a; a = b; b = tmp; return;&#125;void Select_sort(vector&lt;int&gt;&amp; numbers, int&amp; N)&#123; for(int i = 0;i &lt; N;i++)&#123; int minIndex = i; for(int j = N-1; j&gt;i;j--)&#123; if(numbers[j]&lt;numbers[minIndex]) minIndex = j; &#125; if(minIndex!=i) swap(numbers[minIndex],numbers[i]); &#125;&#125;int main(void)&#123; int N = 0; cin &gt;&gt; N; vector&lt;int&gt; numbers(N); for(int i = 0;i&lt;N;i++) scanf("%d",&amp;(numbers[i])); Select_sort(numbers,N); for(int i = 0;i&lt;N;i++) cout &lt;&lt; numbers[i] &lt;&lt; ' ' ; return 0;&#125; 时间复杂度——O(n^2) 用数组实现的选择排序是不稳定的，用链表实现的选择排序是稳定的。 不过，一般提到排序算法时，大家往往会默认是数组实现，所以选择排序是不稳定的 插入排序思想：不是通过交换位置，而是通过找到合适的位置插入元素，来达到排序的目的，参考扑克牌 步骤：第一个不用排序（类比第一张牌），从第二张牌开始插入（注意，我们插入的肯定是排好了的有序序列，程序执行步骤确定，参考摸牌） 保存当前值，因为要移位可能被占用，然后插入最终符合条件的空位，完成一次插入。 关键看好边界条件——因为会有覆盖操作 代码（自己写的） 1234567891011121314151617181920212223242526272829#include&lt;iostream&gt;#include&lt;vector&gt;using namespace std;void Insert_sort(vector&lt;int&gt;&amp; numbers, int&amp; N)&#123; for(int i = 1; i &lt; N; i++)&#123; int target = numbers[i]; int j = i-1; while(j&gt;=0 &amp;&amp; numbers[j]&gt;target)&#123; numbers[j+1] = numbers[j]; j--; &#125; numbers[j+1] = target; &#125;&#125;int main(void)&#123; int N = 0; cin &gt;&gt; N; vector&lt;int&gt; numbers(N); for(int i = 0;i&lt;N;i++) scanf("%d",&amp;(numbers[i])); Insert_sort(numbers,N); for(int i = 0;i&lt;N;i++) cout &lt;&lt; numbers[i] &lt;&lt; ' ' ; return 0;&#125; 快速排序思想：其实是来自冒泡排序，通过比较和交换小数和大数，这样一来不仅把小数冒泡到上面同时也把大数沉到下面 冒泡+二分+递归分治 代码（自己写的） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#include&lt;iostream&gt;#include&lt;vector&gt;using namespace std;void swap(int&amp; a, int&amp;b)&#123; int tmp = a; a = b; b = tmp;&#125;int Partition(vector&lt;int&gt;&amp; numbers, int low, int up)&#123; int pivot = numbers[up]; int index = low; for(int i = low;i&lt;up;i++)&#123; if(numbers[i]&lt;pivot)&#123; if(i!=index) swap(numbers[i],numbers[index]); index++; &#125; &#125; swap(numbers[index],numbers[up]); return index;&#125;void quickSort(vector&lt;int&gt;&amp; numbers, int low, int up)&#123; if(low&lt;up)&#123; int mid = Partition(numbers,low,up); quickSort(numbers, low, mid-1); quickSort(numbers, mid+1, up); &#125;&#125;void qSort(vector&lt;int&gt;&amp; numbers)&#123; quickSort(numbers,0,numbers.size()-1);&#125;int main(void)&#123; int N = 0; cin &gt;&gt; N; vector&lt;int&gt; numbers(N); for(int i = 0;i&lt;N;i++) scanf("%d",&amp;(numbers[i])); qSort(numbers); for(int i = 0;i&lt;N;i++) cout &lt;&lt; numbers[i] &lt;&lt; ' ' ; return 0;&#125; O(nlgn) 不稳定 堆排序借助堆来实现排序，思想同简单的选择排序，从当前要排的序列里找一个最值，然后与要放到的位置交换即可 主要分两个步骤： 1.建堆 如果想升序排序就使用大顶堆/最大堆，反之使用小顶堆。原因是堆顶元素需要交换到序列尾部。 我们可以用自底向上的方法将数组A[1..n]转换成最大堆。 首先，我们知道，i/2向下取整+1到n都是叶结点（从我们之前约定好的标号对应上来看） 可以看作是具有最大堆性质的结点，所以我们只需要堆1-n/2向下取整的结点调用一次MAX-HEAPIFY，便可以完成建堆过程。 可以证明 这个过程是线性复杂度O(n) 关于堆的基本操作过程的时间复杂度为O(lgn) MAX-HEAPIFY:A[i]的左右孩子都是最大堆，使得A[i]变成一个最大堆，维护最大堆的性质，O(lgn) BUILD-MAX-HEAP：线性时间复杂度，从无序的输入数据中构造一个最大堆 HEAPSORT:O(nlgn)对一个数组进行原址排序。 MAX-HEAP-INSERT HEAP-EXTRACT-MAX HEAP-INCREASE-KEY HEAP-MAXIMUM：利用堆实现一个优先队列，O(lgn) 2.排序 最大元素总是存在A[1]中，通过与A[n]互换，调用一次MAX-HEAPIFY 并去掉结点n(heapsize-1，但是还存储在数组中），通过这样的重复操作，可以不断排序 注意：写代码时，要利用/抽象堆的操作——MAX-HEAPIFY 代码(自己写的) 注意：swap函数肯定是引用 别晕 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#include&lt;iostream&gt;#include&lt;vector&gt;using namespace std;void swap(int&amp; a, int&amp; b)&#123; int tmp = a; a = b; b = tmp;&#125;void max_heapify(vector&lt;int&gt;&amp; numbers, int start, int end)&#123; int tmp = numbers[start]; int i = 2*start+1; while(i&lt;=end)&#123; if(i+1&lt;=end &amp;&amp; numbers[i]&lt;numbers[i+1]) i++; if(numbers[i]&lt;tmp) break; numbers[start] = numbers[i]; start = i; i = 2*start + 1; &#125; numbers[start] = tmp;&#125;void heap_sort(vector&lt;int&gt;&amp; numbers)&#123; int length = numbers.size(); for(int i = length/2-1;i&gt;=0;i--) max_heapify(numbers,i,length-1);// for(int i = 0;i&lt;length;i++)// cout &lt;&lt; numbers[i] &lt;&lt; ' ' ; for(int i = length-1;i&gt;0;i--)&#123; swap(numbers[0],numbers[i]); max_heapify(numbers,0,i-1); &#125;&#125;int main(void)&#123; int N = 0; cin &gt;&gt; N; vector&lt;int&gt; numbers(N); for(int i = 0;i&lt;N;i++) scanf("%d",&amp;(numbers[i])); heap_sort(numbers); for(int i = 0;i&lt;N;i++) cout &lt;&lt; numbers[i] &lt;&lt; ' ' ; return 0;&#125; O(nlgn) 不稳定 希尔排序是插入排序的高效率实现，也叫缩小增量排序 插入排序中，如果待排序列是正序时，时间复杂度是O(n) 如果序列是基本有序的，使用直接插入排序效率就非常高 思想：先将整个待排记录序列分割成为若干子序列分别进行直接插入排序，待整个序列中的记录基本有序时再对全体记录进行一次直接插入排序。 希尔排序的特点是，子序列的构成不是简单的逐段分割，而是将某个相隔某个增量的记录组成一个子序列。如上面的例子，第一堂排序时的增量为5，第二趟排序的增量为3。由于前两趟的插入排序中记录的关键字是和同一子序列中的前一个记录的关键字进行比较，因此关键字较小的记录就不是一步一步地向前挪动，而是跳跃式地往前移，从而使得进行最后一趟排序时，整个序列已经做到基本有序，只要作记录的少量比较和移动即可。因此希尔排序的效率要比直接插入排序高。 大量实验的基础上推出当n在某个范围内时，时间复杂度可以达到O(n^1.3)。 代码思路： 首先是增量的遍历，从length/2开始，每次除以2，直到1 其次是对于每个增量d，有length/d个子序列，注意我们这里排序是从0到length-1，而不是一个个子序列来，d可以帮我们定位到当前元素在当前序列中的上一个元素 注意 插入排序是从第二个元素开始的，在这里是从d开始的，因为增量从d变成了1 12345678910111213141516171819202122232425262728293031323334353637#include&lt;vector&gt;#include&lt;iostream&gt;using namespace std;void shell_sort_Core(vector&lt;int&gt;&amp; numbers,int d)&#123; for(int i = d;i&lt;=numbers.size()-1;i++)&#123; int j = i -d; int tmp = numbers[i]; while(j&gt;=0)&#123; if(numbers[j]&lt;tmp) break; numbers[j+d] = numbers[j]; j -= d; &#125; numbers[j+d] = tmp; &#125;&#125;void shell_sort(vector&lt;int&gt;&amp; numbers)&#123; int length = numbers.size(); for(int d = length/2;d&gt;=1;d/=2) shell_sort_Core(numbers,d);&#125;int main(void)&#123; int N = 0; cin &gt;&gt; N; vector&lt;int&gt; numbers(N); for(int i = 0;i&lt;N;i++) scanf("%d",&amp;(numbers[i])); shell_sort(numbers); for(int i = 0;i&lt;N;i++) cout &lt;&lt; numbers[i] &lt;&lt; ' ' ; return 0;&#125; 归并排序是另一种不同的排序方法，思想是递归分治， 基本思想是，先递归划分子问题，然后合并结果。把待排序列看成由两个有序的子序列，然后合并两个子序列，然后把子序列看成由两个有序序列。。。。。倒着来看，其实就是先两两合并，然后四四合并。。。最终形成有序序列。空间复杂度为O(n)，时间复杂度为O(nlogn)。 或者也可以叫合并排序 代码：自己写的 注意：mid的取值，在right=left+1的时候 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#include&lt;iostream&gt;#include&lt;vector&gt;using namespace std;void merge(vector&lt;int&gt;&amp; numbers, int left, int mid, int right)&#123; int i = left; int j = mid+1; int k = 0; vector&lt;int&gt; tmp_array(right-left+1); while(i&lt;=mid &amp;&amp; j&lt;=right)&#123; if(numbers[i]&lt;numbers[j]) tmp_array[k++] = numbers[i++]; else tmp_array[k++] = numbers[j++]; &#125; while(i&lt;=mid) tmp_array[k++] = numbers[i++]; while(j&lt;=right) tmp_array[k++] = numbers[j++]; for(int i = 0;i&lt;tmp_array.size();i++) numbers[left+i] = tmp_array[i];&#125;void mSort(vector&lt;int&gt;&amp; numbers, int left, int right)&#123; if(right==left) return; int mid = (left+right)/2; mSort(numbers, left, mid); mSort(numbers,mid+1,right); merge(numbers,left,mid,right);&#125; void merge_sort(vector&lt;int&gt;&amp; numbers)&#123; mSort(numbers, 0, numbers.size()-1);&#125;int main(void)&#123; int N = 0; cin &gt;&gt; N; vector&lt;int&gt; numbers(N); for(int i = 0;i&lt;N;i++) scanf("%d",&amp;(numbers[i])); merge_sort(numbers); for(int i = 0;i&lt;N;i++) cout &lt;&lt; numbers[i] &lt;&lt; ' ' ; return 0;&#125; 计数排序O(n)时间复杂度的排序算法 有前提条件：待排序的数要满足一定的范围的整数，而且计数排序需要比较多的辅助空间 基本思想：用待排序的数作为计数数组的下标，统计每个数字个数。然后依次输出即可得到有序序列 最大的数决定了数组的长度 这种特性也让技术排序适合于都是正整数的场景 step1:根据值new一个数组/vector，初始化全0，直接键值++ step2:根据得到的vector，遍历一遍并对给出的vector依序赋值即可 代码 自己写的 123456789101112131415161718192021222324252627282930313233343536#include&lt;iostream&gt;#include&lt;vector&gt;using namespace std;int max_(vector&lt;int&gt;&amp; numbers)&#123; int max = -1;//针对的都是正整数 for(int i = 0;i&lt;numbers.size();i++)&#123; if(numbers[i]&gt;max) max = numbers[i]; &#125; return max;&#125;void count_sort(vector&lt;int&gt;&amp; numbers)&#123; int length_ = max_(numbers); vector&lt;int&gt; tmp_array(length_ + 1, 0); for(int i = 0;i&lt;numbers.size();i++) tmp_array[numbers[i]]++; int k = 0; for(int i = 0;i&lt;length_+1;i++)&#123; for(int j = 0;j&lt;tmp_array[i];j++)&#123; numbers[k++] = i; &#125; &#125;&#125; int main(void)&#123; int N = 0; cin &gt;&gt; N; vector&lt;int&gt; numbers(N); for(int i = 0;i&lt;N;i++) scanf("%d",&amp;(numbers[i])); count_sort(numbers); for(int i = 0;i&lt;N;i++) cout &lt;&lt; numbers[i] &lt;&lt; ' ' ; return 0;&#125; 桶排序是计数排序的一种改进和推广， 桶排序的基本思想 假设有一组长度为N的待排关键字序列K[1…n]， 首先将这个序列划分为M个子区间(桶) 基于某种映射函数，将待排列的关键字k映射到第i个桶中(即同数组B的下标i)，那么该关键字k就作为B[i]的元素（每个桶B[i]都是一组大小为N/M的序列），接着对每个桶B[i]中的元素排序（可以使用快排）。然后依次枚举输出B[0]…B[M]中的全部序列即是一个有序序列。 bindex=f(key) 其中，bindex 为桶数组B的下标(即第bindex个桶), k为待排序列的关键字。桶排序之所以能够高效，其关键在于这个映射函数，它必须做到：如果关键字k1&lt;k2，那么f(k1)&lt;=f(k2)。也就是说B(i)中的最小数据都要大于B(i-1)中最大数据。很显然，映射函数的确定与数据本身的特点有很大的关系。 也就是很大一部分的排序工作被映射函数做了 所以桶排序高效 桶排序分析：桶排序利用函数的映射关系，减少了几乎所有的比较工作。实际上，桶排序的f(k)值的计算，其作用就相当于快排中划分，希尔排序中的子序列，归并排序中的子问题，已经把大量数据分割成了基本有序的数据块(桶)。然后只需要对桶中的少量数据做先进的比较排序即可。 假如待排序列K= {49、 38 、 35、 97 、 76、 73 、 27、 49 }。这些数据全部在1—100之间。因此我们定制10个桶，然后确定映射函数f(k)=k/10。则第一个关键字49将定位到第4个桶中(49/10=4)。依次将所有关键字全部堆入桶中，并在每个非空的桶中进行快速排序 如果是1-1000之间则需要100个桶，所以我们需要知道数目的范围 配合我们使用的映射函数 对N个关键字进行桶排序的时间复杂度分为两个部分： (1) 循环计算每个关键字的桶映射函数，这个时间复杂度是O(N)。 (2) 利用先进的比较排序算法对每个桶内的所有数据进行排序，其时间复杂度为 ∑ O(Ni*logNi) 。其中Ni 为第i个桶的数据量。 很显然，第(2)部分是桶排序性能好坏的决定因素。尽量减少桶内数据的数量是提高效率的唯一办法(因为基于比较排序的最好平均时间复杂度只能达到O(N*logN)了)。因此，我们需要尽量做到下面两点： (1) 映射函数f(k)能够将N个数据平均的分配到M个桶中，这样每个桶就有[N/M]个数据量。 (2) 尽量的 增大桶的数量。极限情况下每个桶只能得到一个数据，这样就完全避开了桶内数据的“比较”排序操作。当然，做到这一点很不容易，数据量巨大的情况下，f(k)函数会使得桶集合的数量巨大，空间浪费严重。这就是一个时间代价和空间代价的权衡问题了 对于N个待排数据，M个桶，平均每个桶[N/M]个数据的桶排序平均时间复杂度为：O(N)+O(M*(N/M)*log(N/M))=O(N+N*(logN-logM))=O(N+N*logN-N*logM)当N=M时，即极限情况下每个桶只有一个数据时。桶排序的最好效率能够达到O(N)。 总结： 桶排序的平均时间复杂度为线性的O(N+C)，其中C=N*(logN-logM)。如果相对于同样的N，桶数量M越大，其效率越高，最好的时间复杂度达到O(N)。 当然桶排序的空间复杂度 为O(N+M)，如果输入数据非常庞大，而桶的数量也非常多，则空间代价无疑是昂贵的。此外，桶排序是稳定的。 基数排序又是一种和前面排序方式都不同的排序方式，不需要进行记录关键字之间的比较。 基数排序是一个借助多关键字排序思想对单逻辑关键字进行排序的方法 比如说成绩的排序，如果两个人总分相同，则语文高的排在前面，语文成绩也相同则数学高的排在前面。。。如果对数字进行排序，那么个位、十位、百位就是不同优先级的关键字，如果要进行升序排序，那么个位、十位、百位优先级一次增加。基数排序是通过多次的收分配和收集来实现的，关键字优先级低的先进行分配和收集 最后进行的肯定是占比最大的也就是最高位 所以这里我们最大值有几位 桶的个数是每位的取值也就是0-9共10个 最大值有几位我们就要比较多少次 注意和桶排序区别开，虽然这里也是分成几类，但是这里是按照逻辑比较，桶排序是通过特殊函数映射然后每个桶内排序 代码(自己写的) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152#include&lt;iostream&gt;#include&lt;vector&gt;#include&lt;math.h&gt;using namespace std;int getMaxBit(vector&lt;int&gt;&amp; numbers)&#123; int max = INT_MIN; for(int i = 0;i&lt;numbers.size();i++)&#123; if(max&lt;numbers[i]) max = numbers[i]; &#125; int maxBit = 1; while(max/10!=0)&#123; maxBit++; max /= 10; &#125; return maxBit;&#125;void rSortCore(vector&lt;int&gt;&amp; numbers, int bit)&#123; int bucketNum = 10; //Obvious vector&lt;vector&lt;int&gt; &gt; Buckets(bucketNum); for(int i = 0;i&lt;numbers.size();i++) Buckets[(numbers[i]/int(pow(10,bit-1)))%10].push_back(numbers[i]); int k = 0; for(int i = 0;i&lt;Buckets.size();i++)&#123; for(int j = 0;j&lt;Buckets[i].size();j++)&#123; numbers[k++] = Buckets[i][j]; &#125; &#125;&#125;void radix_sort(vector&lt;int&gt;&amp; numbers)&#123; int max_bit = getMaxBit(numbers); for(int bit = 1;bit&lt;=max_bit;bit++) rSortCore(numbers,bit);&#125;int main(void)&#123; int N = 0; cin &gt;&gt; N; vector&lt;int&gt; numbers(N); for(int i = 0;i&lt;N;i++) scanf("%d",&amp;(numbers[i])); radix_sort(numbers); for(int i = 0;i&lt;N;i++) cout &lt;&lt; numbers[i] &lt;&lt; ' ' ; return 0;&#125; 冒泡排序、选择排序、插入排序三种简单的排序 快速排序、堆排序、希尔排序三种比较高效的排序 基于分治递归思想的归并排序 还有计数排序、桶排序、基数排序三种线性排序 排序算法要么简单有效，要么是利用简单排序的特点加以改进，要么是以空间换取时间在特定情况下的高效排序。但是这些排序方法都不是固定不变的，需要结合具体的需求和场景来选择甚至组合使用。才能达到高效稳定的目的。没有最好的排序，只有最适合的排序。 从平均时间来看，快速排序是效率最高的，但快速排序在最坏情况下的时间性能不如堆排序和归并排序。而后者相比较的结果是，在n较大时归并排序使用时间较少，但使用辅助空间较多。 上面说的简单排序包括除希尔排序之外的所有冒泡排序、插入排序、简单选择排序。其中直接插入排序最简单，但序列基本有序或者n较小时，直接插入排序是好的方法，因此常将它和其他的排序方法，如快速排序、归并排序等结合在一起使用。 基数排序的时间复杂度也可以写成O(d*n)。因此它最使用于n值很大而关键字较小的的序列。若关键字也很大，而序列中大多数记录的最高关键字均不同，则亦可先按最高关键字不同，将序列分成若干小的子序列，而后进行直接插入排序。 从方法的稳定性来比较，基数排序是稳定的内排方法，所有时间复杂度为O(n^2)的简单排序也是稳定的。但是快速排序、堆排序、希尔排序等时间性能较好的排序方法都是不稳定的。稳定性需要根据具体需求选择。 上面的算法实现大多数是使用线性存储结构，像插入排序这种算法用链表实现更好，省去了移动元素的时间。具体的存储结构在具体的实现版本中也是不同的。附：基于比较排序算法时间下限为O(nlogn)的证明：基于比较排序下限的证明是通过决策树证明的，决策树的高度Ω（nlgn），这样就得出了比较排序的下限。 红黑树 AVL树 B树 B+树 Tire树二叉搜索树： 任意节点左子树不为空,则左子树的值均小于根节点的值. 任意节点右子树不为空,则右子树的值均大于于根节点的值. 任意节点的左右子树也分别是二叉查找树. 没有键值相等的节点. 某些情况,二叉查找树会退化成一个有n个节点的线性链.——不平衡 AVL树带有平衡条件的二叉查找树，一般是用平衡因子差值判断是否平衡并通过旋转来实现平衡，左右子树树高不超过1，严格的平衡二叉树。 只要不满足该条件，就要通过旋转实现平衡，而旋转是非常耗时的 所以，AVL树适合于插入删除次数少 查找多的情况 局限性： 维护这种高度平衡所付出的代价比从中获得的效率收益还大,故而实际的应用不多 如果应用场景中对插入删除不频繁,只是对查找要求较高,那么AVL还是较优于红黑树. 红黑树在 每个节点增加一个存储位表示节点的颜色,可以是red或black. 通过对任何一条从根到叶子的路径上各个节点着色的方式的限制,红黑树确保没有一条路径会比其它路径长出两倍. 是一种弱平衡二叉树（相同结点数的情况下，可以推出，AVL树的高度低于红黑树）。 相对于AVL树来讲，旋转次数变少，对于搜索 插入 删除操作多的情况下，我们使用红黑树 性质： 1.每个结点是红 or 黑 2.根结点是黑色 3.叶结点是黑色（NIL）——这里的叶结点是指最后的左右空指针 4.红色结点的两个子结点是黑色 5.对每个结点，从该结点到其他后代叶结点的简单路径上，均包含相同数目的黑色结点 应用： 广泛用于C++的STL中,map和set都是用红黑树实现的. 著名的linux进程调度Completely Fair Scheduler,用红黑树管理进程控制块,进程的虚拟内存区域都存储在一颗红黑树上,每个虚拟地址区域都对应红黑树的一个节点,左指针指向相邻的地址虚拟存储区域,右指针指向相邻的高地址虚拟地址空间. IO多路复用epoll的实现采用红黑树组织管理sockfd，以支持快速的增删改查. ngnix中,用红黑树管理timer,因为红黑树是有序的,可以很快的得到距离当前最小的定时器. java中TreeMap的实现 B/B+树ps B-树就是B树 B/B+树是为了磁盘或其它存储设备而设计的一种平衡多路查找树(相对于二叉,B树每个内节点有多个分支),与红黑树相比,在相同的的节点的情况下,一颗B/B+树的高度远远小于红黑树的高度(在下面B/B+树的性能分析中会提到).B/B+树上操作的时间通常由存取磁盘的时间和CPU计算时间这两部分构成,而CPU的速度非常快,所以B树的操作效率取决于访问磁盘的次数,关键字总数相同的情况下B树的高度越小，磁盘I/O所花的时间越少. B树的性质 定义任意非叶子结点最多只有M个儿子；且M&gt;2； 最小度数t, t&gt;=2 根结点的儿子数为[2, M]； 除根结点以外的非叶子结点的儿子数为[M/2, M]； 每个结点存放至少M/2-1（取上整）和至多M-1个关键字；（至少2个关键字） 非叶子结点的关键字个数=指向儿子的指针个数-1； 非叶子结点的关键字：K[1], K[2], …, K[M-1]；且K[i] &lt; K[i+1]；——升序排列 非叶子结点的指针：P[1], P[2], …, P[M]；其中P[1]指向关键字小于K[1]的子树，P[M]指向关键字大于K[M-1]的子树，其它P[i]指向关键字属于(K[i-1], K[i])的子树； 注意是开区间 所有叶子结点位于同一层； 结合下面图看上面性质 这里只是一个简单的B树,在实际中B树节点中关键字很多的.上面的图中比如35节点,35代表一个key(索引)，而小黑块代表的是这个key所指向的内容在内存中实际的存储位置.是一个指针. B+树B+树是应文件系统所需而产生的一种B树的变形树(文件的目录一级一级索引,只有最底层的叶子节点(文件)保存数据.),非叶子节点只保存索引,不保存实际的数据,数据都保存在叶子节点中.这不就是文件系统文件的查找吗?我们就举个文件查找的例子:有3个文件夹,a,b,c, a包含b,b包含c,一个文件yang.c, a,b,c就是索引(存储在非叶子节点), a,b,c只是要找到的yang.c的key,而实际的数据yang.c存储在叶子节点上.所有的非叶子节点都可以看成索引部分 B+树的性质——提到的都是和B树不同的性质，其他相同 非叶子节点的子树指针与关键字个数相同; 非叶子节点的子树指针p[i],指向关键字值属于[k[i],k[i+1]]的子树.(B树是开区间,也就是说B树不允许关键字重复,B+树允许重复)； 为所有叶子节点增加一个链指针. 所有关键字都在叶子节点出现(稠密索引). (且链表中的关键字恰好是有序的); 非叶子节点相当于是叶子节点的索引(稀疏索引),叶子节点相当于是存储(关键字)数据的数据层. 更适合于文件系统; 非叶子节点(比如5,28,65)只是一个key(索引),实际的数据存在叶子节点上(5,8,9)才是真正的数据或指向真实数据的指针. 把实际的数据用一个链表链在一起，使得遍历整棵树只要遍历叶子结点就行 应用B和B+树主要用在文件系统以及数据库做索引.比如Mysql; B/B+树性能分析 n个节点的平衡二叉树的高度为H(即logn),而n个节点的B/B+树的高度为 logt((n+1)/2)+1; 若要作为内存中的查找表,B树却不一定比平衡二叉树好,尤其当m较大时更是如此.因为查找操作CPU的时间在B-树上是O(mlogtn)=O(lgn(m/lgt)),而m/lgt&gt;1;所以m较大时O(mlogtn)比平衡二叉树的操作时间大得多. 因此在内存中使用B树必须取较小的m.（通常取最小值m=3，此时B-树中每个内部结点可以有2或3个孩子，这种3阶的B-树称为2-3树）。 为什么说B+tree比B树更适合实际应用中操作系统的文件索引和数据索引. B+-tree的内部节点并没有指向关键字具体信息的指针,因此其内部节点相对B树更小,如果把所有同一内部节点的关键字存放在同一盘块中,那么盘块所能容纳的关键字数量也越多,一次性读入内存的需要查找的关键字也就越多,相对IO读写次数就降低了.由于非终结点并不是最终指向文件内容的结点，而只是叶子结点中关键字的索引。所以任何关键字的查找必须走一条从根结点到叶子结点的路。所有关键字查询的路径长度相同，导致每一个数据的查询效率相当。ps:我在知乎上看到有人是这样说的,我感觉说的也挺有道理的:他们认为数据库索引采用B+树的主要原因是:B树在提高了IO性能的同时并没有解决元素遍历的我效率低下的问题,正是为了解决这个问题,B+树应用而生.B+树只需要去遍历叶子节点就可以实现整棵树的遍历.而且在数据库中基于范围的查询是非常频繁的，而B树不支持这样的操作（或者说效率太低）. 深入分析首先，内存是快的，磁盘是慢的，所以磁盘I/O（也就是从磁盘和内存间I/O数据）是非常慢的，比在内存中直接操作数据慢几个数量级 注意我们上面的示意图都是索引，而每个索引对应数据，但在上面示意图中没有体现 B树的中间结点 是会存储卫星数据的 B+树的中间结点不会存储，只有叶子结点存储，因为叶子结点包含了所有索引，可以允许B+树这么做 B树卫星数据示意图 B+树卫星数据示意图 区别第一点：在 B 树中，节点的关键字用于在查询时确定查询区间，因此关键字数比子树数少一；而在 B+ 树中，节点的关键字代表子树的最大值，因此关键字数等于子树数。 第二点，除叶子节点外的所有节点的关键字，都在它的下一级子树中同样存在，最后所有数据都存储在叶子节点中。 根节点的最大关键字其实就表示整个 B+ 树的最大元素。(最大还是最小要看选取的是区间左端点还是右端点作为关键字) 第三点，叶子节点包含了全部的数据，并且按顺序排列，B+ 树使用一个链表将它们排列起来，这样在查询时效率更快。 由于 B+ 树的中间节点不含有实际数据，只有子树的最大数据和子树指针，因此磁盘页中可以容纳更多节点元素，也就是说同样数据情况下，B+ 树会 B 树更加“矮胖”，因此查询效率更快。 B+ 树的查找必会查到叶子节点，更加稳定。 有时候需要查询某个范围内的数据，由于 B+ 树的叶子节点是一个有序链表，只需在叶子节点上遍历即可，不用像 B 树那样挨个中序遍历比较大小。 B+ 树的三个优点： 层级更低，IO 次数更少 每次都需要查询到叶子节点，查询性能稳定 叶子节点形成有序链表，范围查询方便 范围查询是指，查询位于一个范围内的所有数，比如9-30之间 https://zhuanlan.zhihu.com/p/54102723 https://juejin.im/entry/5b0cb64e518825157476b4a9 Trie树 字典树又称单词查找树或者键树。 典型应用是统计和排序大量字符串(但不仅限于字符串)，经常被搜索引擎系统用于文本词频统计 优点：最大限度的减少无谓的字符串比较，查询效率比哈希表高 核心思想：空间换时间，利用字符串的公共前缀来降低查询时间的开销以达到提高效率的目的 基本性质 根结点不包含字符，出根结点外每一个结点都只包含一个字符 从根结点到某一结点，路径上经过的字符连接起来，为该结点对应的字符串 每个结点的所有子结点包含的字符都不相同 题目：给你100000个长度不超过10的单词。对于每一个单词，我们要 判断他是否出现过，如果出现了，求第一次出现在第几个位置。 现在回到例子中，如果我们用最傻的方法，对于每一个单词，我们都要去查找它前面的单词中是否有它。那么这个算法的复杂度就是O(n^2)。显然对于100000的范围难以接受。现在我们换个思路想。假设我要查询的单词是abcd，那么在他前面的单词中，以b，c，d，f之类开头的我显然不必考虑。而只要找以a开头的中是否存在abcd就可以了。同样的，在以a开头中的单词中，我们只要考虑以b作为第二个字母的，一次次缩小范围和提高针对性，这样一个树的模型就渐渐清晰了。 如上图所示，对于每一个节点，从根遍历到他的过程就是一个单词，如果这个节点被标记为红色，就表示这个单词存在，否则不存在。 那么，对于一个单词，我只要顺着他从根走到对应的节点，再看这个节点是否被标记为红色就可以知道它是否出现过了。把这个节点标记为红色，就相当于插入了这个单词。 这样一来我们查询和插入可以一起完成（重点体会这个查询和插入是如何一起完成的，稍后，下文具体解释），所用时间仅仅为单词长度. 我们可以看到，trie树每一层的节点数是26^i级别的。所以为了节省空间。我们用动态链表，或者用数组来模拟动态。空间的花费，不会超过单词数×单词长度 前缀查询已知n个由小写字母构成的平均长度为10的单词,判断其中是否存在某个串为另一个串的前缀子串。下面对比3种方法 哈希不好搞，但是trie还是很简单 最容易想到的：即从字符串集中从头往后搜，看每个字符串是否为字符串集中某个字符串的前缀，复杂度为O(n^2)。 使用hash：我们用hash存下所有字符串的所有的前缀子串，建立存有子串hash的复杂度为O(nxlen)，而查询的复杂度为O(n)* O(1)= O(n)。 使用trie：因为当查询如字符串abc是否为某个字符串的前缀时，显然以b,c,d….等不是以a开头的字符串就不用查找了。所以建立trie的复杂度为O(nxlen)，而建立+查询在trie中是可以同时执行的，建立的过程也就可以成为查询的过程，hash就不能实现这个功能。所以总的复杂度为O(nxlen)，实际查询的复杂度也只是O(len)。（说白了，就是Trie树的平均高度h为len，所以Trie树的查询复杂度为O（h）=O（len）。好比一棵二叉平衡树的高度为logN，则其查询，插入的平均时间复杂度亦为O（logN））。 下面解释下上述方法3中所说的为什么hash不能将建立与查询同时执行，而Trie树却可以： 在hash中，例如现在要输入两个串911，911456，如果要同时查询这两个串，且查询串的同时若hash中没有则存入。那么，这个查询与建立的过程就是先查询其中一个串911，没有，然后存入9、91、911；而后查询第二个串911456，没有然后存入9、91、911、9114、91145、911456。因为程序没有记忆功能，所以并不知道911在输入数据中出现过，只是照常以例行事，存入9、91、911、9114、911…。也就是说用hash必须先存入所有子串，然后for循环查询。 而trie树中，存入911后，已经记录911为出现的字符串，在存入911456的过程中就能发现而输出答案；倒过来亦可以，先存入911456，在存入911时，当指针指向最后一个1时，程序会发现这个1已经存在，说明911必定是某个字符串的前缀。 可以看出： 每条边对应一个字母。 每个节点对应一项前缀。叶节点对应最长前缀，即单词本身。 单词inn与单词int有共同的前缀“in”, 因此他们共享左边的一条分支，root-&gt;i-&gt;in。同理，ate, age, adv, 和ant共享前缀”a”，所以他们共享从根节点到节点”a”的边。 查询操纵非常简单。比如要查找int，顺着路径i -&gt; in -&gt; int就找到了。 ​ 搭建Trie的基本算法也很简单，无非是逐一把每则单词的每个字母插入Trie。插入前先看前缀是否存在。如果存在，就共享，否则创建对应的节点和边。比如要插入单词add，就有下面几步： 考察前缀”a”，发现边a已经存在。于是顺着边a走到节点a。 考察剩下的字符串”dd”的前缀”d”，发现从节点a出发，已经有边d存在。于是顺着边d走到节点ad 考察最后一个字符”d”，这下从节点ad出发没有边d了，于是创建节点ad的子节点add，并把边ad-&gt;add标记为d。 Trie树的应用除了本文引言处所述的问题能应用Trie树解决之外，Trie树还能解决下述问题（节选自此文：海量数据处理面试题集锦）： 3、有一个1G大小的一个文件，里面每一行是一个词，词的大小不超过16字节，内存限制大小是1M。返回频数最高的100个词。 9、1000万字符串，其中有些是重复的，需要把重复的全部去掉，保留没有重复的字符串。请怎么设计和实现？ 10、 一个文本文件，大约有一万行，每行一个词，要求统计出其中最频繁出现的前10个词，请给出思想，给出时间复杂度分析。 13、寻找热门查询：搜索引擎会通过日志文件把用户每次检索使用的所有检索串都记录下来，每个查询串的长度为1-255字节。假设目前有一千万个记录，这些查询串的重复读比较高，虽然总数是1千万，但是如果去除重复和，不超过3百万个。一个查询串的重复度越高，说明查询它的用户越多，也就越热门。请你统计最热门的10个查询串，要求使用的内存不能超过1G。(1) 请描述你解决这个问题的思路；(2) 请给出主要的处理流程，算法，以及算法的复杂度。 红黑树 AVL树 B-树 B+树 Trie树(字典树) 海量数据问题： 十亿整数（随机生成&amp;可重复）中前K最大的数 十亿整数（随机生成&amp;可重复）中出现频率最高的一千个 快排 建堆 归并 桶 算法的时间空间复杂度，最好最差平均情况 布隆过滤器： 几十亿个数经常要查找某一个数在不在里面，使用布隆过滤器，布隆过滤器的原理。布隆过滤器可能出现误判，怎么保证无误差？ HTTP： http/https 1.0、1.1、2.0的特点和区别 get/post 区别 HTTP返回状态码 http 协议头相关 http数据由请求行，首部字段，空行，报文主体四个部分组成首部字段分为：通用首部字段，请求首部字段，响应首部字段，实体首部字段 https与http的区别？如何实现加密传输？加解密方式？ 浏览器中输入一个URL发生什么，用到哪些协议？ 安全相关 至少了解攻击的原理和基本的防御方法，常见的攻击方法有一下几种 SQL注入 XSS CSRF SYN洪水攻击 APR欺骗 数据库 主要参考书籍：《数据库系统概念》，《高性能MySQL》 SQL语言(内外连接，子查询，分组，聚集，嵌套，逻辑) MySQL索引方法？索引的优化？ InnoDB与MyISAM区别？ 事务的ACID 事务的四个隔离级别 查询优化(从索引上优化，从SQL语言上优化) B-与B+树区别？ MySQL的联合索引(又称多列索引)是什么？生效的条件？ 其他 ++i是否是原子操作明显不是，++i主要有三个步骤，把数据从内存放在寄存器上，在寄存器上进行自增，把数据从寄存器拷贝会内存，每个步骤都可能被中断。 判断大小端 设计模式 单利模式线程安全的写法 STL里的迭代器模式，适配器写法 分布式系统 map_reduce 原理 负载均衡 CDN 算法和数据结构，数据结构我比较关注哈希、优先级队列等，算法则是字符串处理、简单的 DFS、BFS、动态规划都有 系统的知识：进程、线程、协程、锁的使用、消息队列、共享内存、还有网络协议、epoll、select等。顺便会考察一些处理问题的基本思路，比如通过哈希来划分、通过队列来序列化操作等等。此外，往往很多同学的项目经历中，有很多点可以结合系统的知识来考察，看看是否真的做过项目。比如我就碰到过自己写过 web server 的，搞过 key-value 数据库的，声称读过 redis 源码的，这些很适合配合系统知识考察，确认是不是真的做过这些项目，理解如何。 一类是Linux基本操作，包括常用的Linux命令和工具的使用 shell脚本的编写，能通过脚本玩车给一些日常任务 另一类是重点，Linux环境编程，需要对Linux的API要熟悉(POSIX哪些函数，当然ANSI标准库的函数也要熟悉)。经常考察的就是IO 各类IPC的操作方式，socket通信的流程 select/poll/epoll等IO多路复用模型。socket和IO多路复用是网络编程的重点 用template 写工厂模式 右值引用 哪些情况非用pointer不可。vector的增长 map的实现 iterator invalidation相关问题。 ![Screen Shot 2019-08-08 at 11.41.13 AM](/Users/liutao/Desktop/screenshot/Screen Shot 2019-08-08 at 11.41.13 AM.png) C++类的内存布局 然后是C++部分，基础语法是不会考的，很喜欢考类的内存布局，vtable的原理，虚继承的时候类内存布局，多继承的时候类的布局。另外一个重点在内存部分，只要跟内存相关的都喜欢考，对指针的理解，allocator的实现，vector内存分配的策略，各种智能指针实现原理及其使用注意事项, rule of three， RAII，内存泄漏的原油时候如何调试等等。 Linux这里主要考察进程调度和进程生命周期，特别是CFS调度算法，几乎是必问，进程部分还有进程间通信。还有文件系统，对VFS的结构很喜欢考，解释软链接和硬链接（从inode和dentry去解释），还有文件缓存，IO调度算法等等。Linux这里也喜欢问内存，slab，slub，伙伴算法，进程内存空间，线程内存空间等等。在系统编程层次主要考察各种IO系统调用、进程相关的系统调用、socket编程。然后把这些系统调用对应到进程生命周期和进程间通信的各个阶段去考。还会考查高级IO操作，IO多路复用，poll，epoll等等，AIO，零拷贝。另外就是Linux的各种使用命令等等，都是常用命令，sed，grep，top这种。 计算机网络主要集中在tcp/ip还有http上面，喜欢考tcp/ip的各种状态转移，把UNP中那副状态转移图中的11个状态背下来就可以应付，还有就是滑动窗口，慢启动，快恢复等等，偶尔会考路由算法。Http会考查一些状态码，各种http选项，重点考查缓存控制，考查keep-alive和pipe line等等。 文件系统 补充部分通过讲int类型转换为char，获得低字节部分，可以得知cpu是大端还是小端 注意union联合体的共享内存的概念，不同类型指向同一快内存，输出值（有点类似于类型转换的感觉） 所以union可以用来判断cpu是大端还是小端 1234567891011121314151617181920#include &lt;iostream&gt;using namespace std;void checkCPU()&#123; union MyUnion&#123; int a; char c; &#125;test; test.a = 1; if (test.c == 1) cout &lt;&lt; "little endian" &lt;&lt;endl; else cout &lt;&lt; "big endian" &lt;&lt;endl;&#125;int main()&#123; checkCPU(); return 0;&#125; 123456789101112131415161718192021222324252627282930#include &lt;iostream&gt;using namespace std;union test&#123; char mark; long num; float score;&#125;a;int main()&#123; // cout&lt;&lt;a&lt;&lt;endl; // wrong a.mark = 'b'; cout&lt;&lt;a.mark&lt;&lt;endl; // 输出'b' cout&lt;&lt;a.num&lt;&lt;endl; // 98 字符'b'的ACSII值 cout&lt;&lt;a.score&lt;&lt;endl; // 输出错误值 a.num = 10; cout&lt;&lt;a.mark&lt;&lt;endl; // 输出换行 非常感谢suxin同学的指正 cout&lt;&lt;a.num&lt;&lt;endl; // 输出10 cout&lt;&lt;a.score&lt;&lt;endl; // 输出错误值 a.score = 10.0; cout&lt;&lt;a.mark&lt;&lt;endl; // 输出空 cout&lt;&lt;a.num&lt;&lt;endl; // 输出错误值 cout&lt;&lt;a.score&lt;&lt;endl; // 输出10 return 0;&#125; STL的内存管理 ps：new一个对象的过程 step1: malloc分配一块内存 step2: 执行构造函数 在SGI中，allocate申请内存 construct调用构造函数 讲下简单的过程：首先分为两层配置： 第一层使用malloc和free 第二层使用内存池 如果分配或释放的空间&gt;128BYTE，使用第一层 如果&lt;=128B，则调用第二层 第二层内存池：主要是维护了16个空闲链表 注意这里内存池不等于16个空闲链表，内存池首先是从堆里配置一大块内存，然后用来维护16个链表，16个链表分别管理代销为8 16 24 …128的数据块，也就是对应链表的结点指向的内存都是8/16/24/…128 refill：填充的是没有可用区块的空闲链表，也就是这个链表直接指向了NULL 空间配置函数allocate：大于128B调用第一层，否则调用第二层，查找对应的空闲链表，有区块直接用，否则refill空闲链表 空间释放函数deallocate： 检查大小，大于128B调用第一层配置，否则调用第二层配置。首先根据回收数据块的大小判断应该将回收后的数据插入哪个空闲链表，把该结点指向的下一个地址修改为原链表指向的地址（这里是NULL），然后将原链表指向该结点。 4 重新填充空闲链表 如果空闲链表中没有可用数据块，也就是说这个链表只有一个NULL，这时候调用上面的refill来重新填充空间，新的空间取自内存池。默认取20个数据块，如果内存池空间不足，那么能取多少个就多少个 5 从内存池取空间，也就是去空间给空闲链表，第一步肯定是从内存池里申请，如果不够再用malloc从堆里申请给内存池，实在不行，从所有的空闲链表里找可用区块，把该数据块分给内存池，然后将该数据块从链表里删除。 几个过程的思路 申请过程 123456789101112131415if (用户申请的内存不大于128 bytes) 查找对应的链表 if (对应链表拥有一块以上的区块) 调整链表 返回第一个区块地址 else 准备重新填充链表 向内存池申请内存(指定数量的区块) if (内存池申请到一个区块) 返回第一个区块地址 else 调整链表，将区块串接起来 返回第一个区块地址 else 直接用malloc()申请内存 释放过程 12345if (用户释放的内存块大于128 bytes) 直接用free()释放 else 查找对应的链表 回收内存 向内存池申请内存过程 123456789101112if (内存池空间完全满足需求量) 调整内存池起始位置 返回空间地址 else if (内存池空间不能完全满足需求量，但能提供一个以上的区块) 计算能够提供的最大内存 调整内存池起始位置 返回空间地址 else 从内存池中压缩内存 收集比size大的空间 递归调用，修正nobjs 再次申请内存，可能抛出异常 STL里的set和map是基于什么实现的 红黑树的特点 vector封装数组，list封装了链表，map和 set封装了二叉树等，在封装这些数据结构的时候，STL按照程序员的使用习惯，以成员函数方式提供的常用操作，如：插入、排序、删除、查找等。让用户在 STL使用过程中，并不会感到陌生。 vector（向量）——STL中标准而安全的数组。只能在vector 的“前面”增加数据。deque（双端队列double-ended queue）——在功能上和vector相似，但是可以在前后两端向其中添加数据。 list（列表）——游标一次只可以移动一步。如果你对链表已经很熟悉，那么STL中的list则是一个双向链表（每个节点有指向前驱和指向后继的两个指针） set（集合）——包含了经过排序了的数据，这些数据的值(value)必须是唯一的。 map （映射）——经过排序了的二元组的集合，map中的每个元素都是由两个值组成，其中的key（键值，一个map中的键值必须是唯一的）是在排序或搜索时使用，它的值可以在容器中重新获取；而另一个值是该元素关联的数值。比如，除了可以ar[43] = “overripe”这样找到一个数据，map还可以通过ar[“banana”] = “overripe”这样的方法找到一个数据。如果你想获得其中的元素信息，通过输入元素的全名就可以轻松实现。 multiset（多重集）——和集合（set）相似，然而其中的值不要求必须是唯一的（即可以有重复）。 multimap（多重映射）——和映射（map）相似，然而其中的键值不要求必须是唯一的（即可以有重复） STL map和set的使用虽不复杂，但也有一些不易理解的地方，如： 为何map和set的插入删除效率比用其他序列容器高？ 为何每次insert之后，以前保存的iterator不会失效？ 为何map和set不能像vector一样有个reserve函数来预分配数据？ 当数据元素增多时（10000到20000个比较），map和set的插入和搜索速度变化如何？ C++ STL中标准关联容器set, multiset, map, multimap内部采用的就是一种非常高效的平衡检索二叉树：红黑树，也成为RB树 什么是红黑树 红黑树是一棵二叉搜索树，每个结点增加了一个存储位来表示结点颜色，RED or BLACK，通过对任何一条从根到叶子的简单路径上的各个结点的颜色进行约束，确保没有一条路径会比其他路径长出两倍，近似于是平衡的。 性质 1.每个结点是红 or 黑 2.根结点是黑色 3.叶结点是黑色（NIL）——这里的叶结点是指最后的左右空指针 4.红色结点的两个子结点是黑色 5.对每个结点，从该结点到其他后代叶结点的简单路径上，均包含相同数目的黑色结点 使用一个哨兵T.nil来代替所有NIL 节省空间 一般我们把有关键字的非NIL结点成为内部结点，这是我们所关心的部分 从某个结点x出发（不含该结点）到达任意一个叶结点的简单路径上的黑色结点个数称为黑高。 红黑树的黑高为根结点的黑高 一棵n个内部结点的红黑树的高度至多为2lg(n+1) 旋转 INSERT DELETE操作可能违反红黑树的性质，这里需要旋转操作来维持这些性质 右旋 左旋——O(1)时间内完成，只有指针改变，其他所有属性不变 插入 可以证明在O(lgn)时间内完成 插入结点 颜色属性为红色 利用二叉搜索树的插入TREE-INSERT之后调用一个辅助程序INSERT-FIXUP来对结点重新着色并旋转 分析： TREE-INSERT插入红色结点后 哪些性质不能保持 只有两种情况： 1.z是根结点，破坏了性质2 2.z的父结点是红色，破坏了性质4 我们保证我们当前的指向的结点z颜色是红色，所以我们循环的条件就是z.p.color==RED，因为这样破坏了性质4 分情况操作： 父结点是右孩子和左孩子是对称的，所以我们这里只讨论父结点是左孩子的情况，右孩子的代码就是把右孩子中的left和right调换一下 情况一：叔结点是红色，爷肯定是黑色，那么叔 爸 变黑 爷变红，指针指到爷，在进行下一轮循环（符合z是红） 情况二：叔结点是黑色，如果z是右孩子，z上升为爸并左旋，否则不左旋，然后将爸变成黑色，爷变成红色，然后右旋。 为何map和set的插入删除效率比用其他序列容器高？ 插入和删除只需要做指针的变换，不需要内存的移动和拷贝 为什么insert之后，以前保存的iterator不会失效？ iterator相当于指针，指针更换，但是内存没有变（发生移动拷贝释放），所以指向内存的指针也就是iterator不会失效。（当然被删除的那个元素本身失效了） 相对于vector来说，每一次删除和插入，指针都有可能失效，调用push_back在尾部插入也是如此。因为为了保证内部数据的连续存放，iterator指向的那块内存在删除和插入过程中可能已经被其他内存覆盖或者内存已经被释放了。即使时push_back的时候，容器内部空间可能不够，需要一块新的更大的内存，只有把以前的内存释放，申请新的更大的内存，复制已有的数据元素到新的内存，最后把需要插入的元素放到最后，那么以前的内存指针自然就不可用了。特别时在和find等算法在一起使用的时候，牢记这个原则：不要使用过期的iterator。 为何map和set不能像vector一样有个reserve函数来预分配数据？ 引起它的原因在于在map和set内部存储的已经不是元素本身了，而是包含元素的结点 也就是说map内部使用的Alloc并不是map&lt;Key, Data, Compare, Alloc&gt;声明的时候从参数中传入的Alloc。例如： map&lt;int, int, less&lt;int&gt;, Alloc&lt;int&gt; &gt; intmap; 这时候在intmap中使用的allocator并不是Alloc&lt;int&gt;, 而是通过了转换的Alloc，具体转换的方法时在内部通过Alloc&lt;int&gt;::rebind重新定义了新的节点分配器，详细的实现参看彻底学习STL中的Allocator。其实你就记住一点，在map和set内面的分配器已经发生了变化，reserve方法你就不要奢望了。 当数据元素增多时（10000和20000个比较），map和set的插入和搜索速度变化如何？ 如果你知道log2的关系你应该就彻底了解这个答案。在map和set中查找是使用二分查找，也就是说，如果有16个元素，最多需要比较4次就能找到结果，有32个元素，最多比较5次。那么有10000个呢？最多比较的次数为log10000，最多为14次，如果是20000个元素呢？最多不过15次。看见了吧，当数据量增大一倍的时候，搜索次数只不过多了1次，多了1/14的搜索时间而已。你明白这个道理后，就可以安心往里面放入元素了。 最后，对于map和set Winter还要提的就是它们和一个c语言包装库的效率比较。在许多unix和linux平台下，都有一个库叫isc，里面就提供类似于以下声明的函数: 123456void tree_init(void **tree);void *tree_srch(void **tree, int (*compare)(), void *data);void tree_add(void **tree, int (*compare)(), void *data, void (*del_uar)());int tree_delete(void **tree, int (*compare)(), void *data,void (*del_uar)());int tree_trav(void **tree, int (*trav_uar)());void tree_mung(void **tree, void (*del_uar)()); 许多人认为直接使用这些函数会比STL map速度快，因为STL map中使用了许多模板什么的。其实不然，它们的区别并不在于算法，而在于内存碎片。如果直接使用这些函数，你需要自己去new一些节点，当节点特别多，而且进行频繁的删除和插入的时候，内存碎片就会存在，而STL采用自己的Allocator分配内存，以内存池的方式来管理这些内存，会大大减少内存碎片，从而会提升系统的整体性能。Winter在自己的系统中做过测试，把以前所有直接用isc函数的代码替换成map，程序速度基本一致。当时间运行很长时间后（例如后台服务程序），map的优势就会体现出来。从另外一个方面讲，使用map会大大降低你的编码难度，同时增加程序的可读性。何乐而不为？学习STL map, STL set之数据结构基础 linux上进程有5种状态: 运行(正在运行或在运行队列中等待) 中断(休眠中, 受阻, 在等待某个条件的形成或接受到信号) 不可中断(收到信号不唤醒和不可运行, 进程必须等待直到有中断发生) 僵死(进程已终止, 但进程描述符存在, 直到父进程调用wait4()系统调用后释放) 停止(进程收到SIGSTOP, SIGSTP, SIGTIN, SIGTOU信号后停止运行运行) AVL树 任一结点对应的两颗子树的最大高度差为1，因此也被称为高度平衡树 查找 插入和删除再平均和最坏情况下的时间复杂度都是O(lgn) Linux定位内存泄漏 Valgrind Valgrind是一套Linux下，开源的仿真调试工具的集合 Valgrind由内核（core）以及基于内核的其他调试工具组成。内核类似于一个框架（framework），它模拟了一个CPU环境，并提供服务给其他工具；而其他工具则类似于插件 (plug-in)，利用内核提供的服务完成各种特定的内存调试任务。 Valgrind包括如下工具： Memcheck。这是valgrind应用最广泛的工具，一个重量级的内存检查器，能够发现开发中绝大多数内存错误使用情况，比如：使用未初始化的内存，使用已经释放了的内存，内存访问越界等。这也是本文将重点介绍的部分。 Callgrind。它主要用来检查程序中函数调用过程中出现的问题。 Cachegrind。它主要用来检查程序中缓存使用出现的问题。 Helgrind。它主要用来检查多线程程序中出现的竞争问题。 Massif。它主要用来检查程序中堆栈使用中出现的问题。 Extension。可以利用core提供的功能，自己编写特定的内存调试工具 Valgrind检测内存原理： 关键在于建立了两个全局表 Valid-Value表 对于进程的整个地址空间中的每一个字节(byte)，都有与之对应的 8 个 bits；对于 CPU 的每个寄存器，也有一个与之对应的 bit 向量。这些 bits 负责记录该字节或者寄存器值是否具有有效的、已初始化的值。 Valid-Address表 对于进程整个地址空间中的每一个字节(byte)，还有与之对应的 1 个 bit，负责记录该地址是否能够被读写。 检测原理：当要读写内存中某个字节时，首先检查这个字节对应的 A bit。如果该A bit显示该位置是无效位置，memcheck 则报告读写错误。内核（core）类似于一个虚拟的 CPU 环境，这样当内存中的某个字节被加载到真实的 CPU 中时，该字节对应的 V bit 也被加载到虚拟的 CPU 环境中。一旦寄存器中的值，被用来产生内存地址，或者该值能够影响程序输出，则 memcheck 会检查对应的V bits，如果该值尚未初始化，则会报告使用未初始化内存错误。 第十七讲 同步互斥 进程并发执行的好处 共享资源 降低成本 加速 模块化 易于扩展和复用，多个进程完成一个功能 并发编程会出现问题，需要同步互斥来解决 原子操作： 要么操作成功完成 或者操作没有执行 不会出现部分执行的状态 再等待的时候，不能做其他事情——忙等待，占用cpu 锁 利用两个原子操作实现一个锁 Lock.Acquire() 获取锁的拥有权 申请锁，如果没有获得，一直处于等待状态 Lock.Release() 释放锁的拥有权 解锁并唤醒任何等待中的进程 进程间的交互关系：![Screen Shot 2019-08-15 at 4.52.28 PM](/Users/liutao/Desktop/screenshot/Screen Shot 2019-08-15 at 4.52.28 PM.png) 互斥mutual exclusion： 一个进程占用资源，其他进程不能占用 死锁deadlock： 多个进程个占用部分资源 形成循环等待 饥饿 其他进程轮流占用资源，一个进程一直得不到资源 代码的四个区 临界区 是指进程中访问临界资源的一段需要互斥执行的代码 访问临界资源当然要互斥执行 进入区 检查可否进入临界区的一段代码 如可进入，设置正在访问临界区的标志 退出区 清除正在访问临界区的标志 剩余区 跟我们同步互斥没关系的代码 临界区的访问规则 空闲则入 忙则等待 有限等待 让权等待（可选） 不能进入临界区的进程，应释放cpu（如转换到阻塞状态），而不是忙等占用cpu 临界区的实现方法 禁用中断 软件方法 更高级的抽象方法 禁用中断 整个系统由当前进程独占，没有中断，没有上下文切换 因此没有并发 基于软件的同步方法（可以简单的认为，同步就是有序执行，相互协调） 复杂 尤其是多线程多个临界区的时候，更难协调 高级抽象的同步方法 实际上是基于硬件提供的同步原语 原子操作指令：由硬件保证其原子性操作系统提供更高级的编程抽象来简化进程同步 比如 锁lock 信号量semaphore 锁是一个抽象的数据结构：一个二进制变量+两个原子操作（成员函数） 一个二进制变量（锁定/解锁） Lock::Acquire()——锁被释放前一直等待，然后得到锁，该函数返回时就已经获得这个锁了 Lock::Release() 释放锁，唤醒任何等待的进程。 使用锁来控制临界区访问 123lock_next_pid-&gt;Acquire();new_pid = next_pid++;lock_next_pid-&gt;Release(); 简单介绍几个原子操作指令 TS原子操作指令Test-and-Set指令，测试和置位指令 从内存单元中取值 测试该值是否为1（然后返回真或假） 内存单元值设置为1 12345boolean TestAndSet(boolean *target)&#123; boolean rv = *target; *target = true; return rv;&#125; 交换指令（exchange） 交换内存中的两个值（内存都是二进制。。） 12345void Exchange (boolean *a,boolean *b)&#123; boolean tmp = *a; *a = *b; *b = tmp;&#125; 用TS指令实现自旋锁spinlock 12345678910class lock&#123; value = 0;&#125;Lock::Acquire()&#123; while(test-and-set(value)) ;&#125;Lock::Release()&#123; value = 0;&#125; 对Acquire的解读：如果value为1，则返回1，同时说明锁被占用，while 一只循环等待，当value为0时，置1并返回0，循环结束。完成了锁的Acquire Release：将value置0 线程在等待时候要消耗cpu，也就是一直执行TS指令 实现无忙等待锁 123456789101112131415class Lock &#123; int value = 0; WaitQueue q;&#125;Lock::Acquire()&#123; while(test-and-set(value))&#123; add this TCB to wait queue; schedule(); &#125;&#125;Lock::Release()&#123; value = 0; remove one thread t from q; wakeup(t);&#125; 加入一个等待队列，这样的话，Acquire时，如果锁被占用，我们可以先讲这个进程放到等待队列中去，等待过程放弃cpu的控制权，然后执行调度，使cpu执行其他进程，等到不被占用的时候，cpu再回来执行该线程 多个临界区：一个临界区可以用一把锁 非阻塞和阻塞 对应异步和同步 同步，又称直接制约关系，是指多个线程（或进程）为了合作完成任务，必须严格按照规定的 某种先后次序来运行。 互斥，又称间接制约关系，是指系统中的某些共享资源，一次只允许一个线程访问。当一个线程正在访问该临界资源时，其它线程必须等待。 互斥是指某一资源同时只允许一个访问者对其进行访问，具有唯一性和排它性。但互斥无法限制访问者对资源的访问顺序，即访问是无序的。 同步是指在互斥的基础上（大多数情况），通过其它机制实现访问者对资源的有序访问。 同步其实已经实现了互斥，所以同步是一种更为复杂的互斥。 互斥是一种特殊的同步。 前者(排队等候)就是同步等待消息，而后者(等待别人通知)就是异步等待消息。在异步消息处理中，等待消息者(在这个例子中就是等待办理业务的人)往往注册一个回调机制，在所等待的事件被触发时由触发机制(在这里是柜台的人)通过某种机制(在这里是写在小纸条上的号码)找到等待该事件的人。 而在实际的程序中,同步消息处理就好比简单的read/write操作,它们需要等待这两个操作成功才能返回；而异步处理机制就是类似于select/poll之类的多路复用IO操作，当所关注的消息被触发时，由消息触发机制通知触发对消息的处理。 阻塞 非阻塞：关注的是处理消息的机制，阻塞就是等待的时候不能做其他事情，非阻塞就是等待的时候可以做其他事情 异步同步：关注的是消息通知的机制，同步是等待方去询问，异步是被通知（被通知空闲，这时候你可以占用资源） 管道是基于内存文件的通信机制，（管道实际就是放在内存中的一种数据文件，）利用子进程继承父进程的文件描述符，该管道文件可以被父子进程读/写，但是管道本身并不care是谁读写，所以我们在使用时候 关闭父进程读端，子进程写端 或者是关闭父进程写端 子进程读端 这样才能构造一条父子或者子父之间的一条间接通路 我们的进程并不关心 另一端 消息队列是由操作系统维护的以字节序列为基本单位的间接通信机制 “消息”就是一个字节序列 消息队列独立于进程，所以进程退出并不会释放已经创建的消息队列 通过msgget创建消息队列，通过msgctl释放消息队列 共享内存是吧同一物理内存区域映射到多个进程虚拟地址空间的通信机制 同一进程的线程，天然共享内存，而不同进程就不一样了，拥有各自独立的内存空间，所以需要引入共享内存机制，来进行不同进程间的通信 共享内存：快速，方便 不需要系统调用，不需要内核和用户的切换 不足：必须调用额外的同步机制来协调数据访问 当一个任务（进程）执行系统调用而陷入内核代码中执行时，我们就称进程处于内核运行态（或简称为内核态）。 这里的映射和之前的虚拟内存一样 使用页表 一个进程写，另一个进程可以立即看见 没有系统调用干预（无需陷入内核态？？） 这里指的是访问数据的时候无需要系统调用，使用我们的读写指令就可以了 但是共享关系建立和销毁的时候仍然需要系统调用 没有数据复制 不提供同步 由程序员提供同步 一般配合信号量使用 信号量 用信号量表示系统资源的数量 信号量是一种抽象的数据类型，由一个整型变量sem和两个原子操作P V做成 P：申请资源的时候用的 先使sem减1，如果sem&lt;0，进入等待（&lt;0意味着没有响应资源），否则继续执行 V：释放资源的时候使用的 先使sem+1，如果sem&lt;=0，唤醒一个等待进程（&lt;=0说明有需要资源的进程在等待）， 信号量是受保护的整数变量 初始化完成后，只能有P() V()修改 由操作系统保证 P V 是原子操作 P可能阻塞（因为没有资源），V不会阻塞 信号量分为两类： 二进制信号量 资源数目为0或1 资源信号量 资源数目为任何非负值 这两者等价，基于一个可以实现另外一个 信号量的使用 互斥访问 临界区的互斥访问控制 条件同步 线程间的事件等待 用信号量实现临界区的互斥访问 一个信号量对应一个临界区 重要！！ 必须成对使用P() 操作和V()操作 P操作保证互斥访问临界资源 V操作在使用后释放临界资源 PV操作不能次序错误 重复或遗漏 ![Screen Shot 2019-08-14 at 6.27.24 PM](/Users/liutao/Desktop/screenshot/Screen Shot 2019-08-14 at 6.27.24 PM.png) ![Screen Shot 2019-08-14 at 6.30.37 PM](/Users/liutao/Desktop/screenshot/Screen Shot 2019-08-14 at 6.30.37 PM.png) 对信号量和PV操作的理解 信号量是一个类，包含一个数据成员和两个成员函数P操作和V操作 首先信号量受保护，只能被PV操作改变 其次PV操作的一部分是（先）改变信号量的值，然后根据改变后的值的不同做进一步的操作。所以PV操作由两部分组成，一部分是对信号量的改变，二是根据改变后的信号量的值对进程/线程的操作 可以用来做临界区互斥访问 和 条件同步 首先说一下什么是互斥访问和条件同步 互斥访问：同一时间仅能有一个进程/线程访问/占有某一资源 条件同步：B线程需要等待A线程的某段代码执行完成后才能执行，否则阻塞 临界区互斥访问 P()操作保证互斥的访问（占据）临界资源 V()操作保证在使用后释放临界资源 条件同步 指的是两个线程A B其中A的一部分执行需要等待B的条件满足才可以继续下去 比如上面的B执行完X模块后，A才能执行N模块 假设P先执行，那么线程A会阻塞直到B执行完X后的V操作后才会唤醒线程A 假设V先执行，说明X模块已经执行，A执行P后继续执行N，没有问题 关于生产者-消费者问题 ![Screen Shot 2019-08-14 at 7.13.29 PM](/Users/liutao/Desktop/screenshot/Screen Shot 2019-08-14 at 7.13.29 PM.png) 涉及到三个问题： 互斥访问（mutex） 缓冲区空的时候消费者不能取，必须等待生产者放入之后才可以（条件同步） 缓冲区满的时候生产者不能存，必须等待消费者取走之后才可以放入（条件同步） 对应单个信号量： mutex 初值1（没有人访问，所以是可以访问） fullbuffers：填满的个数 emptybuffers：空的个数 假设buffer可以存放n个单位 fullbuffers：没有占位，所以是0 remove操作对应P -1，add操作对应V +1 emptybuffers：全空，所以是n（n是指buffer可以存储n个单位），对应n个单位才能被填满，remove操作对应V+1 add操作对应P-1 ![Screen Shot 2019-08-14 at 7.26.33 PM](/Users/liutao/Desktop/screenshot/Screen Shot 2019-08-14 at 7.26.33 PM.png) 上面的三个顺序不能改变 emptybuffer 和 fullbuffer部分，不然会形成死锁 我们需要先检查 再去互斥访问，如果是满，然后我们去申请，这时候我们已经占用了临界资源，别人不能访问，而我们也没法继续下去（满了当然写不了了），我们会阻塞在fullbuffer/emptybuffer，而别人/别的进程会阻塞在互斥访问mutex上 ![Screen Shot 2019-08-14 at 7.34.08 PM](/Users/liutao/Desktop/screenshot/Screen Shot 2019-08-14 at 7.34.08 PM.png) 管程 改进信号量，处理临界区的麻烦，信号量的PV操作的配对，把这些配对的PV操作集中在一起，就是我们这里说的管程 ![Screen Shot 2019-08-14 at 8.00.50 PM](/Users/liutao/Desktop/screenshot/Screen Shot 2019-08-14 at 8.00.50 PM.png) 锁+信号量——临界区 锁+条件变量——管程 ![Screen Shot 2019-08-14 at 8.20.35 PM](/Users/liutao/Desktop/screenshot/Screen Shot 2019-08-14 at 8.20.35 PM.png) 引入条件变量 管程是一种用于多线程互斥访问共享资源的程序结构 ![Screen Shot 2019-08-14 at 8.08.45 PM](/Users/liutao/Desktop/screenshot/Screen Shot 2019-08-14 at 8.08.45 PM.png) 入口队列加锁，只允许一个线程在管程内部执行 介绍条件变量——是为了实现条件等待 条件变量是一个类，包含了两个数据成员和两个成员函数 数据成员： waitQueue q：等待队列，用来放入等待状态的线程 int numWaiting: 整数，用来表示等待队列中正在等待的线程数目 成员函数： Wait(lock) 首先numWaiting++，表示有一个等待线程要加入等待队列 把该线程放入q队列，并释放管程的互斥访问权lock，执行调度（其他线程可能执行），执行完成后，再重新获取管程的访问权 这里的lock是管程的互斥访问的锁 Signal 首先判断是否有等待的线程numWaiting&gt;0才能释放， 然后从等待队列里去一个线程出来，唤醒，然后numWaiting– 上面wait中的调度其他线程和signal中的唤醒其他线程都需要mutex来协调 mutex：二进制信号量，实现互斥访问。 是一个类，包含numWaiting 和 q数据成员 以及 Wait(lock) Signal两个成员函数 条件变量是管程内的等待机制 进入管程的线程因资源占用而进入等待状态 每个条件变量表示一种等待原因，对应一个等待队列 Wait()操作——完成以下两个操作 将自己阻塞在等待队列中 唤醒一个等待着或者说释放管程的互斥访问，允许另一个线程进入管程 Signal()操作 将等待队列中的一个线程唤醒 如果等待队列为空，则等同空操作 条件变量实现 1234class Condition&#123; int numWaiting = 0; WaitQueue q;&#125; 和信号量不同：信号量的初值和你的资源数是一致的 numWaiting为正表示有线程处于等待状态 schedule：调度的意思 如下是条件变量的的wait 和 signal操作实现 以及维护的Condition类（一个整数和一个等待队列 ![Screen Shot 2019-08-14 at 8.55.21 PM](/Users/liutao/Desktop/screenshot/Screen Shot 2019-08-14 at 8.55.21 PM.png) 条件变量维护一个整数numWaiting：表示处于等待状态的线程个数 和 一个等待队列q release：释放管程的互斥访问权 require：获取管程的互斥访问权 两个成员函数： Wait(lock): 首先numWaiting++，表示有一个等待线程要加入等待队列 把该线程放入q队列，并释放管程的互斥访问权，执行调度（其他线程可能执行），执行完成后，条件满足，再重新获取管程的访问权 Signal： 首先判断是否有等待的线程numWaiting&gt;0才能释放， 然后从等待队列里取一个线程出来，唤醒，然后numWaiting– 用管程实现生产者—消费者问题 记住：生产者-消费者问题中我们需要解觉：两个条件等待和一个互斥访问 首先我们维护一个类： 两个条件变量来实现两个条件等待，一个入口队列的锁lock实现互斥访问，count是管程内部现有资源的数目，初始值为0 12345class BoundedBuffer&#123; Lock lock; int count = 0; condition notFull , notEmpty;&#125; 然后我们生产者和消费者分别对应一个函数deposit和remove（同信号量的实现方法） 首先我们需要进入管程，这时候我们需要再进入时申请入口的锁，退出时释放锁 信号量和管程在这里实现的区别：信号量是先判断是否空/满，再申请互斥访问权，而管程则是先申请再判断，管程是可以这样操作的，因为管程申请了判断如果不符合条件还可以放弃互斥访问权，但是信号量不可以，申请了之后不能放弃，这时有PV操作的工作机制决定的，申请了如果不行会阻塞。 ![Screen Shot 2019-08-15 at 10.01.59 AM](/Users/liutao/Desktop/screenshot/Screen Shot 2019-08-15 at 10.01.59 AM.png) 管程条件变量的释放处理方式 两个线程T1和T2 T1进入等待 当T2的条件满足T1时有两种： Hansen管程：T2执行完后执行T1 Hoare管程：T2的条件变量满足后唤醒T1并放弃互斥访问权，这时候T1执行完后T2再获得互斥访问权继续执行 ![Screen Shot 2019-08-15 at 10.20.02 AM](/Users/liutao/Desktop/screenshot/Screen Shot 2019-08-15 at 10.20.02 AM.png) Hasen：连续执行 比Hoare切换少一次，效率更高，用于真是的OS和Java中 Hoare：原理和逻辑上更符合人类的思维，主要见于教材中 Hasen和Hoare中生产者消费者问题的不同 Hasen中时while Hoare中时if 两个的不同在于，Hasen的while在执行完一次操作后还要继续检查，而if不需要 ![Screen Shot 2019-08-15 at 10.57.40 AM](/Users/liutao/Desktop/screenshot/Screen Shot 2019-08-15 at 10.57.40 AM.png) 二十一讲 文件系统和文件文件系统：负责管理持久数据保存的子系统 提供数据存储和访问功能 组织 检索 读写访问数据 大多数计算机系统都有文件系统 google也是一个文件系统 文件是具有符号名，由字节序列构成的数据项集合 文件系统的基本数据单位 文件名是文件的标识符号 文件系统功能 分配文件磁盘空间 管理文件块（位置和顺序） 管理空闲空间（位置） 分配算法（策略） 管理文件集合 定位：文件及其内容 命名：通过名字找到文件 文件系统结构：文件组织方式 数据可靠和安全 安全：多层次保护数据安全 可靠： 持久保存文件 避免系统崩溃 媒体错误 攻击等 文件属性 文件头：文件系统元数据中的文件信息 文件属性 文件存储位置和顺序 第二讲：文件描述符 文件描述符是指打开的文件在内存当中所维护的相关信息 文件访问模式 进程访问文件数据前必须先“打开”文件 内核跟踪进程打开的所有文件 操作系统为每个进程维护一个打开文件表 文件描述符是打开文件的标识，是操作系统在打开文件表中维护的打开文件状态和信息 具体包括： 文件指针 最近一次读写位置 每个进程分别维护自己的打开文件指针 文件打开计数 当前打开文件的次数 最后一个进程关闭文件时，将其从打开文件表中移除 文件的磁盘位置 缓存数据访问信息 访问权限 每个进程的文件访问模式信息 文件的用户视图和系统视图 用户视图：持久的数据结构 系统访问接口： 字节序列的集合（UNIX） 系统不关系存储在磁盘上的数据结构 操作系统的文件视图 数据块的集合 数据块是逻辑存储单元，而扇区是物理存储单元 块大小可能和扇区大小不一样 进程访问文件最小单位是块——意味着即便是访问一字节，也需要缓存一个数据块（可能4096字节） 进程如何访问文件 顺序访问：按字节依次读取 随机访问： 索引访问：依据数据特征索引 通常操作系统不完整提供索引访问 数据库是建立在索引内容的磁盘访问上 文件的共享和访问控制 访问控制：每个用户能获得哪些文件的那些访问权限 访问模式：读 写 执行 删除 列表等 文件访问控制列表（ACL） &lt;文件实体，权限&gt; UNIX系统中：&lt;用户|组|所有人，读|写|可执行&gt; 用户表示ID 识别用户，表明每个用户所允许的权限及保护模式 用户标识ID：识别用户，表明每个用户所允许的权限及保护模式 组表示ID：允许用户组成组，并指定了组访问权限 语义一致性 规定多进程如何访问共享文件 与同步算法相似 因磁盘IO和网络延迟而设计简单 Unix文件系统（UFS）语义 对打开文件的写入内容立即对其他打开同一文件的其他用户可见 共享文件指针允许多用户同时读取和写入文件 把一致性的问题甩给进程去处理 会话语义 写入内容只有当文件关闭时可见 读写锁： 一些操作系统和文件系统提供该功能 目录 文件别名 文件系统 文件以目录的方式组织起来 ——路径的形式来表示每一个文件 操作系统只允许内核修改目录，来确保映射的完整性 文件别名：两个或者多个文件名关联同一个文件——方便共享，减少存储空间 实现：硬链接：多个文件指向一个文件 软链接：功过存储真是文件的逻辑名称来实现（存储的是真实路径） 删除的时候不一样，硬是删除文件，软是删除别名 文件目录的循环： 不允许子目录的链接，只允许文件的链接 增加链接时，用循环检测算法确定是否合理 名字解析：把逻辑名字转换成物理资源 依据路径名，找到文件系统中的实际文件 遍历目录直到找到目标文件 举例：解析”/bin/ls” 读取根目录的文件头（磁盘固定位置） 读取根目录的数据块，搜索”bin”项 读取bin的文件头 读取bin的数据块，搜索ls项 读取ls的文件头 当前工作目录PWD：每个进程都会指向一个文件目录用于解析文件名 相对路径：不必每次从头开始找 文件系统挂载 文件系统需要先挂载才能访问 文件系统种类 磁盘文件系统 文件存储在存储设备上，比如磁盘 数据库文件系统 文件系统是可被寻址（辨识）的 比如WinFS 日志文件系统 记录文件系统的修改/事件 网络/分布式文件系统 NFS SMB AFS GFS 特殊/虚拟文件系统 针对网络/分布式文件系统 文件可以通过网络被共享 文件位于远程服务器 客户端远程挂载在服务器文件系统 标准系统文件访问转换成远程访问 标准文件共享协议 NFS for UNIX CIFS for WIndows 分布式文件系统挑战： 客户端和客户端上的用户辨别很复杂 例如 NFS不安全 一致性问题 错误处理模式 虚拟文件系统VFS Virtual File System 分层结构 虚拟文件系统，向上提供文件/文件系统API 向下对应各种不同的实际文件系统，提供相应访问接口 目标：针对所有不同文件系统提供抽象 对上提供文件和文件系统接口 内部管理文件和关联的数据结构 高效查询例程 遍历文件系统 与特定文件系统模块的交互 文件系统基本数据结构 文件卷控制块 superblock 文件控制块 inode 目录项 文件缓存和打开文件 数据块按需读入内存 数据块使用后被缓存 两种数据块缓存方式 数据块缓存 页缓存：同一缓存数据块和内存页 文件描述符：每个被打开的文件都有一个文件描述符 文件状态信息“目录项 当前文件指针 文件操作设置等 打开文件表： 每个进程一个进程打开文件表 一个系统级的打开文件表 有文件被打开时，文件卷就不能被卸载（挂载的反义） 一些文件系统提供文件锁，用于协调多进程的文件访问 文件分配如何表示分配给一个文件数据块的位置和顺序 分配方式： 连续分配 链式分配 索引分配 组合到一起来用 链式索引块 多级索引块 空闲空间管理不需要记录顺序，只需要记录分布情况 跟踪记录文件卷中的未分配的数据块 IO 子系统I/O特点： 设备接口类型 同步和异步I/O I/O结构 I/O数据传输 磁盘调度 磁盘缓存 三种常见设备接口类型： 字符设备 如键盘/鼠标 串口等 块设备 如 磁盘驱动器 磁带驱动器 光驱等 网络设备 如：以太网 无线 蓝牙等 访问特征： 格式化报文交换 I/O命令 send/receive 网络报文 通过网络接口支持多种网络协议 同步和异步I/O 阻塞I/O：“Wait” 读数据（read）时，进程将进入等待状态，直到完成数据读出 写数据（write）时，进程将进入等待状态，直到设备完成数据写入处理 ![Screen Shot 2019-08-17 at 4.29.46 PM](/Users/liutao/Desktop/screenshot/Screen Shot 2019-08-17 at 4.29.46 PM.png) 非阻塞I/O：“ Don’t Wait” 命令发出后 我不等待 立即从read或write系统调用返回，返回值为成功传输字节数 read或write的传输字节数可能为0——可能读写不成功后者数据量不一致 ![Screen Shot 2019-08-17 at 4.29.32 PM](/Users/liutao/Desktop/screenshot/Screen Shot 2019-08-17 at 4.29.32 PM.png) 异步I/O：“Tell Me Later” 读数据时，使用指针标记好用户的缓冲区，立即返回；稍后内核将填充缓冲区并通知用户 写数据时，使用指针标记好用户的缓冲区，立即返回；稍后内核讲处理数据并通知用户 驱动程序会等待，但是上层应用程序不会等待，可以去干别的事情 ![Screen Shot 2019-08-17 at 4.29.46 PM](/Users/liutao/Desktop/screenshot/Screen Shot 2019-08-17 at 4.29.46 PM.png) I/O结构 ![Screen Shot 2019-08-17 at 4.38.05 PM](/Users/liutao/Desktop/screenshot/Screen Shot 2019-08-17 at 4.38.05 PM.png) 主板南北桥哈 CPU和设备的连接 设备控制器 CPU和I/O设备间的接口 向CPU提供特殊指令和寄存器 I/O地址 CPU用来控制I/O硬件 内存地址或端口号 I/O指令 内存映射I/O CPU和设备之间的通信方式 轮询 设备中断和DMA 具体讨论一下I/O指令和内存映射I/O I/O指令 通过I/O端口号访问设备寄存器 特殊的cpu指令 内存映射I/O 设备的寄存器/存储被映射到内存物理空间中 通过内粗load/store 完成I/O操作 MMU设置映射 软件-驱动-硬件 最底层是设备，每个设备对应一个设备控制器，然后在上面每个设备对应自己一个驱动 在上面是I/O子系统，然后上边是内核部分 ![Screen Shot 2019-08-18 at 10.40.52 AM](/Users/liutao/Desktop/screenshot/Screen Shot 2019-08-18 at 10.40.52 AM.png) ![Screen Shot 2019-08-18 at 11.10.38 AM](/Users/liutao/Desktop/screenshot/Screen Shot 2019-08-18 at 11.10.38 AM.png) I/O数据传输 程序控制I/O（PIO，Programmed I/O） 通过CPU的in/out或者load/store传输所有数据 特点： 硬件简单 编程容易 消耗的cpu时间和数据量成正比 适用于简单的 小型的设备I/O 直接内存访问（DMA） 设备控制器可直接访问系统总线 控制器直接与内存互相传输数据 特点 设备传输数据不影响CPU 需要CPU参与设置 适用于高吞吐量的I/O exit()和_exit()区别：exit()是对 _exit的封装，exit()会先刷新流然后调用_exit _exit调用后立即返回内核， 当程序执行到exit或_exit时，系统无条件的停止剩下所有操作，清除包括PCB在内的各种数据结构，并终止本进程的运行。 由于Linux的标准函数库中，有一种被称作“缓冲I/O”的操作，其特征就是对应每一个打开的文件，在内存中都有一片缓冲区。每次读文件时，会连续的读出若干条记录，这样在下次读文件时就可以直接从内存的缓冲区读取；同样，每次写文件的时候也仅仅是写入内存的缓冲区，等满足了一定的条件（如达到了一定数量或遇到特定字符等），再将缓冲区中的内容一次性写入文件。这种技术大大增加了文件读写的速度，但也给编程代来了一点儿麻烦。比如有一些数据，认为已经写入了文件，实际上因为没有满足特定的条件，它们还只是保存在缓冲区内，这时用_exit()函数直接将进程关闭，缓冲区的数据就会丢失。因此，要想保证数据的完整性，就一定要使用exit()函数 高性能网络中的IO模型 设计服务端并发模型时，主要有以下两个关键点： 服务器如何管理连接，获取输入数据 服务器如何处理请求 ps：在 Linux 下实现高并发网络编程时都是以 IO 复用模型模式为主。 I/O模型的基本认识 四个概念：同步和异步 阻塞和非阻塞 1）阻塞调用与非阻塞调用； 2）阻塞调用是指调用结果返回之前，当前线程会被挂起，调用线程只有在得到结果之后才会返回； 3）非阻塞调用指在不能立刻得到结果之前，该调用不会阻塞当前线程。 两者的最大区别在于被调用方在收到请求到返回结果之前的这段时间内，调用方是否一直在等待。 阻塞是指调用方一直在等待而且别的事情什么都不做；非阻塞是指调用方先去忙别的事情。 同步：主动问询消息 异步：被通知消息 recvfrom函数：经socket接收数据，视为系统调用 一个输入操作（指输入到socket）包括两个不同的阶段 等待数据准备好 从内核向进程复制数据 对于一个套接字上的输入操作，第一步通常涉及等待数据从网络中到达。当所等待分组到达时，它被复制到内核中的某个缓冲区。第二步就是把数据从内核缓冲区复制到应用进程缓冲区。 程序在系统调用完成上面两步操作（等待和复制），根据 调用方式的阻塞 非阻塞——调用者（应用程序进程） 操作系统处理应用程序请求，处理方式的同步、异步处理的不同——被调用者（操作系统内核？或者说被调用的那个系统调用函数）处理的方式 分为5种I/O模型 I/O模型1:阻塞I/O blocking I/O 应用程序在从调用recvfrom开始到该函数返回有数据包准备好这段时间时阻塞的，也就是等待，recvfrom返回成功后，应用进程开始处理数据报 优点：程序简单，在阻塞等待数据期间进程/线程挂起，基本不会占用 CPU 资源。 缺点： 每个连接需要独立的进程/线程单独处理，当并发请求量大时为了维护程序，内存、线程切换开销较大，这种模型在实际生产中很少使用。 I/O模型2:非阻塞式I/O non-blocking I/O 在非阻塞式 I/O 模型中，应用程序把一个套接口设置为非阻塞，就是告诉内核，当所请求的 I/O 操作无法完成时，不要将进程睡眠。 而是返回一个错误，应用程序基于 I/O 操作函数将不断的轮询数据是否已经准备好，如果没有准备好，继续轮询，直到数据准备好为止。 轮询polling：由CPU定时发出询问，依序询问每一个周边设备是否需要其服务，有即给予服务，服务结束后再问下一个周边，接着不断周而复始 优点：不会阻塞在内核的等待数据过程，每次发起的 I/O 请求可以立即返回，不用阻塞等待，实时性较好。 缺点： ** **轮询将会不断地询问内核，这将占用大量的 CPU 时间，系统资源利用率较低，所以一般 Web 服务器不使用这种 I/O 模型。 I/O模型3: I/O复用模型（I/O multiplexing） 用到Select Poll Epoll函数 这几个函数可以同时阻塞多个 I/O 操作，而且可以同时对多个读操作，多个写操作的 I/O 函数进行检测，直到有数据可读或可写时，才真正调用 I/O 操作函数。 优点：可以基于一个阻塞对象，同时在多个描述符上等待就绪，而不是使用多个线程(每个文件描述符一个线程)，这样可以大大节省系统资源。 缺点：当连接数较少时效率相比多线程+阻塞 I/O 模型效率较低，可能延迟更大，因为单个连接处理需要 2 次系统调用，占用时间会有增加。 I/O模型4 ：信号驱动式I/O模型（signal-driven I/O） 在信号驱动式 I/O 模型中，应用程序使用套接口进行信号驱动 I/O，并安装一个信号处理函数，进程继续运行并不阻塞。 在套接口安装一个信号处理函数 当数据准备好时，进程会收到一个 SIGIO 信号，可以在信号处理函数中调用 I/O 操作函数处理数据。 优点：线程并没有在等待数据时被阻塞，可以提高资源的利用率。 缺点：信号 I/O 在大量 IO 操作时可能会因为信号队列溢出导致没法通知。 信号驱动 I/O 尽管对于处理 UDP 套接字来说有用，即这种信号通知意味着到达一个数据报，或者返回一个异步错误。 但是，对于 TCP 而言，信号驱动的 I/O 方式近乎无用，因为导致这种通知的条件为数众多，每一个来进行判别会消耗很大资源，与前几种方式相比优势尽失。 I/O模型5:异步I/O模型（AIO asynchronous I/O） 由 POSIX 规范定义，应用程序告知内核启动某个操作，并让内核在整个操作（包括将数据从内核拷贝到应用程序的缓冲区）完成后通知应用程序。 这种模型与信号驱动模型的主要区别在于：信号驱动 I/O 是由内核通知应用程序何时启动一个 I/O 操作，而异步 I/O 模型是由内核通知应用程序 I/O 操作何时完成。 这里进程只告诉os我要完成操作，os内核完成后告诉进程，中间不会有进程的recvfrom调用，意味着进程整个过程不会阻塞，效率极高 优点：异步 I/O 能够充分利用 DMA 特性，让 I/O 操作与计算重叠。 缺点：要实现真正的异步 I/O，操作系统需要做大量的工作。目前 Windows 下通过 IOCP 实现了真正的异步 I/O。 而在 Linux 系统下，Linux 2.6才引入，目前 AIO 并不完善，因此在 Linux 下实现高并发网络编程时都是以 IO 复用模型模式为主。 关于一个I/O操作：一个是何时可以启动，另一个是启动后到完成，两个时间段 发起——&gt;等待——&gt;可以启动——&gt;操作——&gt;完成 一个是发起到可以启动的等待时间—— ps：这的等待是等待数据住呗，也就是拷贝到os内核缓冲区 另一个是启动到完成的操作时间 五种I/O模型除了异步I/O模型剩下的都是同步I/O模型 注意：阻塞不会占用cpu，阻塞I/O的开销主要在于进程/线程切换，高并发时，大量的进程/线程切换，会带来大量的开销 非阻塞是轮询但不阻塞，进程会一直占用cpu，直到数据准备好。实时性好，但是浪费cpu资源 所有模型中的recvfrom操作都会阻塞进程/线程，这是该系统调用决定的，针对于前四种 第五种不会调用recvfrom函数，POSIX有其他定义。。但是不完善 more： 针对linux操作系统而言，将最高的1G字节（从虚拟地址0xC0000000到0xFFFFFFFF），供内核使用，称为内核空间，而将较低的3G字节（从虚拟地址0x00000000到0xBFFFFFFF），供各个进程使用，称为用户空间 网络IO的本质是socket的读取，socket在linux系统中被抽象为流，I/O可以理解为是对流的操作。 对于一次I/O操作（以read为例）： step1:数据会先被拷贝到操作系统内核的缓冲区中，——数据到内核空间 step2:然后从操作系统内核缓冲区 拷贝 到 应用程序地址空间——内核空间到用户空间——具体的某一个应用程序进程空间 所以相当于是： step1:等待数据准备，先拷贝到os内核缓冲区 step2:数据拷贝，从内核拷贝到进程地址空间 对于socket流而言： 第一步：通常涉及等待网络上的数据分组到达，然后被复制到内核的某个缓冲区。 第二步：把数据从内核缓冲区复制到应用进程缓冲区。 阻塞：就是被休息，cpu处理其他进程去了。 阻塞I/O：两个阶段全部阻塞，该应用程序不再消费cpu而只是简单等待响应状态 数据接收到os内核缓冲区以及从os内核缓冲区搬运到进程缓冲区 当用户进程调用了recv()/recvfrom()这个系统调用，kernel就开始了IO的第一个阶段：准备数据（对于网络IO来说，很多时候数据在一开始还没有到达。比如，还没有收到一个完整的UDP包。这个时候kernel就要等待足够的数据到来）。这个过程需要等待，也就是说数据被拷贝到操作系统内核的缓冲区中是需要一个过程的。而在用户进程这边，整个进程会被阻塞（当然，是进程自己选择的阻塞）。第二个阶段：当kernel一直等到数据准备好了，它就会将数据从kernel中拷贝到用户内存，然后kernel返回结果，用户进程才解除block的状态，重新运行起来。——也就是kernel返回结果后，进程从阻塞到就绪，再到运行 非阻塞I/O 特点：在等待（数据准备）阶段不阻塞，而是轮询polling 设备是以非阻塞的形式打开的。这意味着 IO 操作不会立即完成，read 操作可能会返回一个错误代码，说明这个命令不能立即满足（EAGAIN 或 EWOULDBLOCK）。 在网络IO时候，非阻塞IO也会进行recvform系统调用，检查数据是否准备好，与阻塞IO不一样，”非阻塞将大的整片时间的阻塞分成N多的小的阻塞, 所以进程不断地有机会 ‘被’ CPU光顾”。 也就是说非阻塞的recvform系统调用调用之后，进程并没有被阻塞，内核马上返回给进程，如果数据还没准备好，此时会返回一个error。进程在返回之后，可以干点别的事情，然后再发起recvform系统调用。重复上面的过程，循环往复的进行recvform系统调用。这个过程通常被称之为轮询。轮询检查内核数据，直到数据准备好，再拷贝数据到进程，进行数据处理。需要注意，拷贝数据整个过程，进程仍然是属于阻塞的状态。如下： 轮询具体实现就是隔一段时间调用recvfrom， 若无数据报准备好，内核立即返回EWOULDBLOCK，这个时候进程会继续轮询，隔段时间调用recvfrom 知道数据报准备好，此时进程调用recvfrom会阻塞，直到kernel返回结果，用户进程才解除block的状态，重新运行起来。——也就是kernel返回结果后，进程从阻塞到就绪，再到运行 当用户进程发出read操作时，如果kernel中的数据还没有准备好，那么它并不会block用户进程，而是立刻返回一个error。从用户进程角度讲，它发起一个read操作后，并不需要等待，而是马上就得到了一个结果。用户进程判断结果是一个error时，它就知道数据还没有准备好，于是它可以再次发送read操作。一旦kernel中的数据准备好了，并且又再次收到了用户进程的system call，那么它马上就将数据拷贝到了用户内存，然后返回。 进程在第一阶段需要不断主动询问 同步非阻塞方式相比同步阻塞方式： 优点：能够在等待任务完成的时间里干其他活了（包括提交其他任务，也就是 “后台” 可以有多个任务在同时执行）。但是也占用了cpu，但是不需要频繁切换进程/线程。 缺点：任务完成的响应延迟增大了，因为每过一段时间才去轮询一次read操作，而任务可能在两次轮询之间的任意时间完成。这会导致整体数据吞吐量的降低。 I/O多路复用 轮询会消耗大量cpu时间，后台” 可能有多个任务在同时进行，人们就想到了循环查询多个任务的完成状态，只要有任何一个任务完成，就去处理它。 而且轮询不是由进程的用户态来做，而是有人帮忙。这就是所谓的“I/O多路复用” select poll和epoll就是做这件事情的——循环查询 epoll会比poll select效率高，，后面会逐步讲解 select调用是内核级别的，select的轮询和非阻塞I/O的轮询去呗在于： select可以等待多个socket，同时对多个I/O端口监听，任何一个socket准备好了，就能返回成功，然后进行系统调用recvfrom，进行第二阶段，这个过程是阻塞的 select或poll调用后，会阻塞进程——因为非阻塞I/O里面是进程进行轮询当然是非阻塞，这里是内核进行轮询，数据好了会告诉进程，进程这段时间阻塞，不占用cpu I/O复用模型会用到select、poll、epoll函数，这几个函数也会使进程阻塞，但是和阻塞I/O所不同的的，这两个函数可以同时阻塞多个I/O操作。而且可以同时对多个读操作，多个写操作的I/O函数进行检测，直到有数据可读或可写时（注意不是全部数据可读或可写），才真正调用I/O操作函数。 对于多路复用，也就是轮询多个socket。多路复用既然可以处理多个IO，也就带来了新的问题，多个IO之间的顺序变得不确定了 最大的好处：单个process可以同时处理多个网络连接I/O 当用户进程调用了select，那么整个进程会被block，而同时，kernel会“监视”所有select负责的socket，当任何一个socket中的数据准备好了，select就会返回。这个时候用户进程再调用read操作，将数据从kernel拷贝到用户进程。 多路复用的特点是通过一种机制一个进程能同时等待IO文件描述符，内核监视这些文件描述符（套接字描述符），其中的任意一个进入读就绪状态，select， poll，epoll函数就可以返回。对于监视的方式，又可以分为 select， poll， epoll三种方式。 相比于blocking I/O，单个连接需要调用两次system call，而blocking I/O只需要一次 在IO multiplexing Model中，实际中，对于每一个socket，一般都设置成为non-blocking，但是，如上图所示，整个用户的process其实是一直被block的。只不过process是被select这个函数block，而不是被socket IO给block。所以IO多路复用是阻塞在select，epoll这样的系统调用之上，而没有阻塞在真正的I/O系统调用如recvfrom之上。注意socket一般设置non-blocking的 对于没有阻塞在recvfrom的理解：如同non-blocking I/O的过程，调用recvfrom不会阻塞，但是在多路复用I/O模型中，由于调用recvfrom的时候数据已经准备好了，所以直接进入第二阶段数据搬迁过程，这个时间段是阻塞的。 在I/O编程过程中，当需要同时处理多个客户端接入请求时，可以利用多线程或者I/O多路复用技术进行处理。I/O多路复用技术通过把多个I/O的阻塞复用到同一个select的阻塞上，从而使得系统在单线程的情况下可以同时处理多个客户端请求 单线程同时处理多个客户端请求——系统开销小，不需要额外创建新的进程/线程也不需要维护 主要应用场景： 服务器需要同时处理多个处于监听状态或者多个连接状态的套接字。 服务器需要同时处理多种网络协议的套接字。 进程在这里调用select之后，处于阻塞等待的状态，所以可以归结为同步模型 从整个IO过程来看，他们都是顺序执行的，因此可以归为同步模型(synchronous)。都是进程主动等待且向内核检查状态。【此句很重要！！！】 高并发程序：一般使用同步非阻塞 而不是 多线程 + 同步阻塞 扯到并发和并行的区别。比如去某部门办事需要依次去几个窗口，办事大厅里的人数就是并发数，而窗口个数就是并行度。也就是说并发数是指同时进行的任务数（如同时服务的 HTTP 请求），而并行数是可以同时工作的物理资源数量（如 CPU 核数）。 并发数：同时进行的任务数 并行数：可以同时工作的物理资源数 通过合理调度任务的不同阶段，并发数可以远远大于并行度，这就是区区几个 CPU 可以支持上万个用户并发请求的奥秘。在这种高并发的情况下，为每个任务（用户请求）创建一个进程或线程的开销非常大。而同步非阻塞方式可以把多个 IO 请求丢到后台去，这就可以在一个进程里服务大量的并发 IO 请求 同步是需要主动等待消息通知，而异步则是被动接收消息通知，通过回调、通知、状态等方式来被动获取消息 IO多路复用在阻塞到select阶段时，用户进程是主动等待并调用select函数获取数据就绪状态消息，并且其进程状态为阻塞。所以，把IO多路复用归为同步阻塞模式。 信号驱动式I/O 信号驱动式I/O：首先我们允许Socket进行信号驱动IO,并安装一个信号处理函数，进程继续运行并不阻塞。当数据准备好时，进程会收到一个SIGIO信号，可以在信号处理函数中调用I/O操作函数处理数据。 第二阶段还是阻塞的 ps 在某些地方大家会把立即返回和不立即返回混淆的原因，是因为如果不立即返回就会阻塞block。。这是程序/操作系统机制？？，返回后才能根据具体的返回做下一步 ——上述是自己感悟。。 异步I/O 非阻塞 最大特点：两个阶段都是非阻塞的 相对于同步IO，异步IO不是顺序执行。用户进程进行aio_read系统调用之后，无论内核数据是否准备好，都会直接返回给用户进程，然后用户态进程可以去做别的事情。等到socket数据准备好了，内核直接复制数据给进程，然后从内核向进程发送通知。IO两个阶段，进程都是非阻塞的。 最后全部完成后，操作系统向进程发送通知。。 用户进程发起aio_read操作之后，立刻就可以开始去做其它的事。而另一方面，从kernel的角度，当它收到到一个asynchronous read之后，首先它会立刻返回，所以不会对用户进程产生任何block。然后，kernel会等待数据准备完成，然后将数据拷贝到用户内存，当这一切都完成之后，kernel会给用户进程发送一个signal或执行一个基于线程的回调函数来完成这次 IO 处理过程，告诉它read操作完成了。 这里就是另外的系统调用了，不再用recvfrom 在 Linux 中，通知的方式是 “信号”： 如果这个进程正在用户态忙着做别的事（例如在计算两个矩阵的乘积），那就强行打断之，调用事先注册的信号处理函数，这个函数可以决定何时以及如何处理这个异步任务。由于信号处理函数是突然闯进来的，因此跟中断处理程序一样，有很多事情是不能做的，因此保险起见，一般是把事件 “登记” 一下放进队列，然后返回该进程原来在做的事。 如果这个进程正在内核态忙着做别的事，例如以同步阻塞方式读写磁盘，那就只好把这个通知挂起来了，等到内核态的事情忙完了，快要回到用户态的时候，再触发信号通知。 如果这个进程现在被挂起了，例如无事可做 sleep 了，那就把这个进程唤醒，下次有 CPU 空闲的时候，就会调度到这个进程，触发信号通知。 关于 select poll epoll 先谈一下wakeup和callback机制，I/O多路复用机制存在的本质 Linux通过socket睡眠队列来管理所有等待socket的某个事件的process，同时通过wakeup机制来异步唤醒整个睡眠队列上等待事件的process，通知process相关事件发生。 socket的事件发生的时候，其会顺序遍历socket睡眠队列上的每个process节点，调用每个process节点挂载的callback函数。在遍历的过程中，如果遇到某个节点是排他的，那么就终止遍历，总体上会涉及两大逻辑：（1）睡眠等待逻辑；（2）唤醒逻辑。 睡眠等待逻辑：涉及select poll epoll_wait的阻塞等待逻辑 123[1]select、poll、epoll_wait陷入内核，判断监控的socket是否有关心的事件发生了，如果没，则为当前process构建一个wait_entry节点，然后插入到监控socket的sleep_list[2]进入循环的schedule直到关心的事件发生了[3]关心的事件发生后，将当前process的wait_entry节点从socket的sleep_list中删除。 唤醒逻辑 123[1]socket的事件发生了，然后socket顺序遍历其睡眠队列，依次调用每个wait_entry节点的callback函数[2]直到完成队列的遍历或遇到某个wait_entry节点是排他的才停止。[3]一般情况下callback包含两个逻辑：1.wait_entry自定义的私有逻辑；2.唤醒的公共逻辑，主要用于将该wait_entry的process放入CPU的就绪队列，让CPU随后可以调度其执行。 注意：每个进程可以监控多个socket，而一个socket也可以被多个进程监控，每个socket都有一个sleep_list，里面是多个进程的wait_entry节点 具体逻辑见上 select——1024在一个高性能的网络服务上，大多情况下一个服务进程(线程)process需要同时处理多个socket，我们需要公平对待所有socket，对于read而言，那个socket有数据可读，process就去读取该socket的数据来处理。于是对于read，一个朴素的需求就是关心的N个socket是否有数据”可读”，也就是我们期待”可读”事件的通知，而不是盲目地对每个socket调用recv/recvfrom来尝试接收数据。我们应该block在等待事件的发生上，这个事件简单点就是”关心的N个socket中一个或多个socket有数据可读了”，当block解除的时候，就意味着，我们一定可以找到一个或多个socket上有可读的数据。另一方面，根据上面的socket wakeup callback机制，我们不知道什么时候，哪个socket会有读事件发生，于是，process需要同时插入到这N个socket的sleep_list上 等待任意一个socket可读事件发生而被唤醒，当process被唤醒的时候，其callback里面应该有个逻辑去检查具体那些socket可读了。 注意进程在系统调用select之后会阻塞 select的多路复用逻辑：select为每个socket引入一个poll逻辑，该poll逻辑用于收集socket发生的事件 poll逻辑就是轮询，每个socket不断（有间隔时间）去问询事件是否准备好了。 123456789poll()&#123; //其他逻辑 if (recieve queque is not empty) &#123; sk_event |= POLL_IN； &#125; //其他逻辑&#125; select的逻辑： select的函数原型：5个参数，后面4个参数都是in/out类型(值可能会被修改返回) 1int select(int nfds, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout); 当用户process调用select的时候，select会将需要监控的readfds集合拷贝到内核空间（假设监控的仅仅是socket可读），然后遍历自己监控的socket sk，挨个调用sk的poll逻辑以便检查该sk是否有可读事件，遍历完所有的sk后，如果没有任何一个sk可读，那么select会调用schedule_timeout进入schedule循环，使得process进入睡眠。如果在timeout时间内某个sk上有数据可读了，或者等待timeout了，则调用select的process会被唤醒，接下来select就是遍历监控的sk集合，挨个收集可读事件并返回给用户了（这里一个事件发生，还要全部遍历一遍），相应的伪码如下： 123456for (sk in readfds)&#123; sk_event.evt = sk.poll(); sk_event.sk = sk; ret_event_for_process;&#125; select存在两个问题： 这里的fds是文件描述符 1234[1] 被监控的fds需要从用户空间拷贝到内核空间 为了减少数据拷贝带来的性能损坏，内核对被监控的fds集合大小做了限制，并且这个是通过宏控制的，大小不可改变(限制为1024)。[2] 被监控的fds集合中，只要有一个有数据可读，整个socket集合就会被遍历一次调用sk的poll函数收集可读事件 由于当初的需求是朴素，仅仅关心是否有数据可读这样一个事件，当事件通知来的时候，由于数据的到来是异步的，我们不知道事件来的时候，有多少个被监控的socket有数据可读了，于是，只能挨个遍历每个socket来收集可读事件。 有三个问题需要解决： （1）被监控的fds集合限制为1024，1024太小了，我们希望能够有个比较大的可监控fds集合 （2）fds集合需要从用户空间拷贝到内核空间的问题，我们希望不需要拷贝 （3）当被监控的fds中某些有数据可读的时候，我们希望通知更加精细一点，就是我们希望能够从通知中得到有可读事件的fds列表，而不是需要遍历整个fds来收集。 poll——鸡肋上面select的三个问题，第一个是用法限制，2和3则是性能问题 poll只解决了1024的限制问题 下面是poll的函数原型，poll改变了fds集合的描述方式，使用了pollfd结构而不是select的fd_set结构，使得poll支持的fds集合限制远大于select的1024。poll虽然解决了fds集合大小1024的限制问题，但是，它并没改变大量描述符数组被整体复制于用户态和内核态的地址空间之间，以及个别描述符就绪触发整体描述符集合的遍历的低效问题。poll随着监控的socket集合的增加性能线性下降，poll不适合用于大并发场景。 1int poll(struct pollfd *fds, nfds_t nfds, int timeout); epoll——终极武功计算机行业中，有两种解决问题的思想： cs领域的任何问题，都可以通过添加一个中间层来解决 变集中（中央）处理为分散（分布式）处理 1. fds集合拷贝问题的解决 I/O多路复用，必须做两件事 1）准备好**需要监控的fds集合 2）探测并返回fds集合中哪些fd刻度了。 细看select或poll的函数原型，我们会发现，每次调用select或poll都在重复地准备(集中处理)整个需要监控的fds集合。然而对于频繁调用的select或poll而言，fds集合的变化频率要低得多，我们没必要每次都重新准备(集中处理)整个fds集合。 于是，epoll引入了epoll_ctl系统调用，将高频调用的epoll_wait和低频的epoll_ctl隔离开。同时，epoll_ctl通过(EPOLL_CTL_ADD、EPOLL_CTL_MOD、EPOLL_CTL_DEL)三个操作来分散对需要监控的fds集合的修改，做到了有变化才变更，将select或poll高频、大块内存拷贝(集中处理)变成epoll_ctl的低频、小块内存的拷贝(分散处理)，避免了大量的内存拷贝。同时，对于高频epoll_wait的可读就绪的fd集合返回的拷贝问题，epoll通过内核与用户空间mmap(内存映射)同一块内存来解决。mmap将用户空间的一块地址和内核空间的一块地址同时映射到相同的一块物理内存地址（不管是用户空间还是内核空间都是虚拟地址，最终要通过地址映射映射到物理地址），使得这块物理内存对内核和对用户均可见，减少用户态和内核态之间的数据交换。 另外，epoll通过epoll_ctl来对监控的fds集合来进行增、删、改，那么必须涉及到fd的快速查找问题，于是，一个低时间复杂度的增、删、改、查的数据结构来组织被监控的fds集合是必不可少的了。在linux 2.6.8之前的内核，epoll使用hash来组织fds集合，于是在创建epoll fd的时候，epoll需要初始化hash的大小。于是epoll_create(int size)有一个参数size，以便内核根据size的大小来分配hash的大小。在linux 2.6.8以后的内核中，epoll使用红黑树来组织监控的fds集合，于是epoll_create(int size)的参数size实际上已经没有意义了。 2 按需遍历就绪的fds集合 通过上面的socket的睡眠队列唤醒逻辑我们知道，socket唤醒睡眠在其睡眠队列的wait_entry(process)的时候会调用wait_entry的回调函数callback，并且，我们可以在callback中做任何事情。为了做到只遍历就绪的fd，我们需要有个地方来组织那些已经就绪的fd。为此，epoll引入了一个中间层，一个双向链表(ready_list)，一个单独的睡眠队列(single_epoll_wait_list)，并且，与select或poll不同的是，epoll的process不需要同时插入到多路复用的socket集合的所有睡眠队列中，相反process只是插入到中间层的epoll的单独睡眠队列中，process睡眠在epoll的单独队列上，等待事件的发生。 同时，引入一个中间的wait_entry_sk，它与某个socket sk密切相关，wait_entry_sk睡眠在sk的睡眠队列上，其callback函数逻辑是将当前sk排入到epoll的ready_list中，并唤醒epoll的single_epoll_wait_list。 而single_epoll_wait_list上睡眠的process的回调函数就明朗了：遍历ready_list上的所有sk，挨个调用sk的poll函数收集事件，然后唤醒process从epoll_wait返回。 引入两个： 一个是ready_list ，当某个socket事件到达时， 同时，引入一个中间的wait_entry_sk，它与某个socket sk密切相关，wait_entry_sk睡眠在sk的睡眠队列上，其callback函数逻辑是将当前sk排入到epoll的ready_list中，并唤醒epoll的single_epoll_wait_list。而single_epoll_wait_list上睡眠的process的回调函数就明朗了：遍历ready_list上的所有sk，挨个调用sk的poll函数收集事件，然后唤醒process从epoll_wait返回 也就是主要是有一个ready_list在socket事件到达后会有call_back的逻辑把当前sk（也就是socket事件到达的），放到ready_list中 那么后续唤醒single_epoll_wait_list上的睡眠的process的回调函数 只会爱个调用ready_list上的sk，挨个调用sk的poll函数收集事件，然后唤醒process从epoll_wait返回 简单一句话，就是通过callback逻辑 维护了一个ready_list，这个list中保存了当前事件到达的socket，后面我们只需要遍历这个ready_list上的socket，然后返回给用户就可以了 于是，整个过来可以分为以下几个逻辑： （1）epoll_ctl EPOLL_CTL_ADD逻辑 12[1] 构建睡眠实体wait_entry_sk，将当前socket sk关联给wait_entry_sk，并设置wait_entry_sk的回调函数为epoll_callback_sk[2] 将wait_entry_sk排入当前socket sk的睡眠队列上 回调函数epoll_callback_sk的逻辑如下： 12[1] 将之前关联的sk排入epoll的ready_list[2] 然后唤醒epoll的单独睡眠队列single_epoll_wait_list （2）epoll_wait逻辑 123[1] 构建睡眠实体wait_entry_proc，将当前process关联给wait_entry_proc，并设置回调函数为epoll_callback_proc[2] 判断epoll的ready_list是否为空，如果为空，则将wait_entry_proc排入epoll的single_epoll_wait_list中，随后进入schedule循环，这会导致调用epoll_wait的process睡眠。[3] wait_entry_proc被事件唤醒或超时醒来，wait_entry_proc将被从single_epoll_wait_list移除掉，然后wait_entry_proc执行回调函数epoll_callback_proc 回调函数epoll_callback_proc的逻辑如下： 12[1] 遍历epoll的ready_list，挨个调用每个sk的poll逻辑收集发生的事件，对于监控可读事件而已，ready_list上的每个sk都是有数据可读的，这里的遍历必要的(不同于select/poll的遍历，它不管有没数据可读都需要遍历一些来判断，这样就做了很多无用功。)[2] 将每个sk收集到的事件，通过epoll_wait传入的events数组回传并唤醒相应的process。 （3）epoll唤醒逻辑 整个epoll的协议栈唤醒逻辑如下(对于可读事件而言)： 123456[1] 协议数据包到达网卡并被排入socket sk的接收队列[2] 睡眠在sk的睡眠队列wait_entry被唤醒，wait_entry_sk的回调函数epoll_callback_sk被执行[3] epoll_callback_sk将当前sk插入epoll的ready_list中[4] 唤醒睡眠在epoll的单独睡眠队列single_epoll_wait_list的wait_entry，wait_entry_proc被唤醒执行回调函数epoll_callback_proc[5] 遍历epoll的ready_list，挨个调用每个sk的poll逻辑收集发生的事件[6] 将每个sk收集到的事件，通过epoll_wait传入的events数组回传并唤醒相应的process。 epoll巧妙的引入一个中间层解决了大量监控socket的无效遍历问题。细心的同学会发现，epoll在中间层上为每个监控的socket准备了一个单独的回调函数epoll_callback_sk，而对于select/poll，所有的socket都公用一个相同的回调函数。正是这个单独的回调epoll_callback_sk使得每个socket都能单独处理自身，当自己就绪的时候将自身socket挂入epoll的ready_list。同时，epoll引入了一个睡眠队列single_epoll_wait_list，分割了两类睡眠等待。process不再睡眠在所有的socket的睡眠队列上，而是睡眠在epoll的睡眠队列上，在等待”任意一个socket可读就绪”事件。而中间wait_entry_sk则代替process睡眠在具体的socket上，当socket就绪的时候，它就可以处理自身了。 5.3 ET(Edge Triggered 边沿触发) vs LT(Level Triggered 水平触发)5.3.1 ET vs LT - 概念 说到Epoll就不能不说说Epoll事件的两种模式了，下面是两个模式的基本概念 Edge Triggered (ET) 边沿触发 .socket的接收缓冲区状态变化时触发读事件，即空的接收缓冲区刚接收到数据时触发读事件 .socket的发送缓冲区状态变化时触发写事件，即满的缓冲区刚空出空间时触发读事件 仅在缓冲区状态变化时触发事件，比如数据缓冲去从无到有的时候(不可读-可读) Level Triggered (LT) 水平触发 .socket接收缓冲区不为空，有数据可读，则读事件一直触发 .socket发送缓冲区不满可以继续写入数据，则写事件一直触发 符合思维习惯，epoll_wait返回的事件就是socket的状态 通常情况下，大家都认为ET模式更为高效，实际上是不是呢？下面我们来说说两种模式的本质： 我们来回顾一下，5.2节（3）epoll唤醒逻辑 的第五个步骤 1[5] 遍历epoll的ready_list，挨个调用每个sk的poll逻辑收集发生的事件 大家是不是有个疑问呢：挂在ready_list上的sk什么时候会被移除掉呢？其实，sk从ready_list移除的时机正是区分两种事件模式的本质。因为，通过上面的介绍，我们知道ready_list是否为空是epoll_wait是否返回的条件。于是，在两种事件模式下，步骤5如下： 对于Edge Triggered (ET) 边沿触发： 1[5] 遍历epoll的ready_list，将sk从ready_list中移除，然后调用该sk的poll逻辑收集发生的事件 对于Level Triggered (LT) 水平触发： 12[5.1] 遍历epoll的ready_list，将sk从ready_list中移除，然后调用该sk的poll逻辑收集发生的事件[5.2] 如果该sk的poll函数返回了关心的事件(对于可读事件来说，就是POLL_IN事件)，那么该sk被重新加入到epoll的ready_list中。 对于可读事件而言，在ET模式下，如果某个socket有新的数据到达，那么该sk就会被排入epoll的ready_list，从而epoll_wait就一定能收到可读事件的通知(调用sk的poll逻辑一定能收集到可读事件)。于是，我们通常理解的缓冲区状态变化(从无到有)的理解是不准确的，准确的理解应该是是否有新的数据达到缓冲区。 而在LT模式下，某个sk被探测到有数据可读，那么该sk会被重新加入到read_list，那么在该sk的数据被全部取走前，下次调用epoll_wait就一定能够收到该sk的可读事件(调用sk的poll逻辑一定能收集到可读事件)，从而epoll_wait就能返回。 5.3.2 ET vs LT - 性能 通过上面的概念介绍，我们知道对于可读事件而言，LT比ET多了两个操作：(1)对ready_list的遍历的时候，对于收集到可读事件的sk会重新放入ready_list；(2)下次epoll_wait的时候会再次遍历上次重新放入的sk，如果sk本身没有数据可读了，那么这次遍历就变得多余了。 在服务端有海量活跃socket的时候，LT模式下，epoll_wait返回的时候，会有海量的socket sk重新放入ready_list。如果，用户在第一次epoll_wait返回的时候，将有数据的socket都处理掉了，那么下次epoll_wait的时候，上次epoll_wait重新入ready_list的sk被再次遍历就有点多余，这个时候LT确实会带来一些性能损失。然而，实际上会存在很多多余的遍历么？ 先不说第一次epoll_wait返回的时候，用户进程能否都将有数据返回的socket处理掉。在用户处理的过程中，如果该socket有新的数据上来，那么协议栈发现sk已经在ready_list中了，那么就不需要再次放入ready_list，也就是在LT模式下，对该sk的再次遍历不是多余的，是有效的。同时，我们回归epoll高效的场景在于，服务器有海量socket，但是活跃socket较少的情况下才会体现出epoll的高效、高性能。因此，在实际的应用场合，绝大多数情况下，ET模式在性能上并不会比LT模式具有压倒性的优势，至少，目前还没有实际应用场合的测试表面ET比LT性能更好。 5.3.3 ET vs LT - 复杂度 我们知道，对于可读事件而言，在阻塞模式下，是无法识别队列空的事件的，并且，事件通知机制，仅仅是通知有数据，并不会通知有多少数据。于是，在阻塞模式下，在epoll_wait返回的时候，我们对某个socket_fd调用recv或read读取并返回了一些数据的时候，我们不能再次直接调用recv或read，因为，如果socket_fd已经无数据可读的时候，进程就会阻塞在该socket_fd的recv或read调用上，这样就影响了IO多路复用的逻辑(我们希望是阻塞在所有被监控socket的epoll_wait调用上，而不是单独某个socket_fd上)，造成其他socket饿死，即使有数据来了，也无法处理。 接下来，我们只能再次调用epoll_wait来探测一些socket_fd，看是否还有数据可读。在LT模式下，如果socket_fd还有数据可读，那么epoll_wait就一定能够返回，接着，我们就可以对该socket_fd调用recv或read读取数据。然而，在ET模式下，尽管socket_fd还是数据可读，但是如果没有新的数据上来，那么epoll_wait是不会通知可读事件的。这个时候，epoll_wait阻塞住了，这下子坑爹了，明明有数据你不处理，非要等新的数据来了在处理，那么我们就死扛咯，看谁先忍不住。 等等，在阻塞模式下，不是不能用ET的么？是的，正是因为有这样的缺点，ET强制需要在非阻塞模式下使用。在ET模式下，epoll_wait返回socket_fd有数据可读，我们必须要读完所有数据才能离开。因为，如果不读完，epoll不会在通知你了，虽然有新的数据到来的时候，会再次通知，但是我们并不知道新数据会不会来，以及什么时候会来。由于在阻塞模式下，我们是无法通过recv/read来探测空数据事件，于是，我们必须采用非阻塞模式，一直read直到EAGAIN。因此，ET要求socket_fd非阻塞也就不难理解了。 另外，epoll_wait原本的语意是：监控并探测socket是否有数据可读(对于读事件而言)。LT模式保留了其原本的语意，只要socket还有数据可读，它就能不断反馈，于是，我们想什么时候读取处理都可以，我们永远有再次poll的机会去探测是否有数据可以处理，这样带来了编程上的很大方便，不容易死锁造成某些socket饿死。相反，ET模式修改了epoll_wait原本的语意，变成了：监控并探测socket是否有新的数据可读。 于是，在epoll_wait返回socket_fd可读的时候，我们需要小心处理，要不然会造成死锁和socket饿死现象。典型如listen_fd返回可读的时候，我们需要不断的accept直到EAGAIN。假设同时有三个请求到达，epoll_wait返回listen_fd可读，这个时候，如果仅仅accept一次拿走一个请求去处理，那么就会留下两个请求，如果这个时候一直没有新的请求到达，那么再次调用epoll_wait是不会通知listen_fd可读的，于是epoll_wait只能睡眠到超时才返回，遗留下来的两个请求一直得不到处理，处于饿死状态。 5.3.4 ET vs LT - 总结 最后总结一下，ET和LT模式下epoll_wait返回的条件 ET - 对于读操作 [1] 当接收缓冲buffer内待读数据增加的时候时候(由空变为不空的时候、或者有新的数据进入缓冲buffer) [2] 调用epoll_ctl(EPOLL_CTL_MOD)来改变socket_fd的监控事件，也就是重新mod socket_fd的EPOLLIN事件，并且接收缓冲buffer内还有数据没读取。(这里不能是EPOLL_CTL_ADD的原因是，epoll不允许重复ADD的，除非先DEL了，再ADD) 因为epoll_ctl(ADD或MOD)会调用sk的poll逻辑来检查是否有关心的事件，如果有，就会将该sk加入到epoll的ready_list中，下次调用epoll_wait的时候，就会遍历到该sk，然后会重新收集到关心的事件返回。 ET - 对于写操作 [1] 发送缓冲buffer内待发送的数据减少的时候(由满状态变为不满状态的时候、或者有部分数据被发出去的时候) [2] 调用epoll_ctl(EPOLL_CTL_MOD)来改变socket_fd的监控事件，也就是重新mod socket_fd的EPOLLOUT事件，并且发送缓冲buffer还没满的时候。 LT - 对于读操作 LT就简单多了，唯一的条件就是，接收缓冲buffer内有可读数据的时候 LT - 对于写操作 LT就简单多了，唯一的条件就是，发送缓冲buffer还没满的时候 在绝大多少情况下，ET模式并不会比LT模式更为高效，同时，ET模式带来了不好理解的语意，这样容易造成编程上面的复杂逻辑和坑点。因此，建议还是采用LT模式来编程更为舒爽。 ps：回调函数 当程序跑起来时，一般情况下，应用程序（application program）会时常通过API调用库里所预先备好的函数。但是有些库函数（library function）却要求应用先传给它一个函数，好在合适的时候调用，以完成目标任务。这个被传入的、后又被调用的函数就称为回调函数（callback function）。 打个比方，有一家旅馆提供叫醒服务，但是要求旅客自己决定叫醒的方法。可以是打客房电话，也可以是派服务员去敲门，睡得死怕耽误事的，还可以要求往自己头上浇盆水。这里，“叫醒”这个行为是旅馆提供的，相当于库函数，但是叫醒的方式是由旅客决定并告诉旅馆的，也就是回调函数。而旅客告诉旅馆怎么叫醒自己的动作，也就是把回调函数传入库函数的动作，称为登记回调函数（to register a callback function） 可以看到，回调函数通常和应用处于同一抽象层（因为传入什么样的回调函数是在应用级别决定的）。而回调就成了一个高层调用底层，底层再回过头来调用高层的过程。（我认为）这应该是回调最早的应用之处，也是其得名如此的原因 网络编程中的线程模型 具体选择线程还是进程，更多是与平台及编程语言相关 C 语言使用线程和进程都可以(例如 Nginx 使用进程，Memcached 使用线程)，Java 语言一般使用线程(例如 Netty)， 线程模型1:传统阻塞I/O服务模型 特点 采用阻塞式I/O模型获取输入数据 每个连接都需要独立的线程来完成数据输入，业务处理，数据返回的完整操作 存在问题 并发数较大时，需要创建大量线程，系统资源占用较大 连接建立后，如果当前线程没有数据可读，线程就阻塞在Read操作上，造成线程资源浪费 线程模型2:Reactor模式针对上面传统阻塞I/O服务模型的两个缺点，有如下解决方案 基于I/O复用模型 基于线程池复用线程资源 I/O复用结合线程池，这就是Reactor模式的基本设计思想 dispatch：调度 Reactor 模式，是指通过一个或多个输入同时传递给服务处理器的服务请求的事件驱动处理模式。 服务端程序处理传入多路请求，并将它们同步分派给请求对应的处理线程，Reactor 模式也叫 Dispatcher 模式。 即 I/O复用监听事件，收到事件后分发（Dispatch给某进程），是编写高性能网络服务器的必备技术之一 两个部分：监听 &amp; 分发 Reactor模式中有两个关键组成： 1）Reactor：Reactor 在一个单独的线程中运行，负责监听和分发事件，分发给适当的处理程序来对 IO 事件做出反应。 它就像公司的电话接线员，它接听来自客户的电话并将线路转移到适当的联系人； 2）Handlers：处理程序执行 I/O 事件要完成的实际事件，类似于客户想要与之交谈的公司中的实际官员。Reactor 通过调度适当的处理程序来响应 I/O 事件，处理程序执行非阻塞操作。 根据 Reactor 的数量和处理资源池线程的数量不同，有 3 种典型的实现： 单Reactor单线程 单Reactor多线程 主从Reactor多线程 单Reactor 单线程 1）Reactor 对象通过 Select 监控客户端请求事件，收到事件后通过 Dispatch 进行分发； 2）如果是建立连接请求事件，则由 Acceptor 通过 Accept 处理连接请求，然后创建一个 Handler 对象处理连接完成后的后续业务处理； 3）如果不是建立连接事件，则 Reactor 会分发调用连接对应的 Handler 来响应； 4）Handler 会完成 Read→业务处理→Send 的完整业务流程。 一个handler对应一个连接的处理，但同一时刻只能有一个handler处理（单线程模式） 优点：模型简单，没有多线程、进程通信、竞争的问题，全部都在一个线程中完成。缺点：性能问题，只有一个线程，无法完全发挥多核 CPU 的性能。Handler 在处理某个连接上的业务时，整个进程无法处理其他连接事件，很容易导致性能瓶颈。 可靠性问题，线程意外跑飞，或者进入死循环，会导致整个系统通信模块不可用，不能接收和处理外部消息，造成节点故障。 使用场景：客户端的数量有限，业务处理非常快速，比如 Redis，业务处理的时间复杂度 O(1)。 单Reactor多线程 1）Reactor 对象通过 Select 监控客户端请求事件，收到事件后通过 Dispatch 进行分发； 2）如果是建立连接请求事件，则由 Acceptor 通过 Accept 处理连接请求，然后创建一个 Handler 对象处理连接完成后续的各种事件； 3）如果不是建立连接事件，则 Reactor 会分发调用连接对应的 Handler 来响应； 4）Handler 只负责响应事件，不做具体业务处理，通过 Read 读取数据后，会分发给后面的 Worker 线程池进行业务处理； 5）Worker 线程池会分配独立的线程完成真正的业务处理，然后将响应结果发给 Handler 进行处理； 6）Handler 收到响应结果后通过 Send 将响应结果返回给 Client。 优点：可以充分利用多核 CPU 的处理能力。缺点：多线程数据共享和访问比较复杂；Reactor 承担所有事件的监听和响应，在单线程中运行，高并发场景下容易成为性能瓶颈。 主从Reactor多线程 针对单 Reactor 多线程模型中，Reactor 在单线程中运行，高并发场景下容易成为性能瓶颈，可以让 Reactor 在多线程中运行。 方案说明： 1）Reactor 主线程 MainReactor 对象通过 Select 监控建立连接事件，收到事件后通过 Acceptor 接收，处理建立连接事件； 2）Acceptor 处理建立连接事件后，MainReactor 将连接分配 Reactor 子线程给 SubReactor 进行处理； 3）SubReactor 将连接加入连接队列进行监听，并创建一个 Handler 用于处理各种连接事件； 4）当有新的事件发生时，SubReactor 会调用连接对应的 Handler 进行响应； 5）Handler 通过 Read 读取数据后，会分发给后面的 Worker 线程池进行业务处理； 6）Worker 线程池会分配独立的线程完成真正的业务处理，如何将响应结果发给 Handler 进行处理； 7）Handler 收到响应结果后通过 Send 将响应结果返回给 Client。 优点：父线程与子线程的数据交互简单职责明确，父线程只需要接收新连接，子线程完成后续的业务处理。 父线程与子线程的数据交互简单，Reactor 主线程只需要把新连接传给子线程，子线程无需返回数据。 这种模型在许多项目中广泛使用，包括 Nginx 主从 Reactor 多进程模型，Memcached 主从多线程，Netty 主从多线程模型的支持。 小结3 种模式可以用个比喻来理解：（餐厅常常雇佣接待员负责迎接顾客，当顾客入坐后，侍应生专门为这张桌子服务） 1）单 Reactor 单线程，接待员和侍应生是同一个人，全程为顾客服务； 2）单 Reactor 多线程，1 个接待员，多个侍应生，接待员只负责接待； 3）主从 Reactor 多线程，多个接待员，多个侍应生。 Reactor 模式具有如下的优点： 1）响应快，不必为单个同步时间所阻塞，虽然 Reactor 本身依然是同步的； 2）编程相对简单，可以最大程度的避免复杂的多线程及同步问题，并且避免了多线程/进程的切换开销； 3）可扩展性，可以方便的通过增加 Reactor 实例个数来充分利用 CPU 资源； 4）可复用性，Reactor 模型本身与具体事件处理逻辑无关，具有很高的复用性。 内存碎片 分为内部碎片和外部碎片 这里的内部和外部指的是进程的内部和外部 内部碎片是由于采用固定大小的内存分区，当一个进程不能完全使用分给它的固定内存区域时就产生了内部碎片，通常内部碎片难以完全避免； 外部碎片是由于某些未分配的连续内存区域太小，以至于不能满足任意进程的内存分配请求，从而不能被进程利用的内存区域。 段页式虚拟存储系统： 段：是分配给进程的一段空间 页：组成段的部分 段页式系统中：页可以不连续（通过页表维护），所以避免了外部碎片 但是一个页中（最后一页）也有用不到的空间，称为内部碎片 针对内存碎片：有两种方法 伙伴算法 和 高速缓存slab层 页的大小固定且由系统确定, 将逻辑地址划分为页号和页内地址是由机器硬件实现的. 而段的长度却不固定, 决定于用户所编写的程序, 通常由编译程序在对源程序进行编译时根据信息的性质来划分. 分页的作业地址空间是一维的. 分段的地址空间是二维的. 作业的最后一页中仍有部分空间被浪费掉了. 由此可知, 页式虚拟存储系统中存在内碎片. linux kernel会把物理内存划分成一个个page进行管理， 但是如果对小于page的内存分配，直接分配一个page是一个很大的浪费。linux kernel通过slab实现对小于page大小的内存分配。slab把page按2的m次幂进行划分一个个字节块，当kmalloc申请内存时，通过slab管理器返回需要满足申请大小的最小空闲内存块。 所以综上，linux kernel的内存管理是个二层分层系统，从下往上为： 第一层：全部物理内存，管理器为伙伴系统，最小管理单位为page 第二层：slab page，管理器为slab/slub，最小管理单位为2的m次幂的字节块 伙伴系统解决外碎片 所有的空闲页分组为11个链表，每个链表包含1 2 4 8 16 32 64 128 256 512 1024个连续的页。1024个页框的最大请求对应着4MB大小的连续RAM（每页大小为4KB）。 每个块的第一个页框的物理地址是该块大小的整数倍，例如，大小为16个页框的块，其起始地址是16*2^12的倍数 我们通过一个例子来说明伙伴算法的工作原理，假设现在要请求一个256个页框的块（1MB），算法步骤如下：• 在256个页框的链表中检查是否有一个空闲快，如果没有，查找下一个更大的块，如果有，请求满足。• 在512个页框的链表中检查是否有一个空闲块，如果有，把512个页框的空闲块分为两份，第一份用于满足请求，第二份链接到256个页框的链表中。如果没有空闲块，继续寻找下一个更大的块。下图比较形象地描述了该过程。 以上过程的逆过程，就是页框块的释放过程，也是该算法名字的由来，内核试图把大小为B的一对空闲伙伴块合并为一个2B的单独块，满足以下条件的两个块称之为伙伴： 两个块具有相同的大小 他们的物理地址是连续的 第一块的第一个页框的物理地址是2 * B * 2^12 该算法是递归的，如果它成功合并了B，就会试图去合并2B，以再次试图形成更大的块。 高速缓存Slab层针对经常分配并且释放的对象，如进程描述符，一般比较小，如果用伙伴系统进行分配和释放，不仅会造成大量内存碎片，而且处理速度也太慢 而slab分配器是基于对象进行管理的，相同类型的对象归为一类(如进程描述符就是一类)，每当要申请这样一个对象，slab分配器就从一个slab列表中分配一个这样大小的单元出去，而当要释放时，将其重新保存在该列表中，而不是直接返回给伙伴系统，从而避免这些内碎片。slab分配器并不丢弃已分配的对象，而是释放并把它们保存在内存中。当以后又要请求新的对象时，就可以从内存直接获取而不用重复初始化。（有点像内存池？？） 对象高速缓存的组织如右下图所示，高速缓存的内存区被划分为多个slab，每个slab由一个或多个连续的页框组成，这些页框中既包含已分配的对象，也包含空闲的对象。 对象高速缓存的组织如右下图所示，高速缓存的内存区被划分为多个slab，每个slab由一个或多个连续的页框组成，这些页框中既包含已分配的对象，也包含空闲的对象。 在cache和object中加入slab分配器，是在时间和空间上的折中方案。 slab分配算法slab分配算法采用cache 存储内核对象。当创建cache 时，起初包括若干标记为空闲的对象。对象的数量与slab的大小有关。开始，所有对象都标记为空闲。当需要内核数据结构的对象时，可以直接从cache 上直接获取，并将对象初始化为使用。下面考虑内核如何将slab分配给表示进程描述符的对象。在Linux系统中，进程描述符的类型是struct task_struct ，其大小约为1.7KB。当Linux 内核创建新任务时，它会从cache 中获得struct task_struct 对象所需要的内存。Cache 上会有已分配好的并标记为空闲的struct task_struct 对象来满足请求。Linux 的slab 可有三种状态：满的：slab 中的所有对象被标记为使用。空的：slab 中的所有对象被标记为空闲。部分：slab 中的对象有的被标记为使用，有的被标记为空闲。slab 分配器首先从部分空闲的slab 进行分配。如没有，则从空的slab 进行分配。如没有，则从物理连续页上分配新的slab，并把它赋给一个cache ，然后再从新slab 分配空间。 Linux是如何避免内存碎片的 伙伴算法，用于管理物理内存，避免内存碎片; 高速缓存Slab层用于管理内核分配内存，避免碎片。 共享内存的实现原理？ 系统调用与库函数(open, close, create, lseek, write, read) 同步方法有哪些？ 关于共享内存共享内存针对的通过数据共享来实现的进程间通信 首先我们说一下普通的读写文件原理，进程调用read或write后陷入内核，因为这是系统调用，内核开始读写文件，假设内核在读取文件，内核首先把文件读入自己的内核空间，读完之后进程在内核回归用户态，内核把读入内核内存的数据再copy进入进程的用户态内存空间。实际上我们同一份文件内容相当于读了两次，先读入内核空间，再从内核空间读入用户空间。 数据先搬迁到内核空间，再从内核空间搬迁到用户空间，相当于两次操作 共享内存 共享内存是最快的IPC形式。一旦这样的内存映射到共享它的进程的地址空间，这些进程间数据传递不再涉及到内核，换句话说是进程不再通过执行进入内核的系统调用来传递彼此的数据。 mmap函数要求内核创建一个新的虚拟存储器区域，最好是从地址start开始的一个区域，并将文件描述符fd指定对象的一个连续的片（chunk）映射到这个新的区域。 SHMMNI为128，表示系统中最多可以有128个共享内存对象。 需要某种同步机制，互斥锁和信号量都可以 Linux的2.2.x内核支持多种共享内存方式，如mmap()系统调用，Posix共享内存，以及系统V共享内存 主要介绍mmap()系统调用及系统V共享内存API的原理及应用。 ​ 内存映射函数mmap, 负责把文件内容映射到进程的虚拟内存空间, 通过对这段内存的读取和修改，来实现对文件的读取和修改,而不需要再调用read，write等操作。 我们这里是不同进程通过mmap这个系统调用来完成共享内存这件事情的 内核怎样保证各个进程寻址到同一个共享内存区域的内存页面 cache中page的区分（cache分为page cache和swap cache），一个访问的物理page都驻留在page cache或者swap cahche中， 一个page的所有信息由struct page来描述， struct page中有一个域为指针mapping，指向一个struct address_space。——一个文件对应一个address_space page cache或swap cache中的所有页面就是根据address_space结构以及一个偏移量来区分的。 文件与address_space结构的对应， 一个具体的文件打开后，内核会在内存中为其建立一个struct inode结构，其中的i_mapping域指向一个address_page结构。这样， 一个文件对一个address_space，一个address_space 和 一个偏移量就能够确定一个page cache或swap cache的一个页面， 当要寻址某个数据，通过给定文件及数据在文件中的偏移量找到对应的page 进程调用mmap()时，只是在进程空间内新增了一块相应大小的缓冲区，并设置了相应的访问标识，但并没有建立进程空间到物理页面的映射。因此，第一次访问该空间时，会引发一个缺页异常 对于共享内存映射情况，缺页异常处理程序首先在swap cache中寻找目标页（符合address_space以及偏移量的物理页），如果找到，则直接返回地址；如果没有找到，则判断该页是否在交换区(swap area)，如果在，则执行一个换入操作；如果上述两种情况都不满足，处理程序将分配新的物理页面，并把它插入到page cache中。进程最终将更新进程页表。注：对于映射普通文件情况（非共享映射），缺页异常处理程序首先会在page cache中根据address_space以及数据偏移量寻找相应的页面。如果没有找到，则说明文件数据还没有读入内存，处理程序会从磁盘读入相应的页面，并返回相应地址，同时，进程页表也会更新 所有进程在映射同一个共享内存区域时，情况都一样，在建立线性地址与物理地址之间的映射之后，不论进程各自的返回地址如何，实际访问的必然是同一个共享内存区域对应的物理页面。注：一个共享内存区域可以看作是特殊文件系统shm中的一个文件，shm的安装点在交换区（swap）上。 二、mmap()及其相关系统调用 mmap()系统调用使得进程之间通过映射同一个普通文件实现共享内存。普通文件被映射到进程地址空间后，进程可以向访问普通内存一样对文件进行访问，不必再调用read()，write（）等操作。 注：实际上，mmap()系统调用并不是完全为了用于共享内存而设计的。它本身提供了不同于一般对普通文件的访问方式，进程可以像读写内存一样对普通文件的操作。而Posix或系统V的共享内存IPC则纯粹用于共享目的，当然mmap()实现共享内存也是其主要应用之一。 1、mmap()系统调用形式如下： void* mmap ( void * addr , size_t len , int prot , int flags , int fd , off_t offset )参数fd为即将映射到进程空间的文件描述字，一般由open()返回，同时，fd可以指定为-1，此时须指定flags参数中的MAP_ANON，表明进行的是匿名映射（不涉及具体的文件名，避免了文件的创建及打开，很显然只能用于具有亲缘关系的进程间通信）。len是映射到调用进程地址空间的字节数，它从被映射文件开头offset个字节开始算起。prot 参数指定共享内存的访问权限。可取如下几个值的或：PROT_READ（可读） , PROT_WRITE （可写）, PROT_EXEC （可执行）, PROT_NONE（不可访问）。flags由以下几个常值指定：MAP_SHARED , MAP_PRIVATE , MAP_FIXED，其中，MAP_SHARED , MAP_PRIVATE必选其一，而MAP_FIXED则不推荐使用。offset参数一般设为0，表示从文件头开始映射。参数addr指定文件应被映射到进程空间的起始地址，一般被指定一个空指针，此时选择起始地址的任务留给内核来完成。函数的返回值为最后文件映射到进程空间的地址，进程可直接操作起始地址为该值的有效地址。这里不再详细介绍mmap()的参数，读者可参考mmap()手册页获得进一步的信息。 2、系统调用mmap()用于共享内存的两种方式： （1）使用普通文件提供的内存映射：适用于任何进程之间；此时，需要打开或创建一个文件，然后再调用mmap()；典型调用代码如下： fd=open(name, flag, mode);if(fd&lt;0) … ptr=mmap(NULL, len , PROT_READ|PROT_WRITE, MAP_SHARED , fd , 0); 通过mmap()实现共享内存的通信方式有许多特点和要注意的地方，我们将在范例中进行具体说明。 （2）使用特殊文件提供匿名内存映射：适用于具有亲缘关系的进程之间；由于父子进程特殊的亲缘关系，在父进程中先调用mmap()，然后调用fork()。那么在调用fork()之后，子进程继承父进程匿名映射后的地址空间，同样也继承mmap()返回的地址，这样，父子进程就可以通过映射区域进行通信了。注意，这里不是一般的继承关系。一般来说，子进程单独维护从父进程继承下来的一些变量。而mmap()返回的地址，却由父子进程共同维护。对于具有亲缘关系的进程实现共享内存最好的方式应该是采用匿名内存映射的方式。此时，不必指定具体的文件，只要设置相应的标志即可，参见范例2。 3、系统调用munmap() int munmap( void * addr, size_t len )该调用在进程地址空间中解除一个映射关系，addr是调用mmap()时返回的地址，len是映射区的大小。当映射关系解除后，对原来映射地址的访问将导致段错误发生。 4、系统调用msync() int msync ( void * addr , size_t len, int flags)一般说来，进程在映射空间的对共享内容的改变并不直接写回到磁盘文件中，往往在调用munmap（）后才执行该操作。可以通过调用msync()实现磁盘上文件内容与共享内存区的内容一致。 范例1:两个进程通过映射普通问价实现共享内存通信 两个程序通过命令行参数指定同一个文件来实现共享内存方式的进程间通信。 从程序的运行结果中可以得出的结论 1、 最终被映射文件的内容的长度不会超过文件本身的初始大小，即映射不能改变文件的大小； 2、 可以用于进程通信的有效地址空间大小大体上受限于被映射文件的大小，但不完全受限于文件大小。打开文件被截短为5个people结构大小，而在map_normalfile1中初始化了10个people数据结构，在恰当时候（map_normalfile1输出initialize over 之后，输出umap ok之前）调用map_normalfile2会发现map_normalfile2将输出全部10个people结构的值，后面将给出详细讨论。注：在linux中，内存的保护是以页为基本单位的，即使被映射文件只有一个字节大小，内核也会为映射分配一个页面大小的内存。当被映射文件小于一个页面大小时，进程可以对从mmap()返回地址开始的一个页面大小进行访问，而不会出错；但是，如果对一个页面以外的地址空间进行访问，则导致错误发生，后面将进一步描述。因此，可用于进程间通信的有效地址空间大小不会超过文件大小及一个页面大小的和。 3、 文件一旦被映射后，调用mmap()的进程对返回地址的访问是对某一内存区域的访问，暂时脱离了磁盘上文件的影响。所有对mmap()返回地址空间的操作只在内存中有意义，只有在调用了munmap()后或者msync()时，才把内存中的相应内容写回磁盘文件，所写内容仍然不能超过文件的大小。 Linux有两种共享内存，一种是我们的IPC通信System V版本的共享内存，另一种就是存储映射I/O(mmap) 系统V共享内存指的是把所有共享数据放在共享内存区域（IPC shared memory region），任何想要访问该数据的进程都必须在本进程的地址空间新增一块内存区域，用来映射存放共享数据的物理内存页面。 系统调用mmap()通过映射一个普通文件实现共享内存。系统V则是通过映射特殊文件系统shm中的文件实现进程间的共享内存通信。也就是说，每个共享内存区域对应特殊文件系统shm中的一个文件（这是通过shmid_kernel结构联系起来的），后面还将阐述。 每一个共享内存区都有一个控制结构struct shmid_kernel，是存储管理和文件系统结合起来的桥梁 12345678910111213struct shmid_kernel /* private to the kernel */&#123; struct kern_ipc_perm shm_perm; struct file * shm_file; int id; unsigned long shm_nattch; unsigned long shm_segsz; time_t shm_atim; time_t shm_dtim; time_t shm_ctim; pid_t shm_cprid; pid_t shm_lprid;&#125;; ps：内存对齐，无论是地址对齐还是最后的总大小的对齐，对齐单位都是较小值的整数倍 地址对齐：当前类型的大小和预编译制定的大小的较小值的整数倍 总大小的对齐：结构中最长类型的大小和预编译制定的大小的较小值的整数倍 该结构中最重要的一个域应该是shm_file，它存储了将被映射文件的地址。每个共享内存区对象都对应特殊文件系统shm中的一个文件，一般情况下，特殊文件系统shm中的文件是不能用read()、write()等方法访问的，当采取共享内存的方式把其中的文件映射到进程地址空间后，可直接采用访问内存的方式对其访问。 内核通过数据结构struct ipc_ids shm_ids维护系统中的所有共享内存区域。上图中的shm_ids.entries变量指向一个ipc_id结构数组，而每个ipc_id结构数组中有个指向kern_ipc_perm结构的指针。到这里读者应该很熟悉了，对于系统V共享内存区来说，kern_ipc_perm的宿主是shmid_kernel结构，shmid_kernel是用来描述一个共享内存区域的，这样内核就能够控制系统中所有的共享区域。同时，在shmid_kernel结构的file类型指针shm_file指向文件系统shm中相应的文件，这样，共享内存区域就与shm文件系统中的文件对应起来 创建了一个共享内存区域后，还要将它映射到进程地址空间，系统调用shmat()完成共享内存映射到进程地址空间此项功能，在调用shmget()时，已经创建了文件系统shm中的一个同名文件与共享内存区域相对应，因此，调用shmat()的过程相当于映射文件系统shm中的同名文件过程，原理与mmap()大同小异。 systemV 共享内存API shmget（）用来获得共享内存区域的ID，如果不存在指定的共享区域就创建相应的区域。shmat()把共享内存区域映射到调用进程的地址空间中去，这样，进程就可以方便地对共享区域进行访问操作。shmdt()调用用来解除进程对共享内存区域的映射。shmctl实现对共享内存区域的控制操作。这里我们不对这些系统调用作具体的介绍，读者可参考相应的手册页面，后面的范例中将给出它们的调用方法。 系统V共享内存限制 在/proc/sys/kernel/目录下，记录着系统V共享内存的一下限制，如一个共享内存区的最大字节数shmmax，系统范围内最大共享内存区标识符数shmmni等，可以手工对其调整，但不推荐这样做。 通过对试验结果分析，对比系统V与mmap()映射普通文件实现共享内存通信，可以得出如下结论： 1、 系统V共享内存中的数据，从来不写入到实际磁盘文件中去；而通过mmap()映射普通文件实现的共享内存通信可以指定何时将数据写入磁盘文件中。注：前面讲到，系统V共享内存机制实际是通过映射特殊文件系统shm中的文件实现的，文件系统shm的安装点在交换分区上，系统重新引导后，所有的内容都丢失。 2、 系统V共享内存是随内核持续的，即使所有访问共享内存的进程都已经正常终止，共享内存区仍然存在（除非显式删除共享内存），在内核重新引导之前，对该共享内存区域的任何改写操作都将一直保留。 3、 通过调用mmap()映射普通文件进行进程间通信时，一定要注意考虑进程何时终止对通信的影响。而通过系统V共享内存实现通信的进程则不然。注：这里没有给出shmctl的使用范例，原理与消息队列大同小异。 结论： 共享内存允许两个或多个进程共享一给定的存储区，因为数据不需要来回复制，所以是最快的一种进程间通信机制。共享内存可以通过mmap()映射普通文件（特殊情况下还可以采用匿名映射）机制实现，也可以通过系统V共享内存机制实现。应用接口和原理很简单，内部机制复杂。为了实现更安全通信，往往还与信号灯等同步机制共同使用。 共享内存涉及到了存储管理以及文件系统等方面的知识，深入理解其内部机制有一定的难度，关键还要紧紧抓住内核使用的重要数据结构。系统V共享内存是以文件的形式组织在特殊文件系统shm中的。通过shmget可以创建或获得共享内存的标识符。取得共享内存标识符后，要通过shmat将这个内存区映射到本进程的虚拟地址空间。 上文中的信号灯就是信号量semaphore System V版本的共享内存和存储映射I/O(mmap)区别 1、mmap是在磁盘上建立一个文件，每个进程地址空间中开辟出一块空间进行映射。而对于shm而言，shm每个进程最终会映射到同一块物理内存。shm保存在物理内存，这样读写的速度要比磁盘要快，但是存储量不是特别大。2、相对于shm来说，mmap更加简单，调用更加方便，所以这也是大家都喜欢用的原因。3、另外mmap有一个好处是当机器重启，因为mmap把文件保存在磁盘上，这个文件还保存了操作系统同步的映像，所以mmap不会丢失，但是shmget就会丢失。 在使用虚拟内存的情况下，写时复制（Copy-On-Write）是以页为基础进行的。所以，只要进程不修改它全部的地址空间，那么就不必复制整个地址空间。在fork( )调用结束后，父进程和子进程都相信它们有一个自己的地址空间，但实际上它们共享父进程的原始页，接下来这些页又可以被其他的父进程或子进程共享。 写时复制在内核中的实现非常简单。与内核页相关的数据结构可以被标记为只读和写时复制。如果有进程试图修改一个页，就会产生一个缺页中断。内核处理缺页中断的方式就是对该页进行一次透明复制。这时会清除页面的COW属性，表示着它不再被共享。 现代的计算机系统结构中都在内存管理单元（MMU）提供了硬件级别的写时复制支持，所以实现是很容易的。 在调用fork( )时，写时复制是有很大优势的。因为大量的fork之后都会跟着执行exec，那么复制整个父进程地址空间中的内容到子进程的地址空间完全是在浪费时间：如果子进程立刻执行一个新的二进制可执行文件的映像，它先前的地址空间就会被交换出去。写时复制可以对这种情况进行优化。 fork和vfork的区别： fork( )的子进程拷贝父进程的数据段和代码段；vfork( )的子进程与父进程共享数据段 fork( )的父子进程的执行次序不确定；vfork( )保证子进程先运行，在调用exec或exit之前与父进程数据是共享的，在它调用exec或exit之后父进程才可能被调度运行。 vfork( )保证子进程先运行，在它调用exec或exit之后父进程才可能被调度运行。如果在调用这两个函数之前子进程依赖于父进程的进一步动作，则会导致死锁。 当需要改变共享数据段中变量的值，则拷贝父进程。 异常和中断 内核态和用户态之间的转换方式主要包括：系统调用，异常和中断。 如何设计server，使得能够接收多个客户端的请求 参考回答： 多线程，线程池，io复用 怎样确定当前进程繁忙还是阻塞：使用ps命令 就绪状态的进程在等待什么：等待被唤醒，也就是被调度使用cpu的运行权 各种问题:生产者消费者 哲学家就餐 1、内存溢出 指程序申请内存时，没有足够的内存供申请者使用。内存溢出就是你要的内存空间超过了系统实际分配给你的空间，此时系统相当于没法满足你的需求，就会报内存溢出的错误 2、内存泄漏 内存泄漏是指由于疏忽或错误造成了程序未能释放掉不再使用的内存的情况。内存泄漏并非指内存在物理上的消失，而是应用程序分配某段内存后，由于设计错误，失去了对该段内存的控制，因而造成了内存的浪费。 协程 概念： 协程，又称微线程，纤程，英文名Coroutine。协程看上去也是子程序，但执行过程中，在子程序内部可中断，然后转而执行别的子程序，在适当的时候再返回来接着执行。 例如： 12345678def A() :print &apos;1&apos;print &apos;2&apos;print &apos;3&apos;def B() :print &apos;x&apos;print &apos;y&apos;print &apos;z&apos; 由协程运行结果可能是12x3yz。在执行A的过程中，可以随时中断，去执行B，B也可能在执行过程中中断再去执行A。但协程的特点在于是一个线程执行。 2）协程和线程区别 那和多线程比，协程最大的优势就是协程极高的执行效率。因为子程序切换不是线程切换，而是由程序自身控制，因此，没有线程切换的开销，和多线程比，线程数量越多，协程的性能优势就越明显。 第二大优势就是不需要多线程的锁机制，因为只有一个线程，也不存在同时写变量冲突，在协程中控制共享资源不加锁，只需要判断状态就好了，所以执行效率比多线程高很多。 用户态到内核态的切换操作 1、从当前进程的描述符中提取其内核栈的ss0及esp0信息。 2、使用ss0和esp0指向的内核栈将当前进程的cs,eip，eflags，ss,esp信息保存起来，这个过程也完成了由用户栈找到内核栈的切换过程，同时保存了被暂停执行的程序的下一条指令。 3、将先前由中断向量检索得到的中断处理程序的cs，eip信息装入相应的寄存器，开始执行中断处理程序，这时就转到了内核态的程序执行了。]]></content>
      <categories>
        <category>201909</category>
      </categories>
      <tags>
        <tag>Note</tag>
        <tag>Algorithm</tag>
        <tag>Interview</tag>
      </tags>
  </entry>
</search>
